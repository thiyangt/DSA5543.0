% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  11pt,
  a4paper,
]{report}

\usepackage{amsmath,amssymb}
\usepackage{setspace}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[top=2.5cm,bottom=2.5cm,left=2.5cm,right=2.5cm]{geometry}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{2}

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{241,243,245}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.40,0.45,0.13}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.28,0.35,0.67}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.46,0.62}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.07,0.07,0.07}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother

\makeatletter
\@ifpackageloaded{bookmark}{}{\usepackage{bookmark}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother

\usepackage[style=authoryear-comp,]{biblatex}
\addbibresource{thesisrefs.bib}
\usepackage{bookmark}

\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={DSA 554 3.0 Spatio-temporal Data Analysis},
  pdfauthor={Thiyanga S. Talagala},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}

%% CAPTIONS
\usepackage{caption}
\DeclareCaptionStyle{italic}[justification=centering]
 {labelfont={bf},textfont={it},labelsep=colon}
\captionsetup[figure]{style=italic,format=hang,singlelinecheck=true}
\captionsetup[table]{style=italic,format=hang,singlelinecheck=true}

%% FONT
\usepackage{bera}
\usepackage[charter]{mathdesign}
%\usepackage[scale=0.9]{sourcecodepro}
\usepackage[lf,t]{FiraSans}
\usepackage{fontawesome}

%% HEADERS AND FOOTERS
\usepackage{fancyhdr}
\pagestyle{fancy}
\rfoot{\Large\sffamily\raisebox{-0.1cm}{\textbf{\thepage}}}
\makeatletter
\lhead{\textsf{\expandafter{\@title}}}
\makeatother
\rhead{}
\cfoot{}
\setlength{\headheight}{15pt}
\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0.4pt}
\fancypagestyle{plain}{%
\fancyhf{} % clear all header and footer fields
\fancyfoot[C]{\sffamily\thepage} % except the center
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}}

%% MATHS
\usepackage{bm,amsmath}
\allowdisplaybreaks

%% GRAPHICS
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setcounter{topnumber}{2}
\setcounter{bottomnumber}{2}
\setcounter{totalnumber}{4}
\renewcommand{\topfraction}{0.85}
\renewcommand{\bottomfraction}{0.85}
\renewcommand{\textfraction}{0.15}
\renewcommand{\floatpagefraction}{0.8}
\graphicspath{{figures/}}

%% SECTION TITLES
\usepackage[compact,sf,bf]{titlesec}
\titleformat*{\section}{\Large\sf\bfseries}
\titleformat*{\subsection}{\large\sf\bfseries}
\titleformat*{\subsubsection}{\sf\bfseries}
\titlespacing{\section}{0pt}{*5}{*1}
\titlespacing{\subsection}{0pt}{*2}{*0.2}
\titlespacing{\subsubsection}{0pt}{*1}{*0.1}

%% TABLES
\usepackage{booktabs,tabu}

%% BIBLIOGRAPHY.

\makeatletter
\@ifpackageloaded{biblatex}{
\ExecuteBibliographyOptions{bibencoding=utf8,minnames=1,maxnames=3, maxbibnames=99,dashed=false,terseinits=true,giveninits=true,uniquename=false,uniquelist=false,doi=false, isbn=false,url=true,sortcites=false}
\DeclareFieldFormat{url}{\texttt{\url{#1}}}
\DeclareFieldFormat[article]{pages}{#1}
\DeclareFieldFormat[inproceedings]{pages}{\lowercase{pp.}#1}
\DeclareFieldFormat[incollection]{pages}{\lowercase{pp.}#1}
\DeclareFieldFormat[article]{volume}{\mkbibbold{#1}}
\DeclareFieldFormat[article]{number}{\mkbibparens{#1}}
\DeclareFieldFormat[article]{title}{\MakeCapital{#1}}
\DeclareFieldFormat[article]{url}{}
\DeclareFieldFormat[inproceedings]{title}{#1}
\DeclareFieldFormat{shorthandwidth}{#1}
\usepackage{xpatch}
\xpatchbibmacro{volume+number+eid}{\setunit*{\adddot}}{}{}{}
% Remove In: for an article.
\renewbibmacro{in:}{%
  \ifentrytype{article}{}{%
  \printtext{\bibstring{in}\intitlepunct}}}
\AtEveryBibitem{\clearfield{month}}
\AtEveryCitekey{\clearfield{month}}
\DeclareDelimFormat[cbx@textcite]{nameyeardelim}{\addspace}
\renewcommand*{\finalnamedelim}{\addspace\&\space}
}{}
\makeatother


\hypersetup{
     pdfcreator={Quarto -> pandoc -> LaTeX -> pdf}
}


%% PAGE BREAKING to avoid widows and orphans
\clubpenalty = 2000
\widowpenalty = 2000
\usepackage{microtype}
\def\maketitle{
\pagenumbering{roman}
{\sf\thispagestyle{empty}%
  \null\vskip-.4cm%
  \centerline{\includegraphics[width=12cm]{monash-logo}}
  \vspace*{4cm}
  \begin{center}\fontsize{24}{28}\sf
     \textbf{DSA 554 3.0 Spatio-temporal Data Analysis}\\[2cm]
     \fontsize{18}{20}\sf Thiyanga S. Talagala\\[0.2cm]
     \fontsize{13}{15}\sf 
     \vfill
     \fontsize{13}{15}\sf A thesis submitted for the degree of\\ \\ at Monash University in \number\the\year\\
     
  \end{center}
  \newpage\mbox{}\thispagestyle{empty}\newpage
}
}

% Title and date

\title{DSA 554 3.0 Spatio-temporal Data Analysis}
\date{}
\begin{document}
\maketitle

\renewcommand*\contentsname{Table of contents}
{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{1}
\tableofcontents
}

\setstretch{1.5}
\bookmarksetup{startatroot}

\chapter*{Copyright notice}\label{copyright-notice}
\addcontentsline{toc}{chapter}{Copyright notice}

\markboth{Copyright notice}{Copyright notice}

Produced on 19 December 2025.

¬© Thiyanga S. Talagala (2025).

\clearpage\pagenumbering{arabic}\setcounter{page}{1}

\bookmarksetup{startatroot}

\chapter{Introduction}\label{sec-intro}

In statistics and data science, datasets can take different forms
depending on how they are collected and organized. Understanding the
type of data is crucial because it guides the choice of appropriate
analytical methods.

\section{Cross-sectional data}\label{cross-sectional-data}

Data collected at a single point in time across multiple units (e.g.,
households, firms, individuals).

\textbf{Example:} household income survey conducted in 2025.

\textbf{Assumption:} Each observation (e.g., each household, individual,
firm) is assumed to be unrelated to the others.

In practice, this assumption can be violated if:

\begin{itemize}
\item
  There's clustering (e.g., individuals from the same village may be
  correlated).
\item
  There's spatial correlation (e.g., nearby locations may be similar).
\item
  There's hidden time effects (if data were not truly collected at the
  same time).
\end{itemize}

\section{Time series data}\label{time-series-data}

A time series is a sequence of observations taken sequentially in time.
The data may consist of one variable (univariate time series) or
multiple variables (multivariate time series) observed over regular or
irregular time intervals.

\textbf{Examples:}

Univariate: Monthly rainfall in Colombo from 2000--2025.

Multivariate: Monthly rainfall, temperature, and humidity in Colombo
from 2000--2025.

\section{Spatial data}\label{spatial-data}

Data linked to a geographical location or space.

Example: soil pH levels measured across different districts in Sri
Lanka.

\section{Spatio-temporal data}\label{spatio-temporal-data}

Data that varies across both space and time.

Example: daily dengue cases recorded across different districts over
several years.

\section{Longitudinal data (Repeated
cross-sections)}\label{longitudinal-data-repeated-cross-sections}

Longitudinal data refer to data collected through repeated measurements
over time. The measurements may be taken on the same units (e.g.,
following the same households each year) or on different units at
different time points (e.g., different random samples of households each
year).

\textbf{Example (different random samples of households each year)}

Suppose a national health survey is conducted every 5 years (2000, 2005,
2010, 2015, 2020). Each time, a new random sample of 5,000 households is
selected.

In 2000 ‚Üí Households A, B, C, \ldots{}

In 2005 ‚Üí Households X, Y, Z, \ldots{}

In 2010 ‚Üí Households P, Q, R, \ldots{}

Here, the same households are not followed across time, but the survey
is still longitudinal, since measurements are taken repeatedly over time
to study population-level changes (e.g., trends in obesity, smoking
rates, or income inequality).

\section{Panel data}\label{panel-data}

Panel data are a special case of longitudinal data, where the same units
are observed consistently across multiple time periods. This allows
analysts to study both within-unit dynamics (how a given unit changes
over time) and between-unit differences.

In finance and econometric modelling, panel data is widely used because
it captures both the cross-sectional dimension (different firms,
individuals, or markets) and the time dimension (repeated observations).

In Panel data and Longitudinal data, which combines cross-sectional and
time-series data, allows for the examination of both ``within-behavior''
and ``between-behavior'' effects.

\textbf{Example (Country-level Panel Data)}

Suppose you collect data on GDP growth rates for 50 countries from
2000--2020.

\textbf{1. Country-specific behavior (within a country over time)}

You can see how Sri Lanka's GDP growth changed year by year.

Example:

\begin{itemize}
\tightlist
\item
  was there a slowdown after the 2008 global crisis, followed by
  recovery?
\end{itemize}

\textbf{2. cross-country and temporal effects (Between countries over
time)}

You can compare trends across countries.

Example:

\begin{itemize}
\item
  Did most countries experience a dip in 2008--2009 due to the financial
  crisis?
\item
  Do developing countries generally grow faster than developed countries
  over these 20 years?
\end{itemize}

\bookmarksetup{startatroot}

\chapter{Introduction to Time Series
Analysis}\label{introduction-to-time-series-analysis}

\section{Time series}\label{time-series}

A time series is a sequence of observations recorded in time order. The
time intervals between observations can be regular (e.g., daily,
monthly, yearly) or irregular (e.g., magnitude of a earthquake at a
particular location).

\section{Main Time Series Patterns}\label{main-time-series-patterns}

\subsection{Trend}\label{trend}

Long-term increase or decrease in the data.

\subsection{Seasonal}\label{seasonal}

\begin{itemize}
\item
  A seasonal pattern exists when a series is influenced by seasonal
  factors (e.g., the quarter of the year, the month, or day of the
  week).
\item
  Seasonality is always of a fixed and known period.
\end{itemize}

\subsection{Cyclic}\label{cyclic}

\begin{itemize}
\item
  A cyclic pattern exists when data exhibit rises and falls that are not
  of fixed period.
\item
  The duration of these fluctuations is usually of at least 2 years.
\item
  The average length of cycles is longer than the length of a seasonal
  pattern.
\end{itemize}

\section{Frequency of a time series (Seasonal
periods)}\label{frequency-of-a-time-series-seasonal-periods}

Number of observations per natural time interval (Usually year, but
sometimes a week, a day, an hour)

\subsection{Single Seasonality}\label{single-seasonality}

The time series exhibits one repeating pattern at a fixed frequency.

Example:

Monthly sales that peak every December (annual seasonality).

\begin{longtable}[]{@{}lr@{}}
\toprule\noalign{}
Data & Frequency \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Annual & 1 \\
Quarterly & 4 \\
Monthly & 12 \\
Weekly & 52 \\
\end{longtable}

\subsection{Multiple Seasonality}\label{multiple-seasonality}

The time series exhibits more than one repeating pattern at different
frequencies simultaneously.

Example:

Hourly electricity demand with a daily pattern (peaks every day at
certain hours), a weekly pattern (weekdays vs weekends).

Website traffic with hourly variation and seasonal holiday peaks.

\begin{longtable}[]{@{}cccccc@{}}
\caption{Time Unit Frequencies}\tabularnewline
\toprule\noalign{}
Data & Minute & Hour & Day & Week & Year \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
Data & Minute & Hour & Day & Week & Year \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Daily & NA & NA & NA & 7 & 365.25 \\
Hourly & NA & NA & 24 & 168 & 8766.00 \\
Half-hourly & NA & NA & 48 & 336 & 17532.00 \\
Minutes & 60 & 1440 & 1440 & 10080 & 525960.00 \\
Seconds & 60 & 3600 & 86400 & 604800 & 31557600.00 \\
\end{longtable}

\section{\texorpdfstring{\texttt{DataFrame} for time series data:
Python}{DataFrame for time series data: Python}}\label{dataframe-for-time-series-data-python}

When your DataFrame represents a time series, the index is usually the
date or time, allowing pandas to:

\begin{itemize}
\item
  Plot time series easily
\item
  Resample or aggregate data by time
\item
  Compute rolling statistics
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Import pandas}
\CommentTok{\#py {-}m pip install pandas}
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}

\CommentTok{\# Define data}
\NormalTok{value }\OperatorTok{=}\NormalTok{ [}\DecValTok{100}\NormalTok{, }\DecValTok{250}\NormalTok{, }\DecValTok{78}\NormalTok{, }\DecValTok{300}\NormalTok{, }\DecValTok{500}\NormalTok{]}
\NormalTok{time }\OperatorTok{=} \BuiltInTok{list}\NormalTok{(}\BuiltInTok{range}\NormalTok{(}\DecValTok{2015}\NormalTok{, }\DecValTok{2020}\NormalTok{))}

\CommentTok{\# Create DataFrame}
\NormalTok{df }\OperatorTok{=}\NormalTok{ pd.DataFrame(\{}\StringTok{"Year"}\NormalTok{: time, }\StringTok{"Observation"}\NormalTok{: value\})}

\CommentTok{\# Set \textquotesingle{}Year\textquotesingle{} as index}
\NormalTok{df.set\_index(}\StringTok{"Year"}\NormalTok{, inplace}\OperatorTok{=}\VariableTok{True}\NormalTok{)}

\CommentTok{\# Display the DataFrame}
\BuiltInTok{print}\NormalTok{(df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
      Observation
Year             
2015          100
2016          250
2017           78
2018          300
2019          500
\end{verbatim}

For data collected more often than once a year (e.g., monthly, weekly,
or daily), it's important to tell the computer that the index represents
time. We do this by converting the index to a time or date type using a
time-class function. This helps us sort, select, and analyze the data
correctly over time.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Sample monthly data}
\NormalTok{data }\OperatorTok{=}\NormalTok{ \{}
    \StringTok{"Month"}\NormalTok{: pd.date\_range(start}\OperatorTok{=}\StringTok{"2025{-}01{-}01"}\NormalTok{, periods}\OperatorTok{=}\DecValTok{6}\NormalTok{, freq}\OperatorTok{=}\StringTok{"M"}\NormalTok{),  }\CommentTok{\# 6 months}
    \StringTok{"Sales"}\NormalTok{: [}\DecValTok{120}\NormalTok{, }\DecValTok{150}\NormalTok{, }\DecValTok{170}\NormalTok{, }\DecValTok{130}\NormalTok{, }\DecValTok{180}\NormalTok{, }\DecValTok{200}\NormalTok{]}
\NormalTok{\}}

\CommentTok{\# Create DataFrame}
\NormalTok{z }\OperatorTok{=}\NormalTok{ pd.DataFrame(data)}

\CommentTok{\# Format Month as "Year Month" (e.g., "2025 Jan")}
\NormalTok{z[}\StringTok{"Month"}\NormalTok{] }\OperatorTok{=}\NormalTok{ z[}\StringTok{"Month"}\NormalTok{].dt.strftime(}\StringTok{"\%Y \%b"}\NormalTok{)}

\CommentTok{\# Set Month as index}
\NormalTok{z.set\_index(}\StringTok{"Month"}\NormalTok{, inplace}\OperatorTok{=}\VariableTok{True}\NormalTok{)}

\CommentTok{\# Display the DataFrame}
\BuiltInTok{print}\NormalTok{(z)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
          Sales
Month          
2025 Jan    120
2025 Feb    150
2025 Mar    170
2025 Apr    130
2025 May    180
2025 Jun    200
\end{verbatim}

\section{\texorpdfstring{\texttt{DataFrame} for time series data:
R}{DataFrame for time series data: R}}\label{dataframe-for-time-series-data-r}

We use tsibbles to store data.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidyverse)}
\FunctionTok{library}\NormalTok{(tsibble)}
\FunctionTok{library}\NormalTok{(lubridate)}
\FunctionTok{library}\NormalTok{(feasts)}
\FunctionTok{library}\NormalTok{(denguedatahub)}
\CommentTok{\# install.packages("devtools")}
\CommentTok{\#devtools::install\_github("thiyangt/TourSriLanka")}
\FunctionTok{library}\NormalTok{(TourSriLanka)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y.tsibble }\OtherTok{\textless{}{-}} \FunctionTok{tsibble}\NormalTok{(}
  \AttributeTok{Year =} \DecValTok{2020}\SpecialCharTok{:}\DecValTok{2023}\NormalTok{,}
  \AttributeTok{Earnings =} \FunctionTok{c}\NormalTok{(}\FloatTok{682.4}\NormalTok{, }\FloatTok{506.9}\NormalTok{, }\FloatTok{1136.3}\NormalTok{, }\FloatTok{2068.0}\NormalTok{),}
  \AttributeTok{index =}\NormalTok{ Year)}
\NormalTok{y.tsibble}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tsibble: 4 x 2 [1Y]
   Year Earnings
  <int>    <dbl>
1  2020     682.
2  2021     507.
3  2022    1136.
4  2023    2068 
\end{verbatim}

\section{Dataset: R}\label{dataset-r}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(TourSriLanka)}
\FunctionTok{data}\NormalTok{(earnings)}
\NormalTok{earnings}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 180 x 3
   Month   Year  Earnings
   <chr>   <chr>    <dbl>
 1 January 2009      30  
 2 January 2010      44.7
 3 January 2011      72  
 4 January 2012      88.9
 5 January 2013     149. 
 6 January 2014     233. 
 7 January 2015     259  
 8 January 2016     333. 
 9 January 2017     407. 
10 January 2018     448. 
# i 170 more rows
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{earnings }\OtherTok{\textless{}{-}}\NormalTok{ earnings }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{arrange}\NormalTok{(Year, }\FunctionTok{match}\NormalTok{(Month, month.name) )}
\NormalTok{earnings}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 180 x 3
   Month     Year  Earnings
   <chr>     <chr>    <dbl>
 1 January   2009      30  
 2 February  2009      26.7
 3 March     2009      26.6
 4 April     2009      20.3
 5 May       2009      19.3
 6 June      2009      23.6
 7 July      2009      33  
 8 August    2009      32.2
 9 September 2009      29.6
10 October   2009      29.3
# i 170 more rows
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y.earnings }\OtherTok{\textless{}{-}}\NormalTok{ earnings }\SpecialCharTok{|\textgreater{}} \FunctionTok{mutate}\NormalTok{(}\AttributeTok{Date =} \FunctionTok{seq}\NormalTok{(}\FunctionTok{ymd\_hm}\NormalTok{(}\StringTok{"2009{-}1{-}1 0:00"}\NormalTok{), }\FunctionTok{ymd\_hm}\NormalTok{(}\StringTok{"2023{-}12{-}1 12:00"}\NormalTok{), }\AttributeTok{by =} \StringTok{"month"}\NormalTok{))}
\NormalTok{y.earnings}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 180 x 4
   Month     Year  Earnings Date               
   <chr>     <chr>    <dbl> <dttm>             
 1 January   2009      30   2009-01-01 00:00:00
 2 February  2009      26.7 2009-02-01 00:00:00
 3 March     2009      26.6 2009-03-01 00:00:00
 4 April     2009      20.3 2009-04-01 00:00:00
 5 May       2009      19.3 2009-05-01 00:00:00
 6 June      2009      23.6 2009-06-01 00:00:00
 7 July      2009      33   2009-07-01 00:00:00
 8 August    2009      32.2 2009-08-01 00:00:00
 9 September 2009      29.6 2009-09-01 00:00:00
10 October   2009      29.3 2009-10-01 00:00:00
# i 170 more rows
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y.earnings }\OtherTok{\textless{}{-}}\NormalTok{ y.earnings }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{select}\NormalTok{(Earnings, Date) }\SpecialCharTok{|\textgreater{}} \FunctionTok{mutate}\NormalTok{(}\AttributeTok{Time =} \FunctionTok{yearmonth}\NormalTok{(Date))}
\NormalTok{y.earnings}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 180 x 3
   Earnings Date                    Time
      <dbl> <dttm>                 <mth>
 1     30   2009-01-01 00:00:00 2009 Jan
 2     26.7 2009-02-01 00:00:00 2009 Feb
 3     26.6 2009-03-01 00:00:00 2009 Mar
 4     20.3 2009-04-01 00:00:00 2009 Apr
 5     19.3 2009-05-01 00:00:00 2009 May
 6     23.6 2009-06-01 00:00:00 2009 Jun
 7     33   2009-07-01 00:00:00 2009 Jul
 8     32.2 2009-08-01 00:00:00 2009 Aug
 9     29.6 2009-09-01 00:00:00 2009 Sep
10     29.3 2009-10-01 00:00:00 2009 Oct
# i 170 more rows
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ts.earnings }\OtherTok{\textless{}{-}}\NormalTok{ y.earnings }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{select}\NormalTok{(Earnings, Time) }\SpecialCharTok{|\textgreater{}} \FunctionTok{as\_tsibble}\NormalTok{(}\AttributeTok{index=}\NormalTok{Time)}
\NormalTok{ts.earnings}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tsibble: 180 x 2 [1M]
   Earnings     Time
      <dbl>    <mth>
 1     30   2009 Jan
 2     26.7 2009 Feb
 3     26.6 2009 Mar
 4     20.3 2009 Apr
 5     19.3 2009 May
 6     23.6 2009 Jun
 7     33   2009 Jul
 8     32.2 2009 Aug
 9     29.6 2009 Sep
10     29.3 2009 Oct
# i 170 more rows
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ggts }\OtherTok{\textless{}{-}}\NormalTok{ ts.earnings }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ Time, }\AttributeTok{y =}\NormalTok{ Earnings)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{y =} \StringTok{"Earnings from tourism (USD Mn)"}\NormalTok{, }\AttributeTok{x=}\StringTok{"Time"}\NormalTok{)  }
\NormalTok{ggts}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{02-chap2_files/figure-pdf/unnamed-chunk-13-1.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ts.earnings }\OtherTok{\textless{}{-}}\NormalTok{ y.earnings }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{select}\NormalTok{(Earnings, Time) }\SpecialCharTok{|\textgreater{}} \FunctionTok{as\_tsibble}\NormalTok{(}\AttributeTok{index=}\NormalTok{Time)}
\NormalTok{ts.earnings}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tsibble: 180 x 2 [1M]
   Earnings     Time
      <dbl>    <mth>
 1     30   2009 Jan
 2     26.7 2009 Feb
 3     26.6 2009 Mar
 4     20.3 2009 Apr
 5     19.3 2009 May
 6     23.6 2009 Jun
 7     33   2009 Jul
 8     32.2 2009 Aug
 9     29.6 2009 Sep
10     29.3 2009 Oct
# i 170 more rows
\end{verbatim}

\section{Time series visualisation using grammar of graphics:
R}\label{time-series-visualisation-using-grammar-of-graphics-r}

The grammar of graphics is a way of thinking about plots as layers. Each
plot is built from components like:

\textbf{Data} -- the dataset you are plotting.

\textbf{Aesthetics (aes)} -- how variables map to visual properties like
x, y, color, or size.

\textbf{Geometries (geom)} -- the type of plot (points, lines, bars,
etc.).

\textbf{Facets} -- split the plot into subplots based on a variable.

\textbf{Statistics (stat)} -- summary computations like regression lines
or counts.

\textbf{Scales} -- control axis limits, colors, or sizes.

\textbf{Coordinates (coord)} -- control coordinate system (Cartesian,
polar).

\textbf{Theme} -- control visual appearance like text, background, and
grid.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ggts }\OtherTok{\textless{}{-}}\NormalTok{ ts.earnings }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ Time, }\AttributeTok{y =}\NormalTok{ Earnings)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{y =} \StringTok{"Earnings from tourism (USD Mn)"}\NormalTok{, }\AttributeTok{x=}\StringTok{"Time"}\NormalTok{)  }
\NormalTok{ggts}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{02-chap2_files/figure-pdf/unnamed-chunk-15-1.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ggts }\OtherTok{\textless{}{-}}\NormalTok{ ts.earnings }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ Time, }\AttributeTok{y =}\NormalTok{ Earnings)) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{y =} \StringTok{"Earnings from tourism (USD Mn)"}\NormalTok{, }\AttributeTok{x=}\StringTok{"Time"}\NormalTok{)  }
\NormalTok{ggts}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{02-chap2_files/figure-pdf/unnamed-chunk-16-1.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ts.earnings }\SpecialCharTok{|\textgreater{}}
    \FunctionTok{mutate}\NormalTok{(}\AttributeTok{Time =} \FunctionTok{as\_date}\NormalTok{(}\FunctionTok{yearmonth}\NormalTok{(Time))) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ Time, }\AttributeTok{y =}\NormalTok{ Earnings)) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{scale\_x\_date}\NormalTok{(}\AttributeTok{date\_breaks =} \StringTok{"1 year"}\NormalTok{, }\AttributeTok{date\_labels =} \StringTok{"\%Y"}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{y =} \StringTok{"Earnings from tourism (USD Mn)"}\NormalTok{, }\AttributeTok{x=}\StringTok{"Time"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{02-chap2_files/figure-pdf/unnamed-chunk-17-1.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(viridis)}
\NormalTok{ts.earnings }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{gg\_season}\NormalTok{(Earnings, }\AttributeTok{period =} \StringTok{"1 year"}\NormalTok{,  }\AttributeTok{pal =}\NormalTok{ scales}\SpecialCharTok{::}\FunctionTok{viridis\_pal}\NormalTok{()(}\DecValTok{15}\NormalTok{))  }\SpecialCharTok{+} \FunctionTok{geom\_point}\NormalTok{()  }
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{02-chap2_files/figure-pdf/unnamed-chunk-18-1.pdf}}

\section{Dataset: Python}\label{dataset-python}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ plotnine }\ImportTok{as}\NormalTok{ p9}
\ImportTok{from}\NormalTok{ plotnine.data }\ImportTok{import}\NormalTok{ economics}
\end{Highlighting}
\end{Shaded}

\section{Working with Built-in Data
Set}\label{working-with-built-in-data-set}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}
\ImportTok{import}\NormalTok{ plotnine }\ImportTok{as}\NormalTok{ p9 }
\ImportTok{from}\NormalTok{ plotnine }\ImportTok{import} \OperatorTok{*}
\ImportTok{from}\NormalTok{ plotnine.data }\ImportTok{import} \OperatorTok{*}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\NormalTok{economics}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
          date      pce     pop  psavert  uempmed  unemploy
0   1967-07-01    507.4  198712     12.5      4.5      2944
1   1967-08-01    510.5  198911     12.5      4.7      2945
2   1967-09-01    516.3  199113     11.7      4.6      2958
3   1967-10-01    512.9  199311     12.5      4.9      3143
4   1967-11-01    518.1  199498     12.5      4.7      3066
..         ...      ...     ...      ...      ...       ...
569 2014-12-01  12122.0  320201      5.0     12.6      8688
570 2015-01-01  12080.8  320367      5.5     13.4      8979
571 2015-02-01  12095.9  320534      5.7     13.1      8705
572 2015-03-01  12161.5  320707      5.2     12.2      8575
573 2015-04-01  12158.9  320887      5.6     11.7      8549

[574 rows x 6 columns]
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{economics.info()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 574 entries, 0 to 573
Data columns (total 6 columns):
 #   Column    Non-Null Count  Dtype         
---  ------    --------------  -----         
 0   date      574 non-null    datetime64[ns]
 1   pce       574 non-null    float64       
 2   pop       574 non-null    int64         
 3   psavert   574 non-null    float64       
 4   uempmed   574 non-null    float64       
 5   unemploy  574 non-null    int64         
dtypes: datetime64[ns](1), float64(3), int64(2)
memory usage: 27.0 KB
\end{verbatim}

\subsection{\texorpdfstring{Create \texttt{year} and \texttt{month}
columns}{Create year and month columns}}\label{create-year-and-month-columns}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{economics[}\StringTok{\textquotesingle{}year\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ economics[}\StringTok{\textquotesingle{}date\textquotesingle{}}\NormalTok{].dt.year}
\NormalTok{economics[}\StringTok{\textquotesingle{}month\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ economics[}\StringTok{\textquotesingle{}date\textquotesingle{}}\NormalTok{].dt.month}
\NormalTok{economics}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
          date      pce     pop  psavert  uempmed  unemploy  year  month
0   1967-07-01    507.4  198712     12.5      4.5      2944  1967      7
1   1967-08-01    510.5  198911     12.5      4.7      2945  1967      8
2   1967-09-01    516.3  199113     11.7      4.6      2958  1967      9
3   1967-10-01    512.9  199311     12.5      4.9      3143  1967     10
4   1967-11-01    518.1  199498     12.5      4.7      3066  1967     11
..         ...      ...     ...      ...      ...       ...   ...    ...
569 2014-12-01  12122.0  320201      5.0     12.6      8688  2014     12
570 2015-01-01  12080.8  320367      5.5     13.4      8979  2015      1
571 2015-02-01  12095.9  320534      5.7     13.1      8705  2015      2
572 2015-03-01  12161.5  320707      5.2     12.2      8575  2015      3
573 2015-04-01  12158.9  320887      5.6     11.7      8549  2015      4

[574 rows x 8 columns]
\end{verbatim}

\section{Time series visualisation using grammar of graphics:
Python}\label{time-series-visualisation-using-grammar-of-graphics-python}

{[}See the tutorial here

{]}(https://thiyangt.github.io/spts\_python\_practical/Practical1/)

\section{What is a lag value?}\label{what-is-a-lag-value}

In time series analysis, a lag represents the number of time steps by
which a series is shifted backward to compare it with itself.

Lag 1: Compare each value with the previous observation.

Lag 2: Compare each value with the value two steps before.

Lag k: Compare each value with the value k steps earlier.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}

\CommentTok{\# Small time series with 5 points}
\NormalTok{data }\OperatorTok{=}\NormalTok{ [}\DecValTok{10}\NormalTok{, }\DecValTok{12}\NormalTok{, }\DecValTok{13}\NormalTok{, }\DecValTok{15}\NormalTok{, }\DecValTok{14}\NormalTok{]}
\NormalTok{dates }\OperatorTok{=}\NormalTok{ pd.date\_range(start}\OperatorTok{=}\StringTok{\textquotesingle{}2025{-}01{-}01\textquotesingle{}}\NormalTok{, periods}\OperatorTok{=}\DecValTok{5}\NormalTok{, freq}\OperatorTok{=}\StringTok{\textquotesingle{}D\textquotesingle{}}\NormalTok{)}

\NormalTok{df }\OperatorTok{=}\NormalTok{ pd.DataFrame(\{}\StringTok{\textquotesingle{}Date\textquotesingle{}}\NormalTok{: dates, }\StringTok{\textquotesingle{}Value\textquotesingle{}}\NormalTok{: data\})}
\NormalTok{df.set\_index(}\StringTok{\textquotesingle{}Date\textquotesingle{}}\NormalTok{, inplace}\OperatorTok{=}\VariableTok{True}\NormalTok{)}

\CommentTok{\# Create lagged series}
\NormalTok{df[}\StringTok{\textquotesingle{}Lag1\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ df[}\StringTok{\textquotesingle{}Value\textquotesingle{}}\NormalTok{].shift(}\DecValTok{1}\NormalTok{)  }\CommentTok{\# lag 1}
\NormalTok{df[}\StringTok{\textquotesingle{}Lag2\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ df[}\StringTok{\textquotesingle{}Value\textquotesingle{}}\NormalTok{].shift(}\DecValTok{2}\NormalTok{)  }\CommentTok{\# lag 2}

\CommentTok{\# Show the result}
\BuiltInTok{print}\NormalTok{(df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
            Value  Lag1  Lag2
Date                         
2025-01-01     10   NaN   NaN
2025-01-02     12  10.0   NaN
2025-01-03     13  12.0  10.0
2025-01-04     15  13.0  12.0
2025-01-05     14  15.0  13.0
\end{verbatim}

\section{Correlation vs
Autocorrelation}\label{correlation-vs-autocorrelation}

\subsection{Correlation}\label{correlation}

Measures the strength of the linear relationship between two variables

\[r = \frac{\sum_{i=1}^{n} (x_i -\bar{x})(y_i-\bar{y})}{\sqrt{\sum_{i=1}^{n} (x_i -\bar{x})^2 \sum_{i=1}^{n} (y_i -\bar{y})^2}}\]

\subsection{Autocorrelation}\label{autocorrelation}

Measures the strength of linear relationship between lagged values of
time series.

\[r_k = \frac{\sum (y_t -\bar{y})(y_{t-k}-\bar{y})}{\sum (y_t -\bar{y})^2}\]

\section{Your turn: why different
values?}\label{your-turn-why-different-values}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Correlation (autocorrelation) between original series and lagged series}
\NormalTok{autocorr\_lag1 }\OperatorTok{=}\NormalTok{ df[}\StringTok{\textquotesingle{}Value\textquotesingle{}}\NormalTok{].corr(df[}\StringTok{\textquotesingle{}Lag1\textquotesingle{}}\NormalTok{])}
\NormalTok{autocorr\_lag2 }\OperatorTok{=}\NormalTok{ df[}\StringTok{\textquotesingle{}Value\textquotesingle{}}\NormalTok{].corr(df[}\StringTok{\textquotesingle{}Lag2\textquotesingle{}}\NormalTok{])}

\BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Autocorrelation at lag 1: }\SpecialCharTok{\{}\NormalTok{autocorr\_lag1}\SpecialCharTok{:.3f\}}\SpecialStringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Autocorrelation at lag 1: 0.744
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Autocorrelation at lag 2: }\SpecialCharTok{\{}\NormalTok{autocorr\_lag2}\SpecialCharTok{:.3f\}}\SpecialStringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Autocorrelation at lag 2: 0.655
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}
\ImportTok{from}\NormalTok{ statsmodels.tsa.stattools }\ImportTok{import}\NormalTok{ acf}

\CommentTok{\# Small time series with 5 points}
\NormalTok{data }\OperatorTok{=}\NormalTok{ [}\DecValTok{10}\NormalTok{, }\DecValTok{12}\NormalTok{, }\DecValTok{13}\NormalTok{, }\DecValTok{15}\NormalTok{, }\DecValTok{14}\NormalTok{]}
\NormalTok{dates }\OperatorTok{=}\NormalTok{ pd.date\_range(start}\OperatorTok{=}\StringTok{\textquotesingle{}2025{-}01{-}01\textquotesingle{}}\NormalTok{, periods}\OperatorTok{=}\DecValTok{5}\NormalTok{, freq}\OperatorTok{=}\StringTok{\textquotesingle{}D\textquotesingle{}}\NormalTok{)}

\NormalTok{df }\OperatorTok{=}\NormalTok{ pd.DataFrame(\{}\StringTok{\textquotesingle{}Date\textquotesingle{}}\NormalTok{: dates, }\StringTok{\textquotesingle{}Value\textquotesingle{}}\NormalTok{: data\})}
\NormalTok{df.set\_index(}\StringTok{\textquotesingle{}Date\textquotesingle{}}\NormalTok{, inplace}\OperatorTok{=}\VariableTok{True}\NormalTok{)}

\BuiltInTok{print}\NormalTok{(df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
            Value
Date             
2025-01-01     10
2025-01-02     12
2025-01-03     13
2025-01-04     15
2025-01-05     14
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Compute autocorrelation for lags 1 to 4 (max lag = n{-}1)}
\NormalTok{autocorr\_values }\OperatorTok{=}\NormalTok{ acf(df[}\StringTok{\textquotesingle{}Value\textquotesingle{}}\NormalTok{], nlags}\OperatorTok{=}\DecValTok{4}\NormalTok{, fft}\OperatorTok{=}\VariableTok{False}\NormalTok{)}

\CommentTok{\# Show autocorrelation values}
\ControlFlowTok{for}\NormalTok{ lag, val }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(autocorr\_values):}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Lag }\SpecialCharTok{\{}\NormalTok{lag}\SpecialCharTok{\}}\SpecialStringTok{: }\SpecialCharTok{\{}\NormalTok{val}\SpecialCharTok{:.3f\}}\SpecialStringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Lag 0: 1.000
Lag 1: 0.349
Lag 2: -0.141
Lag 3: -0.481
Lag 4: -0.227
\end{verbatim}

\section{Autocorrelation plots (ACF)}\label{autocorrelation-plots-acf}

The ACF measures the correlation between a time series and lagged
versions of itself. It tells us how past values influence current
values.

\subsection{Example 1}\label{example-1}

Time series plot

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(fable)}
\FunctionTok{library}\NormalTok{(fpp2)}
\FunctionTok{autoplot}\NormalTok{(beer)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{02-chap2_files/figure-pdf/unnamed-chunk-27-1.pdf}}

Seasonal plot

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggseasonplot}\NormalTok{(beer, }\AttributeTok{year.labels=}\ConstantTok{TRUE}\NormalTok{, }\AttributeTok{year.labels.left=}\ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{02-chap2_files/figure-pdf/unnamed-chunk-28-1.pdf}}

ACF

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggAcf}\NormalTok{(beer)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{02-chap2_files/figure-pdf/unnamed-chunk-29-1.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggseasonplot}\NormalTok{(beer, }\AttributeTok{year.labels=}\ConstantTok{TRUE}\NormalTok{, }\AttributeTok{year.labels.left=}\ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{02-chap2_files/figure-pdf/unnamed-chunk-30-1.pdf}}

\section{Example 2}\label{example-2}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{aelec }\OtherTok{\textless{}{-}} \FunctionTok{window}\NormalTok{(elec, }\AttributeTok{start=}\DecValTok{1980}\NormalTok{)}
\FunctionTok{autoplot}\NormalTok{(aelec) }\SpecialCharTok{+} \FunctionTok{xlab}\NormalTok{(}\StringTok{"Year"}\NormalTok{) }\SpecialCharTok{+} \FunctionTok{ylab}\NormalTok{(}\StringTok{"GWh"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{02-chap2_files/figure-pdf/unnamed-chunk-31-1.pdf}}

Seasonal plots

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggseasonplot}\NormalTok{(aelec, }\AttributeTok{year.labels=}\ConstantTok{TRUE}\NormalTok{, }\AttributeTok{year.labels.left=}\ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{02-chap2_files/figure-pdf/unnamed-chunk-32-1.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggAcf}\NormalTok{(aelec, }\AttributeTok{lag=}\DecValTok{48}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{02-chap2_files/figure-pdf/unnamed-chunk-33-1.pdf}}

\section{Example 3}\label{example-3}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{3}\NormalTok{)}
\NormalTok{y }\OtherTok{\textless{}{-}} \FunctionTok{ts}\NormalTok{(}\FunctionTok{rnorm}\NormalTok{(}\DecValTok{50}\NormalTok{))}
\FunctionTok{autoplot}\NormalTok{(y) }\SpecialCharTok{+} \FunctionTok{ggtitle}\NormalTok{(}\StringTok{"White noise"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{02-chap2_files/figure-pdf/unnamed-chunk-34-1.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggAcf}\NormalTok{(y)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{02-chap2_files/figure-pdf/unnamed-chunk-35-1.pdf}}

\section{Exercise}\label{exercise}

Question 6 at \url{https://otexts.com/fpp2/graphics-exercises.html}

\bookmarksetup{startatroot}

\chapter{Introduction to Time Series
Forecasting}\label{introduction-to-time-series-forecasting}

\section{Notation}\label{notation}

\(\hat{Y}_{T+h|T}\) - The forecast of the time series \(ùëå\) at time
\(T+h\), made using the information available up to time \(T\).

\section{Simple time series forecasting
techniques}\label{simple-time-series-forecasting-techniques}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Average method
\item
  Naive method/ random walk method
\item
  Seasonal naive method
\item
  Drift method
\end{enumerate}

\href{https://otexts.com/fpp2/simple-methods.html}{Reading}

\section{Example: Electricity Demand
Forecasting}\label{example-electricity-demand-forecasting}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(fable)}
\FunctionTok{library}\NormalTok{(fpp2)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{aelec }\OtherTok{\textless{}{-}} \FunctionTok{window}\NormalTok{(elec, }\AttributeTok{start=}\DecValTok{1980}\NormalTok{)}
\FunctionTok{autoplot}\NormalTok{(aelec)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{03-chap3_files/figure-pdf/unnamed-chunk-3-1.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Plot some forecasts}
\FunctionTok{autoplot}\NormalTok{(aelec) }\SpecialCharTok{+}
  \FunctionTok{autolayer}\NormalTok{(}\FunctionTok{meanf}\NormalTok{(aelec, }\AttributeTok{h=}\DecValTok{11}\NormalTok{),}
    \AttributeTok{series=}\StringTok{"Mean"}\NormalTok{, }\AttributeTok{PI=}\ConstantTok{FALSE}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{autolayer}\NormalTok{(}\FunctionTok{naive}\NormalTok{(aelec, }\AttributeTok{h=}\DecValTok{11}\NormalTok{),}
    \AttributeTok{series=}\StringTok{"Na√Øve"}\NormalTok{, }\AttributeTok{PI=}\ConstantTok{FALSE}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{autolayer}\NormalTok{(}\FunctionTok{snaive}\NormalTok{(aelec, }\AttributeTok{h=}\DecValTok{11}\NormalTok{),}
    \AttributeTok{series=}\StringTok{"Seasonal na√Øve"}\NormalTok{, }\AttributeTok{PI=}\ConstantTok{FALSE}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ggtitle}\NormalTok{(}\StringTok{"Forecasts from Mean, NAIVE and SNAIVE"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{xlab}\NormalTok{(}\StringTok{"Year"}\NormalTok{) }\SpecialCharTok{+} \FunctionTok{ylab}\NormalTok{(}\StringTok{"Value"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{guides}\NormalTok{(}\AttributeTok{colour=}\FunctionTok{guide\_legend}\NormalTok{(}\AttributeTok{title=}\StringTok{"Forecast"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{03-chap3_files/figure-pdf/unnamed-chunk-4-1.pdf}}

\section{Time Series and Stochastic
Processes}\label{time-series-and-stochastic-processes}

The terms stochastic processes and time series are closely related but
not the same.

A \textbf{stochastic process} is a collection of random variables
indexed by time (or space).

\[\{X_t : t \in T\},\]

where \(T\) is the index set (e.g., discrete or continuous time).

A \textbf{time series} is a single realization (observed data) of a
stochastic process. It is the actual sequence of observations collected
over time.

In short:

Stochastic process = model/theory (all possible sequences). The
probability mechanism (all possible paths).

Time series = observed data (one sequence). One observed path (the
single trajectory we actually have).

\section{Statistical Properties}\label{statistical-properties}

\subsection{Mean function}\label{mean-function}

Let \({X_1, X_2, ...}\) be a sequence of time index random variables.

The \textbf{mean function} of \({X_t}\) is

\[\mu_X(t)=E(X_t).\]

\subsection{Covariance function}\label{covariance-function}

The \textbf{covariance function} of \({X_t}\) is

\[\gamma_X(r, s)=Cov(X_r, X_s)=E[(X_r-\mu_X(r))(X_s-\mu_X(s))]\]

for all integers \((r)\) and \((s)\).

\subsection{Autocovariance function}\label{autocovariance-function}

The autocovariance function of \({X_t}\) at lag \((h)\) is defined by
\[\gamma_X(h):=\gamma_X(h, 0)=\gamma(t+h, t)=Cov(X_{t+h}, X_t).\]

or

The autocovariance function of \({X_t}\) at lag \((h)\) is

\[\gamma_X(h)=Cov(X_{t+h}, X_t).\]

\subsection{Autocorrelation function}\label{autocorrelation-function}

The autocorrelation function of \({X_t}\) at lag \((h)\) is

\[\rho_X(h)=\frac{\gamma_X(h)}{\gamma_X(0)}=Cor(X_{t+h}, X_t).\]

\section{Weakly stationary}\label{weakly-stationary}

A time series \({X_t}\) is called weakly stationary if

\begin{itemize}
\item
  \(\mu_X(t)\) is independent of \(t\).
\item
  \(Var(X_t) = \sigma^2\), Variance is constant. 2
\item
  \(\gamma_X(t+h, t)\) is independent of \((t)\) for each \((h)\). The
  autocovariance depends only on the lag (\(\gamma(h)\) depends only on
  how far apart two points are (\(h\)), and not on the actual time
  \(t\).
\end{itemize}

In other words the statistical properties of the time series (mean,
variance, autocorrelation, etc.) do not depend on the time at which the
series is observed, that is no trend or seasonality. However, a time
series with cyclic behaviour (but with no trend or seasonality) is
stationary.

\section{Strict stationarity of a time
series}\label{strict-stationarity-of-a-time-series}

A time series \(\{X_t\}\) is called strictly stationary if the random
vector \([X_1, X_2..., X_n]\) and \([X_{1+h}, X_{2+h}..., X_{n+h}]\)
have the same joint distribution for all integers \((h)\) and
\((n > 0)\).

\section{1. independent and identically distributed (iid)
noise}\label{independent-and-identically-distributed-iid-noise}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  no trend or seasonal component
\item
  observations are independent and identically distributed (iid) random
  variables with zero mean.
\item
  Notation: \({X_t} \sim IID(0, \sigma^2)\)
\item
  plays an important role as a building block for more complicated time
  series.
\end{enumerate}

\section{2. White noise}\label{white-noise}

If \({X_t}\) is a sequence of uncorrelated random variables, each with
zero mean and variance \(\sigma^2\), then such a sequence is referred to
as \textbf{white noise}.

\section{\texorpdfstring{Every \((IID(0, \sigma^2)\) sequence is
\((WN(0, \sigma^2)\) but not conversely.
Why?}{Every (IID(0, \textbackslash sigma\^{}2) sequence is (WN(0, \textbackslash sigma\^{}2) but not conversely. Why?}}\label{every-iid0-sigma2-sequence-is-wn0-sigma2-but-not-conversely.-why}

\subsection{1. White Noise (WN)}\label{white-noise-wn}

A sequence \(\{X_t\}\) is called \textbf{white noise} with mean \(0\)
and variance \(\sigma^2\), written \(WN(0, \sigma^2)\), if:

\begin{itemize}
\tightlist
\item
  \(\mathbb{E}[X_t] = 0\) for all \(t\).\\
\item
  \(\mathrm{Var}(X_t) = \sigma^2\) for all \(t\).\\
\item
  \(\mathrm{Cov}(X_t, X_s) = 0\) for all \(t \neq s\) (uncorrelated
  across time).
\end{itemize}

Notice: \emph{uncorrelated \(\neq\) independent}.

\subsection{\texorpdfstring{2. i.i.d.
\((0, \sigma^2)\)}{2. i.i.d. (0, \textbackslash sigma\^{}2)}}\label{i.i.d.-0-sigma2}

A sequence \(\{X_t\}\) is \(IID(0, \sigma^2)\) if:

\begin{itemize}
\tightlist
\item
  \(\mathbb{E}[X_t] = 0\).\\
\item
  \(\mathrm{Var}(X_t) = \sigma^2\).\\
\item
  \(X_t\) are independent and identically distributed.
\end{itemize}

\subsection{\texorpdfstring{3. Why every \(IID(0, \sigma^2)\) is
\(WN(0, \sigma^2)\)}{3. Why every IID(0, \textbackslash sigma\^{}2) is WN(0, \textbackslash sigma\^{}2)}}\label{why-every-iid0-sigma2-is-wn0-sigma2}

\begin{itemize}
\tightlist
\item
  Independence \(\;\Rightarrow\;\) zero correlation.\\
\item
  So, an i.i.d. sequence automatically satisfies the white noise
  conditions (same mean, same variance, no correlation).
\end{itemize}

Therefore:

\[
IID(0, \sigma^2) \;\;\Rightarrow\;\; WN(0, \sigma^2).
\]

\subsection{4. Why not conversely?}\label{why-not-conversely}

The reverse is not always true, because \textbf{white noise only
requires uncorrelatedness, not full independence}.

That means a sequence could be white noise but still have dependence in
higher moments (nonlinear dependence).

\section{5. Example of WN but not IID}\label{example-of-wn-but-not-iid}

Let \(\{Z_t\}\) be i.i.d. \(N(0,1)\). Define

\[
X_t = Z_t \cdot Z_{t-1}.
\]

Then:

\begin{itemize}
\tightlist
\item
  \(\mathbb{E}[X_t] = 0\),\\
\item
  \(\mathrm{Var}(X_t) = 1\),\\
\item
  For \(t \neq s\), \(\mathrm{Cov}(X_t, X_s) = 0\). ‚úÖ So it's white
  noise.
\end{itemize}

But the sequence is \textbf{not independent} (because \(X_t\) depends on
\(Z_{t-1}\), which also appears in \(X_{t-1}\)).

Thus,

\[
X_t \sim WN(0,1) \quad \text{but not} \quad IID(0,1).
\]

\section{Simulation example}\label{simulation-example}

IID series

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}

\CommentTok{\# Parameters}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{200}        \CommentTok{\# length of series}
\NormalTok{sigma }\OtherTok{\textless{}{-}} \DecValTok{1}      \CommentTok{\# standard deviation}

\CommentTok{\# IID(0, sigma\^{}2) \textasciitilde{} Normal(0, sigma\^{}2)}
\NormalTok{iid\_seq }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(n, }\AttributeTok{mean =} \DecValTok{0}\NormalTok{, }\AttributeTok{sd =}\NormalTok{ sigma)}

\CommentTok{\# Quick check}
\FunctionTok{mean}\NormalTok{(iid\_seq)      }\CommentTok{\# should be \textasciitilde{}0}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] -0.008570445
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{var}\NormalTok{(iid\_seq)       }\CommentTok{\# should be \textasciitilde{}sigma\^{}2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.8895506
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{acf}\NormalTok{(iid\_seq)       }\CommentTok{\# autocorrelations \textasciitilde{} 0}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{03-chap3_files/figure-pdf/unnamed-chunk-5-1.pdf}}

White noise

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}

\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{200}
\NormalTok{Z }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(n, }\AttributeTok{mean =} \DecValTok{0}\NormalTok{, }\AttributeTok{sd =} \DecValTok{1}\NormalTok{)}

\CommentTok{\# Construct WN but not IID}
\NormalTok{wn\_not\_iid }\OtherTok{\textless{}{-}}\NormalTok{ Z[}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{] }\SpecialCharTok{*}\NormalTok{ Z[}\SpecialCharTok{{-}}\NormalTok{n]   }\CommentTok{\# X\_t = Z\_t * Z\_\{t{-}1\}, length n{-}1}

\CommentTok{\# Quick check}
\FunctionTok{mean}\NormalTok{(wn\_not\_iid)        }\CommentTok{\# \textasciitilde{}0}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] -0.05650406
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{var}\NormalTok{(wn\_not\_iid)         }\CommentTok{\# \textasciitilde{}1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0.8196189
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{acf}\NormalTok{(wn\_not\_iid)         }\CommentTok{\# uncorrelated {-}\textgreater{} ACF \textasciitilde{} 0}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{03-chap3_files/figure-pdf/unnamed-chunk-6-1.pdf}}

Side-by-side visualisation

\pandocbounded{\includegraphics[keepaspectratio]{03-chap3_files/figure-pdf/unnamed-chunk-7-1.pdf}}

\section{3. Random walk}\label{random-walk}

A random walk process is obtained by cumulatively summing iid random
variables. If \({S_t, t=0, 1, 2, ...}\) is a random walk process, then
\(S_0 =0\)

\(S_1=0+X_1\)

\(S_2=0+X_1+X_2\)

\(...\)

\(S_t=X_1+X_2+...+X_t.\)

\textbf{Question}

Is \({S_t, t=0, 1, 2, ...}\) a weak stationary process?

\section{Identifying non-stationarity in the
mean}\label{identifying-non-stationarity-in-the-mean}

\begin{itemize}
\item
  Using time series plot
\item
  ACF plot

  \begin{itemize}
  \item
    ACF of stationary time series will drop to relatively quickly.
  \item
    The ACF of non-stationary series decreases slowly.
  \item
    For non-stationary series, the ACF at lag 1 is often large and
    positive.
  \end{itemize}
\end{itemize}

\section{Backshift notation:}\label{backshift-notation}

\[BX_t=X_{t-1}\]

\section{Ordinary differencing}\label{ordinary-differencing}

The first-order differencing can be defined as

\[\nabla X_t = X_t-X_{t-1}=X_t-BX_t=(1-B)X_t\] where \(\nabla=1-B\).

The second-order differencing

\[\nabla^2X_t=\nabla(\nabla X_t)=\nabla(X_t-X_{t-1})=\nabla X_t - \nabla X_{t-1}\]

\[\nabla X_t - \nabla X_{t-1}=(X_t-X_{t-1})-(X_{t-1}-X_{t-2})\]

In practice, we seldom need to go beyond second order differencing.

\section{Seasonal differencing}\label{seasonal-differencing}

Differencing between an observation and the corresponding observation
from the previous year.

\[\nabla_mX_t=X_t-X_{t-m}=(1-B^m)X_t\] where \((m)\) is the number of
seasons. For monthly, \((m=12)\), for quarterly \((m=4)\).

For monthly series

\[\nabla_{12}X_t=X_t-X_{t-12}\]

\section{Twice-differenced series}\label{twice-differenced-series}

\[\nabla^2_{12}X_t=\nabla_{12}X_t-\nabla_{12}X_{t-1}\]
\[\nabla_{12}X_t-\nabla_{12}X_{t-1}=(X_t-X_{t-12})-(X_{t-1}-X_{t-13})\]
If seasonality is strong, the seasonal differencing should be done
first.

\section{Deterministic trend vs Stochastic
trend}\label{deterministic-trend-vs-stochastic-trend}

\subsection{Deterministic trend}\label{deterministic-trend}

\[Y_t  = f(t) + \epsilon_t\]

where \(\epsilon_t \sim iid(0, \sigma^2)\), \(t = 1, 2, ...T\)

Mean of the process is time dependent, but the variance of the process
is constant.

A trend is deterministic if it is a nonrandom function of time. A
deterministic trend is a predictable, fixed function of time. If you
know the form of the function, you can determine the trend exactly.

\subsection{Stochastic trend}\label{stochastic-trend}

A stochastic trend is driven by random shocks that accumulate over time.
A stochastic trend is driven by random shocks (also called innovations,
disturbances, or error terms) that accumulate over time.

\textbf{1. Random walk}

\[Y_t = Y_{t-1} + \epsilon_t\]

\begin{itemize}
\item
  Random walk has a stochastic trend.
\item
  Model behind naive method.
\end{itemize}

A trend is said to be stochastic if it is a random function of time.

\textbf{2. Random walk with drift}

\[Y_t = \alpha +  Y_{t-1} + \epsilon_t\]

\begin{itemize}
\item
  Random walk with drift has a stochastic trend and a deterministic
  trend.
\item
  Model behind drift method.
\end{itemize}

\section{Random walk}\label{random-walk-1}

\[
\begin{aligned}
  Y_t &= Y_{t-1} + \epsilon_t \\
     Y_1    &= Y_0 + \epsilon_1 \\
         Y_2 &=  Y_1 + \epsilon_2=Y_0 + \epsilon_1 + \epsilon_2\\
          Y_3 &=  Y_2 + \epsilon_3=Y_0 + \epsilon_1 + \epsilon_2 +\epsilon_3\\
          .   \\
          Y_t &=Y_{t-1} + \epsilon_t=Y_0 + \epsilon_1 + \epsilon_2 + \epsilon_3 +...+ \epsilon_t = Y_0 + \sum_{i=1}^{t} \epsilon_t
\end{aligned}
\]

Mean: \(E(Y_t) = Y_0\).

Variance: \(Var(Y_t)=t \sigma^2\).

\section{Random walk with drift}\label{random-walk-with-drift}

\[
\begin{aligned}
  Y_t &= \alpha + Y_{t-1} + \epsilon_t \\
     Y_1    &= \alpha+Y_0 + \epsilon_1 \\
         Y_2 &= \alpha+ Y_1 + \epsilon_2=2 \alpha+Y_0 + \epsilon_1 + \epsilon_2\\
          Y_3 &= \alpha+ Y_2 + \epsilon_3= 3 \alpha+ Y_0 + \epsilon_1 + \epsilon_2 +\epsilon_3\\
          .   \\
          Y_t &= \alpha+Y_{t-1} + \epsilon_t= t \alpha+ Y_0 + \epsilon_1 + \epsilon_2 + \epsilon_3 +...+ \epsilon_t \\
          Y_t &= t \alpha + Y_0 + \sum_{i=1}^{t} \epsilon_t
\end{aligned}
\]

It has a \emph{deterministic trend} \((Y_0 + t \alpha)\) and a
\emph{stochastic trend} \(\sum_{i=1}^{t} \epsilon_t\).

Mean: \(E(Y_t) = Y_0 + t\alpha\)

Variance: \(Var(Y_t) = t\sigma^2\).

There is a trend in both mean and variance.

\section{Common trend removal (de-trending)
procedures}\label{common-trend-removal-de-trending-procedures}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Deterministic trend: Time-trend regression

  The trend can be removed by fitting a deterministic polynomial time
  trend. The residual series after removing the trend will give us the
  de-trended series.
\item
  Stochastic trend: Differencing

  The process is also known as a \textbf{Difference-stationary process}.
\end{enumerate}

\section{Remove seasonality}\label{remove-seasonality}

Take seasonal differencing

\section{Example: Differencing on AirPassengers
Data}\label{example-differencing-on-airpassengers-data}

The built-in AirPassengers dataset (monthly airline passengers,
1949--1960) has trend + seasonality.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Load data}
\FunctionTok{data}\NormalTok{(}\StringTok{"AirPassengers"}\NormalTok{)}
\NormalTok{ts\_data }\OtherTok{\textless{}{-}}\NormalTok{ AirPassengers}

\CommentTok{\#par(mfrow = c(3,2))}

\CommentTok{\# 1. Original series}
\FunctionTok{plot}\NormalTok{(ts\_data, }\AttributeTok{main =} \StringTok{"Original Series"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"Passengers"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{03-chap3_files/figure-pdf/unnamed-chunk-8-1.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{acf}\NormalTok{(ts\_data, }\AttributeTok{main =} \StringTok{"ACF: Original Series"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{03-chap3_files/figure-pdf/unnamed-chunk-8-2.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# 2. First difference (remove trend)}
\NormalTok{diff1 }\OtherTok{\textless{}{-}} \FunctionTok{diff}\NormalTok{(ts\_data, }\AttributeTok{differences =} \DecValTok{1}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(diff1, }\AttributeTok{main =} \StringTok{"1st Difference (Remove Trend)"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"Difference"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{03-chap3_files/figure-pdf/unnamed-chunk-8-3.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{acf}\NormalTok{(diff1, }\AttributeTok{main =} \StringTok{"ACF: 1st Difference"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{03-chap3_files/figure-pdf/unnamed-chunk-8-4.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# 3. Seasonal difference (lag = 12, remove seasonality)}
\NormalTok{diff\_seasonal }\OtherTok{\textless{}{-}} \FunctionTok{diff}\NormalTok{(diff1, }\AttributeTok{lag =} \DecValTok{12}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(diff\_seasonal, }\AttributeTok{main =} \StringTok{"Seasonal Difference (Remove Seasonality)"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"Difference"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{03-chap3_files/figure-pdf/unnamed-chunk-8-5.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{acf}\NormalTok{(diff\_seasonal, }\AttributeTok{main =} \StringTok{"ACF: Seasonal Difference"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{03-chap3_files/figure-pdf/unnamed-chunk-8-6.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# 3. Seasonal difference (lag = 12, remove seasonality from the original series)}
\NormalTok{diff\_seasonal\_only }\OtherTok{\textless{}{-}} \FunctionTok{diff}\NormalTok{(ts\_data, }\AttributeTok{lag =} \DecValTok{12}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(diff\_seasonal\_only, }\AttributeTok{main =} \StringTok{"Seasonal Difference (Remove Seasonality)"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"Difference"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{03-chap3_files/figure-pdf/unnamed-chunk-8-7.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{acf}\NormalTok{(diff\_seasonal\_only, }\AttributeTok{main =} \StringTok{"ACF: Seasonal Difference"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{03-chap3_files/figure-pdf/unnamed-chunk-8-8.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{head}\NormalTok{(ts\_data, }\DecValTok{14}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec
1949 112 118 132 129 121 135 148 148 136 119 104 118
1950 115 126                                        
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{head}\NormalTok{(diff1, }\DecValTok{14}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec
1949       6  14  -3  -8  14  13   0 -12 -17 -15  14
1950  -3  11  15                                    
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{head}\NormalTok{(diff\_seasonal, }\DecValTok{14}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec
1950       5   1  -3  -2  10   8   0   0  -8  -4  12
1951   8  -6  13                                    
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{head}\NormalTok{(diff\_seasonal\_only, }\DecValTok{14}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec
1950   3   8   9   6   4  14  22  22  22  14  10  22
1951  30  24                                        
\end{verbatim}

\section{Notation: I(d)}\label{notation-id}

Integrated to order \(d\): Series can be made stationary by differencing
\(d\) times.

\begin{itemize}
\tightlist
\item
  Known as \(I(d)\) process.
\end{itemize}

\textbf{Question:} Show that random walk process is an \(I(1)\) process.

The random walk process is called a unit root process. (If one of the
roots turns out to be one, then the process is called unit root
process.)

\section{Variance stabilization}\label{variance-stabilization}

Transform the series.

Eg:

\begin{itemize}
\item
  Square root: \(W_t = \sqrt{Y_t}\)
\item
  Logarithm: \(W_t = log({Y_t})\)

  \begin{itemize}
  \item
    This very useful.
  \item
    Interpretable: Changes in a log value are \textbf{relative (percent)
    changes on the original sclae}.
  \end{itemize}
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{log\_ts }\OtherTok{\textless{}{-}} \FunctionTok{log}\NormalTok{(ts\_data)}
\FunctionTok{plot}\NormalTok{(log\_ts, }\AttributeTok{main =} \StringTok{"Log{-}Transformed Series"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"log(Passengers)"}\NormalTok{, }\AttributeTok{col =} \StringTok{"steelblue"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{03-chap3_files/figure-pdf/unnamed-chunk-10-1.pdf}}

\bookmarksetup{startatroot}

\chapter{Models For Stationary Time
Series}\label{models-for-stationary-time-series}

In this chapter we will discuss family of autoregressive moving average
(ARMA) time series models.

\section{General Linear Process}\label{general-linear-process}

A \textbf{linear process} is a time series written as an infinite linear
combination of random shocks \(\{\varepsilon_t\}\). These shocks are
randomly drawn from a fixed distribution, usually Normal and having mean
zero and variance \(\sigma^2_{\epsilon}\). Such a sequence is called a
white noise process.

\[X_t = \mu + \sum_{j=0}^{\infty} \psi_j \, \varepsilon_{t-j},\]

or

\[X_t = \mu + \Psi(B)\epsilon_t\]

where,

\(\mu\) is a parameter that determines the ``level'' of the process

\(\{\psi_j\}\) are coefficients (weights)

\(\varepsilon_t \sim \text{i.i.d. } (0, \sigma^2_\epsilon)\) are white
noise shocks.

\(\Psi(B)\) is the linear operator that transforms \(\epsilon_t\) into
\(X_t\). This is called transfer function or linear filter.

\section{Moving Average Processes}\label{moving-average-processes}

If only finitely many coefficients \(\psi_j\) are nonzero, say up to lag
\(q\), then we have an MA(\(q\)) process:

\[X_t = \mu + \varepsilon_t + \theta_1 \varepsilon_{t-1} + \dots + \theta_q \varepsilon_{t-q},\]

where:

\begin{itemize}
\item
  \(\mu\) is the mean,
\item
  \(\varepsilon_t \sim \text{i.i.d. }(0, \sigma^2)\) are white noise
  shocks,
\item
  \(\theta_1, \dots, \theta_q\) are the MA coefficients.
\end{itemize}

So we can write:

\[\text{MA}(q) \subset \text{Linear Process}.\]

\section{Autoregressive Processes}\label{autoregressive-processes}

\(Y_t = \alpha + \phi_1 Y_{t-1} + \phi_2 Y_{t-2} + \dots + \phi_p Y_{t-p} + \epsilon_t\)

Where:

\(Y_t\) is the value at time \(t\)

\(\alpha\) is a constant,

\(\phi_1, \phi_2,...\phi_p\) are the parameters,

\(\epsilon_t\) is white noise (error term),

\(p\) is the order of the AR model.

\section{AR processes are also just special cases of the general linear
process}\label{ar-processes-are-also-just-special-cases-of-the-general-linear-process}

If the AR process is causal (i.e., roots of the characteristic
polynomial lie outside the unit circle), then it can be written as an
infinite linear process:

\[X_t = \sum_{j=0}^{\infty} \psi_j \, \varepsilon_{t-j},\]

where:

\begin{itemize}
\item
  \(\varepsilon_t \sim \text{i.i.d. }(0, \sigma^2)\) are white noise
  shocks,
\item
  \(\psi_j\) are coefficients determined from the AR parameters.
\end{itemize}

\subsection{AR(p) Process as an Infinite Linear Process Using Backshift
Operator}\label{arp-process-as-an-infinite-linear-process-using-backshift-operator}

Start with the AR(p) process:

\[X_t = \phi_1 X_{t-1} + \phi_2 X_{t-2} + \dots + \phi_p X_{t-p} + \varepsilon_t,\]

where \(\varepsilon_t \sim \text{i.i.d. }(0, \sigma^2)\) are white noise
shocks.

\subsubsection{1. Define the backshift operator
(B)}\label{define-the-backshift-operator-b}

\[B X_t = X_{t-1}, \quad B^2 X_t = X_{t-2}, \dots, B^p X_t = X_{t-p}.\]

\subsubsection{2. Rewrite the AR(p) process using
(B)}\label{rewrite-the-arp-process-using-b}

\[X_t - \phi_1 B X_t - \phi_2 B^2 X_t - \dots - \phi_p B^p X_t = \varepsilon_t\]

Factor out \(X_t\):

\[(1 - \phi_1 B - \phi_2 B^2 - \dots - \phi_p B^p) X_t = \varepsilon_t\]

Define the AR polynomial:

\[\phi(B) = 1 - \phi_1 B - \phi_2 B^2 - \dots - \phi_p B^p\]

Then the AR(p) process becomes:

\[\phi(B) X_t = \varepsilon_t\]

\subsubsection{3. Express as an infinite linear
process}\label{express-as-an-infinite-linear-process}

If the AR process is \textbf{causal} (roots of \(\phi(z)=0\) lie outside
the unit circle), we can invert the operator:

\[X_t = \phi(B)^{-1} \varepsilon_t\]

Expanding gives:

\[X_t = \sum_{j=0}^{\infty} \psi_j \, \varepsilon_{t-j},\]

where the coefficients \(\psi_j\) are determined recursively from the AR
parameters \(\phi_1, \dots, \phi_p\).

This shows that causal AR processes are \textbf{special cases of the
general linear process}.

\section{In-class: Properties of AR(1)
process}\label{in-class-properties-of-ar1-process}

Derive

\begin{itemize}
\item
  Mean
\item
  Variance
\item
  Covariance
\item
  Autocorrelation function of an AR(1) process
\end{itemize}

\section{In-class: Properties of AR(2)
process}\label{in-class-properties-of-ar2-process}

Derive

\begin{itemize}
\item
  Mean
\item
  Variance
\item
  Covariance
\item
  Autocorrelation function of an AR(1) process
\end{itemize}

\section{In-class: Properties of AR(P)
process}\label{in-class-properties-of-arp-process}

Derive

\begin{itemize}
\item
  Mean
\item
  Variance
\item
  Covariance
\item
  Autocorrelation function of an AR(P) process
\end{itemize}

\section{Properties of AR(1) model}\label{properties-of-ar1-model}

Consider the following \(AR(1)\) model.

\begin{equation}
Y_t=\phi_0+\phi_1Y_{t-1}+\epsilon_{t}
\end{equation}

where \({\epsilon_t}\) is assumed to be a white noise process with mean
zero and variance \(\sigma^2\).

\subsection{Mean}\label{mean}

Assuming that the series is weak stationary, we have \(E(Y_t)=\mu\),
\(Var(Y_t)=\gamma_0\), and \(Cov(Y_t, Y_{t-k})=\gamma_k\), where \(\mu\)
and \(\gamma_0\) are constants. Given that \({\epsilon_t}\) is a white
noise, we have \(E(\epsilon_t)=0\). The mean of \(AR(1)\) process can be
computed as follows:

\[
\begin{aligned}
  E(Y_t) &= E(\phi_0+\phi_1 Y_{t-1}) \\
         &= E(\phi_0) +E(\phi_1 Y_{t-1}) \\
         &= \phi_0 +\phi_1 E(Y_{t-1}). \\
\end{aligned}
\]

Under the stationarity condition, \(E(Y_t)=E(Y_{t-1})=\mu\). Thus we get

\[\mu = \phi_0+\phi_1\mu.\]

Solving for \(\mu\) yields

\begin{equation}
E(Y_t)=\mu=\frac{\phi_0}{1-\phi_1}.
\end{equation}

The results has two constraints for \(Y_t\). First, the mean of \(Y_t\)
exists if \(\phi_1 \neq 1 .\) The mean of \(Y_t\) is zero if and only if
\(\phi_0=0\).

\subsection{Variance and the stationary condition of AR (1)
process}\label{variance-and-the-stationary-condition-of-ar-1-process}

First take variance of both sides of Equation (1)

\[Var(Y_t)=Var(\phi_0+\phi_1 Y_{t-1}+\epsilon_t)\]

The \(Y_{t-1}\) occurred before time \(t\). The \(\epsilon_t\) does not
depend on any past observation. Hence, \(cov(Y_{t-1}, \epsilon_t)= 0\).
Furthermore, \({\epsilon_t}\) is a white noise. This gives

\[Var(Y_t)=\phi_1^2 Var(Y_{t-1})+\sigma^2.\]

Under the stationarity condition, \(Var(Y_t)=Var(Y_{t-1})\). Hence,

\[Var(Y_t)=\frac{\sigma^2}{1-\phi_1^2}.\]

provided that \(\phi_1^2 < 1\) or \(|\phi_1| < 1\) (The variance of a
random variable is bounded and non-negative). The necessary and
sufficient condition for the \(AR(1)\) model in Equation (1) to be
weakly stationary is \(|\phi_1| < 1\). This condition is equivalent to
saying that the root of \(1-\phi_1B = 0\) must lie outside the unit
circle. This can be explained as below

Using the backshift notation we can write \(AR(1)\) process as

\[Y_t = \phi_0 + \phi_1BY_{t} + \epsilon_t.\]

Then we get

\[(1-\phi_1B)Y_t=\phi_0 + \epsilon_t.\] The \(AR(1)\) process is said to
be stationary if the roots of \((1-\phi_1B)=0\) lie outside the unit
circle.

\subsection{Covariance}\label{covariance}

The covariance \(\gamma_k=Cov(Y_t, Y_{t-k})\) is called the lag-\(k\)
autocovariance of \(Y_t\). The two main properties of \(\gamma_k\): (a)
\(\gamma_0=Var(Y_t)\) and (b) \(\gamma_{-k}=\gamma_{k}\).

The lag-\(k\) autocovariance of \(Y_t\) is

\begin{equation}
\begin{aligned}
  \gamma_k &= Cov(Y_t, Y_{t-k}) \\
         &= E[(Y_t-\mu)(Y_{t-k}-\mu)] \\
         &= E[Y_tY_{t-k}-Y_t\mu-\mu Y_{t-k} +\mu^2] \\
         &= E(Y_t Y_{t-k}) - \mu^2. \\
\end{aligned}
\end{equation}

Now we have

\begin{equation}
  E(Y_t Y_{t-k}) = \gamma_k + \mu^2
\end{equation}

\subsection{Autocorrelation function of an AR(1)
process}\label{autocorrelation-function-of-an-ar1-process}

To derive autocorrelation function of an AR(1) process we first multiply
both sides of Equation (1) by \(Y_{t-k}\) and take expected values:

\[E(Y_tY_{t-k})=\phi_0E(Y_{t-k})+\phi_1 E(Y_{t-1}Y_{t-k})+E(\epsilon_tY_{t-k})\]
Since \(\epsilon_t\) and \(Y_{t-k}\) are independent and using the
results in Equation \textbf{?@eq-3}

\[\gamma_k + \mu^2 = \phi_0 \mu+\phi_1(\gamma_{k-1}+\mu^2)\]

Substituting the results in Equation (2) to Equation (3) we get

\begin{equation}
\gamma_k = \phi_1 \gamma_{k-1}.
\end{equation}

The autocorrelation function, \(\rho_k\), is defined as

\[\rho_k = \frac{\gamma_k}{\gamma_0}\].

Setting \(k=1\), we get \(\gamma_1 = \phi_1\gamma_0.\) Hence,

\[\rho_1=\phi_1.\]

Similarly with \(k=2\), \(\gamma_2 = \phi_1 \gamma_1\). Dividing both
sides by \(\gamma_0\) and substituting with \(\rho_1=\phi_1\) we get

\[\rho_2=\phi_1^2.\]

Now it is easy to see that in general

\begin{equation}
\rho_k = \frac{\gamma_k}{\gamma_0}=\phi_1^k 
\end{equation}

for \(k=0, 1, 2, 3, ...\).

Since \(|\phi_1| < 1,\) the autocorrelation function is an exponentially
decreasing as the number of lags \(k\) increases. There are two features
in the ACF of AR(1) process depending on the sign of \(\phi_1\). They
are,

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  If \(0 < \phi_1 < 1,\) all correlations are positive.
\item
  if \(-1 < \phi_1 < 0,\) the lag 1 autocorrelation is negative
  (\(\rho_1=\phi_1\)) and the signs of successive autocorrelations
  alternate from positive to negative with their magnitudes decreasing
  exponentially.
\end{enumerate}

\section{Properties of AR(2) model}\label{properties-of-ar2-model}

Now consider a second-order autoregressive process (AR(2))

\begin{equation}
Y_t=\phi_0+\phi_1Y_{t-1}+\phi_2Y_{t-2}+\epsilon_t.
\end{equation}

\subsection{Mean}\label{mean-1}

\textbf{Question 1:} Using the same technique as that of the AR(1), show
that

\[E(Y_t) = \mu = \frac{\phi_0}{1-\phi_1 - \phi_2}\] and the mean of
\(Y_t\) exists if \(\phi_1 + \phi_2 \neq 1\).

\subsection{Variance}\label{variance}

\textbf{Question 2:} Show that
\[Var(Y_t) = \frac{(1-\phi_2)\sigma^2}{(1+\phi_2)((1+\phi_2)^2-\phi_1^2)}.\]

Here is a guide to the solution

Start with

\[Var(Y_t)=Var(\phi_0+\phi_1Y_{t-1}+\phi_2Y_{t-2}+\epsilon_t)\]

Solve it until you obtain the Eq. (a) as shown below.

\begin{equation}
\gamma_0 (1-\phi_1^2 - \phi_2^2) = 2\phi_1\phi_2\gamma_1+\sigma^2.
\end{equation}

Next multiply both sides of Equation 7 by \(Y_{t-1}\) and obtain an
expression for \(\gamma_1\). Let's call this Eq. (b).

Solve Eq. (a) and (b) for \(\gamma_0.\)

\subsection{Stationarity of AR(2)
process}\label{stationarity-of-ar2-process}

To discuss the stationarity condition of the \(AR(2)\) process we use
the roots of the characteristic polynomial. Here is the illustration.

Using the backshift notation we can write \(AR(2)\) process as

\[Y_t = \phi_0 + \phi_1 BY_{t} + \phi_2 B^2 Y_{t} + \epsilon_t.\]

Furthermore, we get

\[(1-\phi_1 B - \phi_2 B^2) Y_t = \phi_0 + \epsilon_t.\]

The \textbf{characteristic polynomial} of \(AR(2)\) process is

\[\Phi(B)=1-\phi_1 B - \phi_2 B^2.\]

and the corresponding \textbf{AR characteristic equation}

\[1-\phi_1 B - \phi_2 B^2=0.\]

For stationarity, the roots of AR characteristic equation must lie
outside the unit circle. The two roots of the AR characteristic equation
are

\[\frac{\phi_1 \pm \sqrt{\phi_1^2 + 4\phi_2}}{-2\phi_2}\]

Using algebraic manipulation, we can show that these roots will exceed 1
in modulus if and only if simultaneously \(\phi_1 + \phi_2 < 1,\)
\(\phi_2-\phi_1 < 1,\) and \(|\phi_2| < 1.\) This is called the
stationarity condition of \(AR(2)\) process.

\subsection{Autocorrelation function of an AR(2)
process}\label{autocorrelation-function-of-an-ar2-process}

To derive autocorrelation function of an AR(2) process we first multiply
both sides of Equation 7 by \(Y_{t-k}\) and take expected values:

\begin{align}
E(Y_tY_{t-k}) &= E(\phi_0Y_{t-k}+\theta_1Y_{t-1}Y_{t-k}+\theta_2Y_{t-2}Y_{t-k})+\epsilon_tY_{t-k} \\
&= \phi_0 E(Y_{t-k})+\phi_{1}E(Y_{t-1}Y_{t-k}) + \phi_2 E(Y_{t-2} Y_{t-k}) + E(\epsilon_tY_{t-k}).
\end{align}

Using the independence between \(\epsilon_t\) and \(Y_{t-1}\),
\(E(\epsilon_t Y_{t-k})=0\) and the results in Equation 4 (This is valid
for AR(2)) we have

\[\gamma_k + \mu^2 = \gamma_0 \mu + \theta_1 (\gamma_{k-1}+\mu^2)+\phi_2 (\gamma_{k-2}+\mu^2).\]

(Note that \(E(X_{t-1}X_{t-k})=E(X_{t-1}X_{(t-1)-(k-1)}=\gamma_{k-1})\))

Solving for \(\gamma_k\) we get

\begin{align}
 \gamma_k=\phi_1\gamma_{k-1}+\phi_2\gamma_{k-2}.
\end{align}

By dividing the both sides of Equation 10 by \(\gamma_0\), we have

\begin{align}
 \rho_k=\phi_1\rho_{k-1}+\phi_2\rho_{k-2}.
\end{align}

for \(k>0\).

Setting \(k=1\) and using \(\rho_0=1\) and \(\rho_{-1}=\rho_1\), we get
\textbf{the Yule-Walker equation for \(AR(2)\) process.}

\[\rho_1=\phi_1+\phi_2 \rho_1\] or

\[\rho_1 = \frac{\phi_1}{1-\phi_2}.\]

Similarly, we can show that

\[\rho_2 = \frac{\phi_2(1-\phi_2)+\phi_1^2}{(1-\phi_2)}.\]

\section{Properties of AR(p) model}\label{properties-of-arp-model}

The \(p\)th order autoregressive model can be written as

\begin{align}
Y_t = \phi_0 + \phi_1Y_{t-1}+\phi_2 Y_{t-2}+ ... + \phi_p Y_{t-p}+\epsilon_t.
\end{align}

The AR characteristic equation is

\[1-\phi_1B-\phi_2B^2-...-\phi_pB^p=0.\]

For stationarity of \(AR(p)\) process, the \(p\) roots of the AR
characteristic must lie outside the unit circle.

\subsection{Mean}\label{mean-2}

\textbf{Question 3: } Find \(E(Y_t)\) of \(AR(p)\) process.

\subsection{Variance}\label{variance-1}

\textbf{Question 4: } Find \(Var(Y_t)\) of \(AR(p)\) process.

\subsection{Autocorrelation function (ACF) of an AR(p)
process}\label{autocorrelation-function-acf-of-an-arp-process}

\textbf{Question 5: } Similar to the results in Equation 12 for
\(AR(2)\) process, obtain the following recursive relationship for
\(AR(p)\).

\begin{align}
\rho_k = \phi_1\rho_{k-1}+\phi_2 \rho_{k-2} + ... + \phi_p \rho_{k-p}.
\end{align}

Setting \(k=1, 2, ..., p\) into Equation 14 and using \(\rho_0=1\) and
\(\rho_{-k}=\rho_k\), we get the Yule-Walker equations for \(AR(p)\)
process

\begin{equation}
\begin{aligned}
  \rho_1 &= \phi_1+\phi_2 \rho_{1} + ... + \phi_p \rho_{p-1}\\
  \rho_2 &= \phi_1 \rho_1+\phi_2  + ... + \phi_p \rho_{p-2}\\
  ... \\
  \rho_p &= \phi_1 \rho_{p-1} +\phi_2 \rho_{p-2}  + ... + \phi_p \\
\end{aligned}
\end{equation}

The Yule-Walker equations in 14 can be written in matrix form as below.

\[\left[\begin{array}
{r}
\rho_1  \\
\rho_2  \\
.\\
.\\
.\\
\rho_p
\end{array}\right] = \left[\begin{array}
{rrrrrrr}
1 & \rho_1 & \rho_2 & .&.&.& \rho_{p-1} \\
\rho_1 & 1 & \rho_1 & .&.&.& \rho_{p-2} \\
. & . & . & .&.&.& . \\
. & . & . & .&.&.& . \\
. & . & . & .&.&.& . \\
\rho_{p-1} & \rho_{p-2} & \rho_{p-3} & .&.&.& 1 \\
\end{array}\right] \left[\begin{array}
{r}
\phi_1  \\
\phi_2  \\
.\\
.\\
.\\
\phi_p
\end{array}\right]
\]

or

\[\bm{\rho_p}=\bm{P_p\phi}.\]

where,

\[\bm{\rho_p} = \left[\begin{array}
{r}
\rho_1  \\
\rho_2  \\
.\\
.\\
.\\
\rho_p
\end{array}\right], \bm{P_p} = \left[\begin{array}
{rrrrrrr}
1 & \rho_1 & \rho_2 & .&.&.& \rho_{p-1} \\
\rho_1 & 1 & \rho_1 & .&.&.& \rho_{p-2} \\
. & . & . & .&.&.& . \\
. & . & . & .&.&.& . \\
. & . & . & .&.&.& . \\
\rho_{p-1} & \rho_{p-2} & \rho_{p-3} & .&.&.& 1 \\
\end{array}\right], \bm{\phi} = \left[\begin{array}
{r}
\phi_1  \\
\phi_2  \\
.\\
.\\
.\\
\phi_p
\end{array}\right]\]

The parameters can be estimated using

\[\bm{\phi}=\bm{P_p^{-1}\rho_p}.\]

\textbf{Question 6:} Obtain the parameters of an \(AR(3)\) process whose
first autocorrelations are \(\rho_1=0.9\); \(\rho_2=0.9\);
\(\rho_3=0.5\). Is the process stationary?

\section{The partial autocorrelation function
(PACF)}\label{the-partial-autocorrelation-function-pacf}

Let \(\phi_{ki}\), the \(j\)th coefficient in an \(AR(k)\) model. Then,
\(\phi_{kk}\) is the last coefficient. From Equation
\textbf{?@eq-yulep}, the \(\phi_{kj}\) satisfy the set of equations

\begin{equation}
\rho_j=\phi_{k1}\rho_{j-1}+...+\phi_{k(k-1)}\rho_{j-k+1}+\phi_{kk}\rho_{j-k},
\end{equation}

for \(j=1, 2, ...k\), leading to the Yule-Walker equations which may be
written

\begin{equation}
\left[\begin{array}
{r}
\rho_1  \\
\rho_2  \\
.\\
.\\
.\\
\rho_k
\end{array}\right] = \left[\begin{array}
{rrrrrrr}
1 & \rho_1 & \rho_2 & .&.&.& \rho_{k-1} \\
\rho_1 & 1 & \rho_1 & .&.&.& \rho_{k-2} \\
. & . & . & .&.&.& . \\
. & . & . & .&.&.& . \\
. & . & . & .&.&.& . \\
\rho_{k-1} & \rho_{k-2} & \rho_{k-3} & .&.&.& 1 \\
\end{array}\right] \left[\begin{array}
{r}
\phi_{k1}  \\
\phi_{k2}  \\
.\\
.\\
.\\
\phi_{kk}
\end{array}\right]
\end{equation}

or

\[\bm{\rho_k}=\bm{P_k\phi_k}.\]

where

\[\bm{\rho_k} = \left[\begin{array}
{r}
\rho_1  \\
\rho_2  \\
.\\
.\\
.\\
\rho_k
\end{array}\right], \bm{P_k} =\left[\begin{array}
{rrrrrrr}
1 & \rho_1 & \rho_2 & .&.&.& \rho_{k-1} \\
\rho_1 & 1 & \rho_1 & .&.&.& \rho_{k-2} \\
. & . & . & .&.&.& . \\
. & . & . & .&.&.& . \\
. & . & . & .&.&.& . \\
\rho_{k-1} & \rho_{k-2} & \rho_{k-3} & .&.&.& 1 \\
\end{array}\right], \bm{\phi_k} = \left[\begin{array}
{r}
\phi_{k1}  \\
\phi_{k2}  \\
.\\
.\\
.\\
\phi_{kk}
\end{array}\right]\]

For each \(k\), we compute the coefficients \(\phi_{kk}\). Solving the
equations for \(k=1, 2, 3...\) successively, we obtain

For \(k=1\),

\begin{equation}
\phi_{11}=\rho_1.
\end{equation}

For \(k=2\),

\begin{equation}
\phi_{22}=\frac{\left[\begin{array}
{rr}
1 & \rho_2  \\
\rho_1 & \rho_2  \\
\end{array}\right]}{\left[\begin{array}
{rr}
1 & \rho_1  \\
\rho_1 & 1  \\
\end{array}\right]} = \frac{\rho_2-\rho_1^2}{1-\rho_1^2}
\end{equation}

For \(k=3\),

\begin{equation}
\phi_{33}=\frac{\left[\begin{array}
{rrr}
1 & \rho_1 & \rho_1  \\
\rho_1 & 1 & \rho_2  \\
\rho_2 & \rho_1 & \rho_3  \\
\end{array}\right]}{\left[\begin{array}
{rrr}
1 & \rho_1 & \rho_2  \\
\rho_1 & 1 & \rho_1  \\
\rho_2 & \rho_1 & 1  \\
\end{array}\right]}
\end{equation}

The quantity \(\phi_{kk}\) is called the partial autocorrelation at lag
\(k\) and can be defined as
\[\phi_{kk}=Corr(Y_tY_{t-k}|Y_{t-1}, Y_{t-2},..., Y_{t-k+1}).\] The
partial autocorrelation between \(Y_t\) and \(Y_{t-k}\) is the
correlation between \(Y_t\) and \(Y_{t-k}\) after removing the effect of
the intermediate variables \(Y_{t-1}, Y_{t-2}, ..., Y_{t-k+1}\).

In general the determinant in the numerator of Equations 18, 19 and 20
has the same elements as that in the denominator, but replacing the last
column with \(\bm{\rho_k}= (\rho_1, \rho_2,...\rho_k).\)

\subsection{PACF for AR(1) models}\label{pacf-for-ar1-models}

From Equation 6 we have

\(\rho_k=\phi_1^k\) for \(k=0, 1, 2, 3,...\)

Hence, for \(k=1\), the first partial autocorrelation coefficient is

\[\phi_{11}=\rho_1=\phi_1.\] From 19 for \(k=2\), the second partial
autocorrelation coefficient is

\[\phi_{22}=\frac{\rho_2-\rho_1^2}{1-\rho_1^2}=\frac{\phi_1^2-\phi_1^2}{1-\phi_1^2} = 0\].

Similarly, for \(AR(1)\) we can show that \(\phi_{kk}=0\) for all
\(k > 0\). Hence, for \(AR(1)\) process the partial autocorrelation is
non-zero for lag \(1\) which is the order of the process, but is zero
for lags beyond the order 1.

\subsection{PACF for AR(2) model}\label{pacf-for-ar2-model}

\textbf{Question 7:} For \(AR(2)\) process show that \(\phi_{kk}=0\) for
all \(k>2\). Sketch the PACF of \(AR(2)\) process.

\subsection{PACF for AR(P) model}\label{pacf-for-arp-model}

In general for \(AR(p)\) precess, the partial autocorrelation function
\(\phi_{kk}\) is non-zero for \(k\) less than or equal to \(p\) (the
order of the process) and zero for all \(k\) greater than \(p\). In
other words, the partial autocorrelation function of a \(AR(p)\) process
has a cut-off after lag \(p\).

\section{Moving average (MA) models}\label{moving-average-ma-models}

We first derive the properties of \(MA(1)\) and \(MA(2)\) models and
then give the results for the general \(MA(q)\) model.

\section{Properties of MA(1) model}\label{properties-of-ma1-model}

The general form for \(MA(1)\) model is

\begin{equation}
Y_t = \theta_0 + \theta_1 \epsilon_{t-1} + \epsilon_t
\end{equation}

where \(\theta_0\) is a constant and \({\epsilon_t}\) is a white noise
series.

\subsection{Mean}\label{mean-3}

\textbf{Question 8:} Show that \(E(Y_t) = \theta_0\).

\subsection{Variance}\label{variance-2}

\textbf{Question 9:} Show that \(Var(Y_t) = (1+\theta_1^2)\sigma^2\).

We can see both mean and variance are time-invariant. \(MA\) models are
finite linear combinations of a white noise sequence. Hence, \(MA\)
processes are always weakly stationary.

\subsection{Autocorrelation function of an MA(1)
process}\label{autocorrelation-function-of-an-ma1-process}

\subsubsection{Method 1}\label{method-1}

To obtain the autocorrelation function of \(MA(1)\), we first multiply
both sides of Equation 21 by \(Y_{t-k}\) and take the expectation.

\begin{equation}
\begin{aligned}
E[Y_tY_{t-k}] &= E[\theta_0 Y_{t-k} + \theta_1 \epsilon_{t-1} Y_{t-k} + \epsilon_t Y_{t-k}]\\
&= \theta_0 E(Y_{t-k}) + \theta_1 E(\epsilon_{t-1}Y_{t-k}) + E(\epsilon_t Y_{t-k})\\
\end{aligned}
\end{equation}

Using the independence between \(\epsilon_t\) and \(Y_{t-k}\) (future
error and past observation) \(E(\epsilon_t Y_{t-k}) = 0\). Now we have

\begin{equation}
E[Y_tY_{t-k}] = \theta_0^2  + \theta_1 E(\epsilon_{t-1}Y_{t-k}) 
\end{equation}

Now let's obtain an expression for \(E[Y_t Y_{t-k}]\).

\begin{equation}
\begin{aligned}
  \gamma_k &= Cov(Y_t, Y_{t-k}) \\
         &= E[(Y_t-\theta_0)(Y_{t-k}-\theta_0)] \\
         &= E[Y_tY_{t-k}-Y_t\theta_0-\theta_0 Y_{t-k} +\theta_0^2] \\
         &= E(Y_t Y_{t-k}) - \theta_0^2. \\
\end{aligned}
\end{equation}

Now we have

\begin{equation}
  E(Y_t Y_{t-k}) = \gamma_k + \theta_0^2.
\end{equation}

Using the Equations 23 and 25 we have

\begin{equation}
  \gamma_k = \theta_0^2 - \theta_0^2 + \theta_1E(\epsilon_{t-1}Y_{t-k}).
\end{equation}

Now let's consider the case \(k=1\).

\begin{equation}
  \gamma_1 = \theta_0^2 - \theta_0^2 + \theta_1E(\epsilon_{t-1}Y_{t-1})
\end{equation}

Today's error and today's value are dependent. Hence,
\(E(\epsilon_{t-1}Y_{t-1}) \neq 0.\) We first need to identify
\(E(\epsilon_{t-1}Y_{t-1})\).

\begin{equation}
\begin{aligned}
E(\epsilon_{t-1}Y_{t-1}) &= E(\theta_0 \epsilon_{t-1} + \theta_1 \epsilon_{t-2} \epsilon_{t-1}+ \epsilon_{t-1}^2)\\
\end{aligned}
\end{equation}

Since, \{\(\epsilon_t\)\} is a white noise process
\(E(\epsilon_{t-1}) = 0\) and \(E(\epsilon_{t-2} \epsilon_{t-1}) = 0\).
Hence, we have

\begin{equation}
\begin{aligned}
E(\epsilon_{t-1}Y_{t-1}) &= E(\epsilon_{t-1}^2)=\sigma^2\\
\end{aligned}
\end{equation}

Substituting \textbf{?@eq-covma5} in \textbf{?@eq-covma3} we get

\[\gamma_1=\theta_1\sigma^2\].

Furthermore, \(\gamma_0 = Var(Y_t)=  (1+\theta_1^2)\sigma^2\). Hence

\[\rho_1=\frac{\gamma_1}{\gamma_0}=\frac{\theta}{1+\theta_1^2}.\]

When \(k=2\), from Equation \textbf{?@eq-covma3} and
\(E(\epsilon_{t-1}Y_{k-2}) = 0\) (future error and past observation) we
get \(\gamma_2=0\). Hence \(\rho_2=0\). Similarly, we can show that

\[\gamma_k = \rho_k=0\] for all \(k \geq 2\).

We can see that the ACF of \(MA(1)\) process is zero, beyond the order
of 1 of the process.

\subsubsection{Method 2: By using the definition of
covariance}\label{method-2-by-using-the-definition-of-covariance}

\begin{equation}
\begin{aligned}
\gamma_1 = Cov(Y_t, Y_{t-1}) &= Cov(\epsilon_t + \theta_1 \epsilon_{t-1}+ \theta_0, \epsilon_{t-1}+\theta_1 \epsilon_{t-2} + \theta_0)\\
&=Cov(\theta_1 \epsilon_{t-1}, \epsilon_{t-1})\\
&=\theta_1 \sigma^2.
\end{aligned}
\end{equation}

\begin{equation}
\begin{aligned}
\gamma_2=Cov(Y_t, Y_{t-2}) &= Cov(\epsilon_t + \theta_1 \epsilon_{t-1}+ \theta_0, \epsilon_{t-2}+\theta_1 \epsilon_{t-3} + \theta_0)\\
&=0.
\end{aligned}
\end{equation}

We have \(\gamma_0=\sigma^2(1+\theta_1^2)\), (Using the variance).

Hence

\[\rho_1=\frac{\gamma_1}{\gamma_0}=\frac{\theta_1}{1+\theta_1^2}.\]

Similarly we can show \(\gamma_k=\rho_k=0\) for all \(k \geq 2\).

\section{Properties of MA(2) model}\label{properties-of-ma2-model}

An \(MA(2)\) model is in the form

\begin{equation}
Y_t = \theta_0 + \theta_1 \epsilon_{t-1} + \theta_2 \epsilon_{t-2} + \epsilon_t
\end{equation}

where \(\theta_0\) is a constant and \({\epsilon_t}\) is a white noise
series.

\subsection{Mean}\label{mean-4}

\textbf{Question 10: } Show that \(E(Y_t) = \theta_0.\)

\subsection{Variance}\label{variance-3}

\textbf{Question 11: } Show that
\(Var(Y_t) = \sigma^2 (1+\theta_1^2 + \theta_2^2).\)

\subsection{Autocorrelation function of an MA(2)
process}\label{autocorrelation-function-of-an-ma2-process}

\textbf{Question 12: }For \(MA(2)\) process show that,

\[\rho_1=\frac{\theta_1(1+\theta_2)}{1+\theta_1^2+\theta_2^2},\]
\[\rho_2 = \frac{\theta_2}{1+\theta_1^2 + \theta_2^2},\]

and \(\rho_k=0\) for all \(k \geq 3.\)

\section{Properties of MA(q) model}\label{properties-of-maq-model}

\begin{equation}
Y_t = \theta_0 + \theta_1 \epsilon_{t-1} + \theta_2 \epsilon_{t-2} +...+ \theta_q \epsilon_{t-q} +\epsilon_t
\end{equation}

where \(\theta_0\) is a constant and \({\epsilon_t}\) is a white noise
series.

\subsection{Mean}\label{mean-5}

\textbf{Question 13:} Show that the constant term of an \(MA\) model is
the mean of the series (i.e.~\(E(Y_t)=\theta_0\)).

\subsection{Variance}\label{variance-4}

\textbf{Question 14:} Show that the variance of an \(MA\) model is
\[Var(Y_t)=(1+\theta_1^2+\theta_2^2+...+\theta_q^2)\sigma^2.\]

\subsection{Autocorrelation function of an MA(q)
process}\label{autocorrelation-function-of-an-maq-process}

\textbf{Question 15:} Show that the autocorrelation function of a
\(MA(q)\) process is zero, beyond the order of \(q\) of the process. In
other words, the autocorrelation function of a moving average process
has a cutoff after lag \(q\).

\section{Partial autocorrelation function of an MA(q)
process}\label{partial-autocorrelation-function-of-an-maq-process}

The partial autocorrelation functions for \(MA(q)\) models behave very
much like the autocorrelation functions of \(AR(p)\) models. The PACF of
\(MA\) models decays exponentially to zero, rather like ACF for \(AR\)
model.

\section{Dual relation between AR and MA
process}\label{dual-relation-between-ar-and-ma-process}

\textbf{Dual relation 1}

\textbf{First we consider the relation AR(p) \textless--\textgreater{}
MA(}\(\infty\)\textbf{)}

Let \(AR(p)\) be a \textbf{stationary} \(AR\) model with order \(p\).
Then,

\[Y_t = \phi_1Y_{t-1}+ \phi_2Y_{t-2}+...+ \phi_pY_{t-p}+\epsilon_t,\]
where \(\epsilon_t \sim WN(0, \sigma^2).\)

Using the backshift operator we can write the \(AR(p)\) model as

\[(1-\phi_1B-\phi_2B^2-...-\phi_pB^P)Y_t=\epsilon_t.\] Then

\[\phi(B)Y_t=\epsilon_t,\] where
\(\phi(B)=1-\phi_1B-\phi_2B^2-...-\phi_pB^p.\) Furthermore, \(Y_t\) can
be written as infinite sum of previous \(\epsilon\)'s as below

\[Y_t = \phi^{-1}(B)\epsilon_t,\] where \(\phi(B)\psi(B)=1\) and
\(\psi(B)=1+\Psi_1B+\psi_2B^2+...\) Then \[Y_t=\psi(B)\epsilon_t.\] This
is a representation of \(MA(\infty)\) process.

\textbf{Next, we consider the relation MA(q) \textless--\textgreater{}
AR(}\(\infty\)\textbf{)}

Let \(MA(q)\) be \textbf{invertible} moving average process

\[Y_t = \epsilon_t + \theta_t\epsilon_{t-1}+\theta_2\epsilon_{t-2}+...+\theta_p\epsilon_{t-q}.\]

Using the backshift operator we can write the \(MA(q)\) process as

\[Y_t = (1+\theta_1B+\theta_2B^2-...+\theta_qB^q)\epsilon_t.\]

Then,

\[Y_t = \theta(B)\epsilon_t,\]

where \(\theta(B)=1+\theta_1B+\theta_2B^2+...+\theta_1B^q.\) Hence, for
an \textbf{invertible} moving average process, \(Y_t\) can be
represented as a finite weighted sum of previous error terms,
\(\epsilon\). Furthermore, since the process is invertible
\(\epsilon_t\) can be represented as an infinite weighted sum of
previous \(Y\)'s as below

\[\epsilon_t=\theta^{-1}(B)Y_t,\] where \(\pi(B)\theta(B)=1\), and
\(\pi(B) = 1+\pi_1B+\pi B^2+...\). Hence,

\[\epsilon_t = \pi(B)Y_t.\] This is an representation of a
\(AR(\infty)\) process.

\textbf{Dual relation 2}

An \(MA(q)\) process has an ACF function that is zero beyond lag \(q\)
and its PACF is decays exponentially to 0. Consequently, an \(AR(p)\)
process has an PACF that is zero beyond lag-\(p\), but its ACF decays
exponentially to 0.

\textbf{Dual relation 3}

For an \(AR(p)\) process the roots of \(\phi(B)=0\) must lie outside the
unit circle to satisfy the condition of stationarity. However, the
parameters of the \(AR(p)\) are not required to satisfy any conditions
to ensure invertibility. Conversely, the parameters of the \(MA\)
process are not required to satisfy any condition to ensure
stationarity. However, to ensure the condition of invertibility, the
roots of \(\theta(B)=0\) must lie outside the unit circle.

\section{Autoregressive and Moving-average (ARMA)
models}\label{autoregressive-and-moving-average-arma-models}

current value = linear combination of past values + linear combination
of past error + current error

The \(ARMA(p, q)\) can be written as

\[Y_t=c+\phi_1 Y_{t-1}+\phi_2 Y_{t-2}+...+\phi_p Y_{t-p}+\theta_1\epsilon_{t-1}+\theta_2\epsilon_{t-2}+...+\theta_q\epsilon_{t-q}+\epsilon_t,\]
where \(\{\epsilon_t\}\) is a white noise process.

Using the back shift operator

\[\phi(B)Y_t=\theta(B)\epsilon_t,\] where \(\phi(.)\) and \(\theta(.)\)
are the \(p\)th and \(q\)th degree polynomials,

\[\phi(B)=1-\phi_1 \epsilon -...-\phi_p \epsilon^p,\] and
\[\theta(B)=1+\theta_1\epsilon+...+\theta_q\epsilon^q.\]

\section{Stationary condition}\label{stationary-condition}

Roots of \[\phi(B)=0\] lie outside the unit circle.

\section{Invertible condition}\label{invertible-condition}

Roots of \[\theta(B)=0\] lie outside the unit circle.

\section{Autocorrelation function and Partial autocorrelation
function}\label{autocorrelation-function-and-partial-autocorrelation-function}

The ACF of an ARMA model exhibits a pattern similar to that of an AR
model. The PACF of ARMA process behaves like the PACF of a MA process.
Hence, the ACF and PACF are not informative in determining the order of
an ARMA model.

\section{Theoretical ACF and PACF for AR, MA and ARMA
models}\label{theoretical-acf-and-pacf-for-ar-ma-and-arma-models}

Theoretical autocorrelation coefficients for some of the more common AR,
MA and ARMA models are shown here. However, the ACF and PACF calculated
from the data will not exactly match any set of theoretical ACF and PACF
because the ACF and PACF calculated from the data are subject to
sampling variation.

\section{ACF and PACF calculated from
data}\label{acf-and-pacf-calculated-from-data}

\begin{figure}[H]

{\centering \pandocbounded{\includegraphics[keepaspectratio]{04-chap4_files/figure-pdf/unnamed-chunk-1-1.pdf}}

}

\caption{ACF and PACF of AR(1), MA(1) and ARMA(1, 1) models calculated
from the data}

\end{figure}%

\section{References}\label{references}

Box, G. E., Jenkins, G. M., Reinsel, G. C., \& Ljung, G. M. (2015). Time
series analysis: forecasting and control.

\bookmarksetup{startatroot}

\chapter{Fit ARIMA class models using
R}\label{fit-arima-class-models-using-r}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidyverse)}
\FunctionTok{library}\NormalTok{(tsibble)}
\FunctionTok{library}\NormalTok{(lubridate)}
\FunctionTok{library}\NormalTok{(feasts)}
\FunctionTok{library}\NormalTok{(denguedatahub)}
\CommentTok{\# install.packages("devtools")}
\CommentTok{\#devtools::install\_github("thiyangt/TourSriLanka")}
\FunctionTok{library}\NormalTok{(TourSriLanka)}
\FunctionTok{library}\NormalTok{(fable)}
\FunctionTok{library}\NormalTok{(fabletools)}
\end{Highlighting}
\end{Shaded}

\section{tibble vs tsibble}\label{tibble-vs-tsibble}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y.tibble }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}
  \AttributeTok{Year =} \DecValTok{2020}\SpecialCharTok{:}\DecValTok{2023}\NormalTok{,}
  \AttributeTok{Earnings =} \FunctionTok{c}\NormalTok{(}\FloatTok{682.4}\NormalTok{, }\FloatTok{506.9}\NormalTok{, }\FloatTok{1136.3}\NormalTok{, }\FloatTok{2068.0}\NormalTok{))}
\NormalTok{y.tibble}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 4 x 2
   Year Earnings
  <int>    <dbl>
1  2020     682.
2  2021     507.
3  2022    1136.
4  2023    2068 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y.tsibble }\OtherTok{\textless{}{-}} \FunctionTok{tsibble}\NormalTok{(}
  \AttributeTok{Year =} \DecValTok{2020}\SpecialCharTok{:}\DecValTok{2023}\NormalTok{,}
  \AttributeTok{Earnings =} \FunctionTok{c}\NormalTok{(}\FloatTok{682.4}\NormalTok{, }\FloatTok{506.9}\NormalTok{, }\FloatTok{1136.3}\NormalTok{, }\FloatTok{2068.0}\NormalTok{),}
  \AttributeTok{index =}\NormalTok{ Year)}
\NormalTok{y.tsibble}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tsibble: 4 x 2 [1Y]
   Year Earnings
  <int>    <dbl>
1  2020     682.
2  2021     507.
3  2022    1136.
4  2023    2068 
\end{verbatim}

\section{Convert tibble to tsibble}\label{convert-tibble-to-tsibble}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y.tibble }\SpecialCharTok{|\textgreater{}} \FunctionTok{as\_tsibble}\NormalTok{(}\AttributeTok{index=}\NormalTok{Year)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tsibble: 4 x 2 [1Y]
   Year Earnings
  <int>    <dbl>
1  2020     682.
2  2021     507.
3  2022    1136.
4  2023    2068 
\end{verbatim}

\section{Exercise}\label{exercise-1}

Extract dengue.cases.indigenous from china\_annual\_data and convert it
into tsibble.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(denguedatahub)}
\NormalTok{china\_annual\_data}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 16 x 5
    year dengue.cases.indigenous dengue.cases.imported counties.with.dengue.fe~1
   <int>                   <dbl>                 <dbl>                     <dbl>
 1  2005                       0                    45                         0
 2  2006                    1007                    46                        15
 3  2007                     481                    56                        13
 4  2008                      86                   134                        11
 5  2009                     200                    73                         5
 6  2010                     112                   119                        14
 7  2011                      35                   113                         6
 8  2012                     438                   149                        14
 9  2013                    4263                   460                        36
10  2014                   46034                   399                       160
11  2015                    3044                  1083                        44
12  2016                    1549                   675                        41
13  2017                    4609                  2112                        76
14  2018                    3801                  1266                       100
15  2019                   15378                  5813                       266
16  2020                     616                   158                         7
# i abbreviated name: 1: counties.with.dengue.fever.indigenous
# i 1 more variable: counties.with.dengue.fever.imported <dbl>
\end{verbatim}

\section{Monthly data}\label{monthly-data}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(TourSriLanka)}
\FunctionTok{data}\NormalTok{(earnings)}
\NormalTok{earnings}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 180 x 3
   Month   Year  Earnings
   <chr>   <chr>    <dbl>
 1 January 2009      30  
 2 January 2010      44.7
 3 January 2011      72  
 4 January 2012      88.9
 5 January 2013     149. 
 6 January 2014     233. 
 7 January 2015     259  
 8 January 2016     333. 
 9 January 2017     407. 
10 January 2018     448. 
# i 170 more rows
\end{verbatim}

\section{Sort data according to the
year}\label{sort-data-according-to-the-year}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{earnings }\OtherTok{\textless{}{-}}\NormalTok{ earnings }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{arrange}\NormalTok{(Year, }\FunctionTok{match}\NormalTok{(Month, month.name) )}
\NormalTok{earnings}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 180 x 3
   Month     Year  Earnings
   <chr>     <chr>    <dbl>
 1 January   2009      30  
 2 February  2009      26.7
 3 March     2009      26.6
 4 April     2009      20.3
 5 May       2009      19.3
 6 June      2009      23.6
 7 July      2009      33  
 8 August    2009      32.2
 9 September 2009      29.6
10 October   2009      29.3
# i 170 more rows
\end{verbatim}

\section{Create sequence of dates using lubridate
package}\label{create-sequence-of-dates-using-lubridate-package}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(lubridate)}
\FunctionTok{seq}\NormalTok{(}\FunctionTok{ymd}\NormalTok{(}\StringTok{"2009{-}1{-}1"}\NormalTok{), }\FunctionTok{ymd}\NormalTok{(}\StringTok{"2023{-}1{-}1"}\NormalTok{), }\AttributeTok{by =} \StringTok{"years"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] "2009-01-01" "2010-01-01" "2011-01-01" "2012-01-01" "2013-01-01"
 [6] "2014-01-01" "2015-01-01" "2016-01-01" "2017-01-01" "2018-01-01"
[11] "2019-01-01" "2020-01-01" "2021-01-01" "2022-01-01" "2023-01-01"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{seq}\NormalTok{(}\FunctionTok{ymd}\NormalTok{(}\StringTok{"2009{-}1{-}1"}\NormalTok{), }\FunctionTok{ymd}\NormalTok{(}\StringTok{"2023{-}1{-}1"}\NormalTok{), }\AttributeTok{by =} \StringTok{"month"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  [1] "2009-01-01" "2009-02-01" "2009-03-01" "2009-04-01" "2009-05-01"
  [6] "2009-06-01" "2009-07-01" "2009-08-01" "2009-09-01" "2009-10-01"
 [11] "2009-11-01" "2009-12-01" "2010-01-01" "2010-02-01" "2010-03-01"
 [16] "2010-04-01" "2010-05-01" "2010-06-01" "2010-07-01" "2010-08-01"
 [21] "2010-09-01" "2010-10-01" "2010-11-01" "2010-12-01" "2011-01-01"
 [26] "2011-02-01" "2011-03-01" "2011-04-01" "2011-05-01" "2011-06-01"
 [31] "2011-07-01" "2011-08-01" "2011-09-01" "2011-10-01" "2011-11-01"
 [36] "2011-12-01" "2012-01-01" "2012-02-01" "2012-03-01" "2012-04-01"
 [41] "2012-05-01" "2012-06-01" "2012-07-01" "2012-08-01" "2012-09-01"
 [46] "2012-10-01" "2012-11-01" "2012-12-01" "2013-01-01" "2013-02-01"
 [51] "2013-03-01" "2013-04-01" "2013-05-01" "2013-06-01" "2013-07-01"
 [56] "2013-08-01" "2013-09-01" "2013-10-01" "2013-11-01" "2013-12-01"
 [61] "2014-01-01" "2014-02-01" "2014-03-01" "2014-04-01" "2014-05-01"
 [66] "2014-06-01" "2014-07-01" "2014-08-01" "2014-09-01" "2014-10-01"
 [71] "2014-11-01" "2014-12-01" "2015-01-01" "2015-02-01" "2015-03-01"
 [76] "2015-04-01" "2015-05-01" "2015-06-01" "2015-07-01" "2015-08-01"
 [81] "2015-09-01" "2015-10-01" "2015-11-01" "2015-12-01" "2016-01-01"
 [86] "2016-02-01" "2016-03-01" "2016-04-01" "2016-05-01" "2016-06-01"
 [91] "2016-07-01" "2016-08-01" "2016-09-01" "2016-10-01" "2016-11-01"
 [96] "2016-12-01" "2017-01-01" "2017-02-01" "2017-03-01" "2017-04-01"
[101] "2017-05-01" "2017-06-01" "2017-07-01" "2017-08-01" "2017-09-01"
[106] "2017-10-01" "2017-11-01" "2017-12-01" "2018-01-01" "2018-02-01"
[111] "2018-03-01" "2018-04-01" "2018-05-01" "2018-06-01" "2018-07-01"
[116] "2018-08-01" "2018-09-01" "2018-10-01" "2018-11-01" "2018-12-01"
[121] "2019-01-01" "2019-02-01" "2019-03-01" "2019-04-01" "2019-05-01"
[126] "2019-06-01" "2019-07-01" "2019-08-01" "2019-09-01" "2019-10-01"
[131] "2019-11-01" "2019-12-01" "2020-01-01" "2020-02-01" "2020-03-01"
[136] "2020-04-01" "2020-05-01" "2020-06-01" "2020-07-01" "2020-08-01"
[141] "2020-09-01" "2020-10-01" "2020-11-01" "2020-12-01" "2021-01-01"
[146] "2021-02-01" "2021-03-01" "2021-04-01" "2021-05-01" "2021-06-01"
[151] "2021-07-01" "2021-08-01" "2021-09-01" "2021-10-01" "2021-11-01"
[156] "2021-12-01" "2022-01-01" "2022-02-01" "2022-03-01" "2022-04-01"
[161] "2022-05-01" "2022-06-01" "2022-07-01" "2022-08-01" "2022-09-01"
[166] "2022-10-01" "2022-11-01" "2022-12-01" "2023-01-01"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{seq}\NormalTok{(}\FunctionTok{ymd}\NormalTok{(}\StringTok{"2009{-}1{-}1"}\NormalTok{), }\FunctionTok{ymd}\NormalTok{(}\StringTok{"2023{-}1{-}1"}\NormalTok{), }\AttributeTok{by =} \StringTok{"quarter"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] "2009-01-01" "2009-04-01" "2009-07-01" "2009-10-01" "2010-01-01"
 [6] "2010-04-01" "2010-07-01" "2010-10-01" "2011-01-01" "2011-04-01"
[11] "2011-07-01" "2011-10-01" "2012-01-01" "2012-04-01" "2012-07-01"
[16] "2012-10-01" "2013-01-01" "2013-04-01" "2013-07-01" "2013-10-01"
[21] "2014-01-01" "2014-04-01" "2014-07-01" "2014-10-01" "2015-01-01"
[26] "2015-04-01" "2015-07-01" "2015-10-01" "2016-01-01" "2016-04-01"
[31] "2016-07-01" "2016-10-01" "2017-01-01" "2017-04-01" "2017-07-01"
[36] "2017-10-01" "2018-01-01" "2018-04-01" "2018-07-01" "2018-10-01"
[41] "2019-01-01" "2019-04-01" "2019-07-01" "2019-10-01" "2020-01-01"
[46] "2020-04-01" "2020-07-01" "2020-10-01" "2021-01-01" "2021-04-01"
[51] "2021-07-01" "2021-10-01" "2022-01-01" "2022-04-01" "2022-07-01"
[56] "2022-10-01" "2023-01-01"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{seq}\NormalTok{(}\FunctionTok{ymd}\NormalTok{(}\StringTok{"2009{-}1{-}1"}\NormalTok{), }\FunctionTok{ymd}\NormalTok{(}\StringTok{"2023{-}1{-}1"}\NormalTok{), }\AttributeTok{by =} \StringTok{"1 week"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  [1] "2009-01-01" "2009-01-08" "2009-01-15" "2009-01-22" "2009-01-29"
  [6] "2009-02-05" "2009-02-12" "2009-02-19" "2009-02-26" "2009-03-05"
 [11] "2009-03-12" "2009-03-19" "2009-03-26" "2009-04-02" "2009-04-09"
 [16] "2009-04-16" "2009-04-23" "2009-04-30" "2009-05-07" "2009-05-14"
 [21] "2009-05-21" "2009-05-28" "2009-06-04" "2009-06-11" "2009-06-18"
 [26] "2009-06-25" "2009-07-02" "2009-07-09" "2009-07-16" "2009-07-23"
 [31] "2009-07-30" "2009-08-06" "2009-08-13" "2009-08-20" "2009-08-27"
 [36] "2009-09-03" "2009-09-10" "2009-09-17" "2009-09-24" "2009-10-01"
 [41] "2009-10-08" "2009-10-15" "2009-10-22" "2009-10-29" "2009-11-05"
 [46] "2009-11-12" "2009-11-19" "2009-11-26" "2009-12-03" "2009-12-10"
 [51] "2009-12-17" "2009-12-24" "2009-12-31" "2010-01-07" "2010-01-14"
 [56] "2010-01-21" "2010-01-28" "2010-02-04" "2010-02-11" "2010-02-18"
 [61] "2010-02-25" "2010-03-04" "2010-03-11" "2010-03-18" "2010-03-25"
 [66] "2010-04-01" "2010-04-08" "2010-04-15" "2010-04-22" "2010-04-29"
 [71] "2010-05-06" "2010-05-13" "2010-05-20" "2010-05-27" "2010-06-03"
 [76] "2010-06-10" "2010-06-17" "2010-06-24" "2010-07-01" "2010-07-08"
 [81] "2010-07-15" "2010-07-22" "2010-07-29" "2010-08-05" "2010-08-12"
 [86] "2010-08-19" "2010-08-26" "2010-09-02" "2010-09-09" "2010-09-16"
 [91] "2010-09-23" "2010-09-30" "2010-10-07" "2010-10-14" "2010-10-21"
 [96] "2010-10-28" "2010-11-04" "2010-11-11" "2010-11-18" "2010-11-25"
[101] "2010-12-02" "2010-12-09" "2010-12-16" "2010-12-23" "2010-12-30"
[106] "2011-01-06" "2011-01-13" "2011-01-20" "2011-01-27" "2011-02-03"
[111] "2011-02-10" "2011-02-17" "2011-02-24" "2011-03-03" "2011-03-10"
[116] "2011-03-17" "2011-03-24" "2011-03-31" "2011-04-07" "2011-04-14"
[121] "2011-04-21" "2011-04-28" "2011-05-05" "2011-05-12" "2011-05-19"
[126] "2011-05-26" "2011-06-02" "2011-06-09" "2011-06-16" "2011-06-23"
[131] "2011-06-30" "2011-07-07" "2011-07-14" "2011-07-21" "2011-07-28"
[136] "2011-08-04" "2011-08-11" "2011-08-18" "2011-08-25" "2011-09-01"
[141] "2011-09-08" "2011-09-15" "2011-09-22" "2011-09-29" "2011-10-06"
[146] "2011-10-13" "2011-10-20" "2011-10-27" "2011-11-03" "2011-11-10"
[151] "2011-11-17" "2011-11-24" "2011-12-01" "2011-12-08" "2011-12-15"
[156] "2011-12-22" "2011-12-29" "2012-01-05" "2012-01-12" "2012-01-19"
[161] "2012-01-26" "2012-02-02" "2012-02-09" "2012-02-16" "2012-02-23"
[166] "2012-03-01" "2012-03-08" "2012-03-15" "2012-03-22" "2012-03-29"
[171] "2012-04-05" "2012-04-12" "2012-04-19" "2012-04-26" "2012-05-03"
[176] "2012-05-10" "2012-05-17" "2012-05-24" "2012-05-31" "2012-06-07"
[181] "2012-06-14" "2012-06-21" "2012-06-28" "2012-07-05" "2012-07-12"
[186] "2012-07-19" "2012-07-26" "2012-08-02" "2012-08-09" "2012-08-16"
[191] "2012-08-23" "2012-08-30" "2012-09-06" "2012-09-13" "2012-09-20"
[196] "2012-09-27" "2012-10-04" "2012-10-11" "2012-10-18" "2012-10-25"
[201] "2012-11-01" "2012-11-08" "2012-11-15" "2012-11-22" "2012-11-29"
[206] "2012-12-06" "2012-12-13" "2012-12-20" "2012-12-27" "2013-01-03"
[211] "2013-01-10" "2013-01-17" "2013-01-24" "2013-01-31" "2013-02-07"
[216] "2013-02-14" "2013-02-21" "2013-02-28" "2013-03-07" "2013-03-14"
[221] "2013-03-21" "2013-03-28" "2013-04-04" "2013-04-11" "2013-04-18"
[226] "2013-04-25" "2013-05-02" "2013-05-09" "2013-05-16" "2013-05-23"
[231] "2013-05-30" "2013-06-06" "2013-06-13" "2013-06-20" "2013-06-27"
[236] "2013-07-04" "2013-07-11" "2013-07-18" "2013-07-25" "2013-08-01"
[241] "2013-08-08" "2013-08-15" "2013-08-22" "2013-08-29" "2013-09-05"
[246] "2013-09-12" "2013-09-19" "2013-09-26" "2013-10-03" "2013-10-10"
[251] "2013-10-17" "2013-10-24" "2013-10-31" "2013-11-07" "2013-11-14"
[256] "2013-11-21" "2013-11-28" "2013-12-05" "2013-12-12" "2013-12-19"
[261] "2013-12-26" "2014-01-02" "2014-01-09" "2014-01-16" "2014-01-23"
[266] "2014-01-30" "2014-02-06" "2014-02-13" "2014-02-20" "2014-02-27"
[271] "2014-03-06" "2014-03-13" "2014-03-20" "2014-03-27" "2014-04-03"
[276] "2014-04-10" "2014-04-17" "2014-04-24" "2014-05-01" "2014-05-08"
[281] "2014-05-15" "2014-05-22" "2014-05-29" "2014-06-05" "2014-06-12"
[286] "2014-06-19" "2014-06-26" "2014-07-03" "2014-07-10" "2014-07-17"
[291] "2014-07-24" "2014-07-31" "2014-08-07" "2014-08-14" "2014-08-21"
[296] "2014-08-28" "2014-09-04" "2014-09-11" "2014-09-18" "2014-09-25"
[301] "2014-10-02" "2014-10-09" "2014-10-16" "2014-10-23" "2014-10-30"
[306] "2014-11-06" "2014-11-13" "2014-11-20" "2014-11-27" "2014-12-04"
[311] "2014-12-11" "2014-12-18" "2014-12-25" "2015-01-01" "2015-01-08"
[316] "2015-01-15" "2015-01-22" "2015-01-29" "2015-02-05" "2015-02-12"
[321] "2015-02-19" "2015-02-26" "2015-03-05" "2015-03-12" "2015-03-19"
[326] "2015-03-26" "2015-04-02" "2015-04-09" "2015-04-16" "2015-04-23"
[331] "2015-04-30" "2015-05-07" "2015-05-14" "2015-05-21" "2015-05-28"
[336] "2015-06-04" "2015-06-11" "2015-06-18" "2015-06-25" "2015-07-02"
[341] "2015-07-09" "2015-07-16" "2015-07-23" "2015-07-30" "2015-08-06"
[346] "2015-08-13" "2015-08-20" "2015-08-27" "2015-09-03" "2015-09-10"
[351] "2015-09-17" "2015-09-24" "2015-10-01" "2015-10-08" "2015-10-15"
[356] "2015-10-22" "2015-10-29" "2015-11-05" "2015-11-12" "2015-11-19"
[361] "2015-11-26" "2015-12-03" "2015-12-10" "2015-12-17" "2015-12-24"
[366] "2015-12-31" "2016-01-07" "2016-01-14" "2016-01-21" "2016-01-28"
[371] "2016-02-04" "2016-02-11" "2016-02-18" "2016-02-25" "2016-03-03"
[376] "2016-03-10" "2016-03-17" "2016-03-24" "2016-03-31" "2016-04-07"
[381] "2016-04-14" "2016-04-21" "2016-04-28" "2016-05-05" "2016-05-12"
[386] "2016-05-19" "2016-05-26" "2016-06-02" "2016-06-09" "2016-06-16"
[391] "2016-06-23" "2016-06-30" "2016-07-07" "2016-07-14" "2016-07-21"
[396] "2016-07-28" "2016-08-04" "2016-08-11" "2016-08-18" "2016-08-25"
[401] "2016-09-01" "2016-09-08" "2016-09-15" "2016-09-22" "2016-09-29"
[406] "2016-10-06" "2016-10-13" "2016-10-20" "2016-10-27" "2016-11-03"
[411] "2016-11-10" "2016-11-17" "2016-11-24" "2016-12-01" "2016-12-08"
[416] "2016-12-15" "2016-12-22" "2016-12-29" "2017-01-05" "2017-01-12"
[421] "2017-01-19" "2017-01-26" "2017-02-02" "2017-02-09" "2017-02-16"
[426] "2017-02-23" "2017-03-02" "2017-03-09" "2017-03-16" "2017-03-23"
[431] "2017-03-30" "2017-04-06" "2017-04-13" "2017-04-20" "2017-04-27"
[436] "2017-05-04" "2017-05-11" "2017-05-18" "2017-05-25" "2017-06-01"
[441] "2017-06-08" "2017-06-15" "2017-06-22" "2017-06-29" "2017-07-06"
[446] "2017-07-13" "2017-07-20" "2017-07-27" "2017-08-03" "2017-08-10"
[451] "2017-08-17" "2017-08-24" "2017-08-31" "2017-09-07" "2017-09-14"
[456] "2017-09-21" "2017-09-28" "2017-10-05" "2017-10-12" "2017-10-19"
[461] "2017-10-26" "2017-11-02" "2017-11-09" "2017-11-16" "2017-11-23"
[466] "2017-11-30" "2017-12-07" "2017-12-14" "2017-12-21" "2017-12-28"
[471] "2018-01-04" "2018-01-11" "2018-01-18" "2018-01-25" "2018-02-01"
[476] "2018-02-08" "2018-02-15" "2018-02-22" "2018-03-01" "2018-03-08"
[481] "2018-03-15" "2018-03-22" "2018-03-29" "2018-04-05" "2018-04-12"
[486] "2018-04-19" "2018-04-26" "2018-05-03" "2018-05-10" "2018-05-17"
[491] "2018-05-24" "2018-05-31" "2018-06-07" "2018-06-14" "2018-06-21"
[496] "2018-06-28" "2018-07-05" "2018-07-12" "2018-07-19" "2018-07-26"
[501] "2018-08-02" "2018-08-09" "2018-08-16" "2018-08-23" "2018-08-30"
[506] "2018-09-06" "2018-09-13" "2018-09-20" "2018-09-27" "2018-10-04"
[511] "2018-10-11" "2018-10-18" "2018-10-25" "2018-11-01" "2018-11-08"
[516] "2018-11-15" "2018-11-22" "2018-11-29" "2018-12-06" "2018-12-13"
[521] "2018-12-20" "2018-12-27" "2019-01-03" "2019-01-10" "2019-01-17"
[526] "2019-01-24" "2019-01-31" "2019-02-07" "2019-02-14" "2019-02-21"
[531] "2019-02-28" "2019-03-07" "2019-03-14" "2019-03-21" "2019-03-28"
[536] "2019-04-04" "2019-04-11" "2019-04-18" "2019-04-25" "2019-05-02"
[541] "2019-05-09" "2019-05-16" "2019-05-23" "2019-05-30" "2019-06-06"
[546] "2019-06-13" "2019-06-20" "2019-06-27" "2019-07-04" "2019-07-11"
[551] "2019-07-18" "2019-07-25" "2019-08-01" "2019-08-08" "2019-08-15"
[556] "2019-08-22" "2019-08-29" "2019-09-05" "2019-09-12" "2019-09-19"
[561] "2019-09-26" "2019-10-03" "2019-10-10" "2019-10-17" "2019-10-24"
[566] "2019-10-31" "2019-11-07" "2019-11-14" "2019-11-21" "2019-11-28"
[571] "2019-12-05" "2019-12-12" "2019-12-19" "2019-12-26" "2020-01-02"
[576] "2020-01-09" "2020-01-16" "2020-01-23" "2020-01-30" "2020-02-06"
[581] "2020-02-13" "2020-02-20" "2020-02-27" "2020-03-05" "2020-03-12"
[586] "2020-03-19" "2020-03-26" "2020-04-02" "2020-04-09" "2020-04-16"
[591] "2020-04-23" "2020-04-30" "2020-05-07" "2020-05-14" "2020-05-21"
[596] "2020-05-28" "2020-06-04" "2020-06-11" "2020-06-18" "2020-06-25"
[601] "2020-07-02" "2020-07-09" "2020-07-16" "2020-07-23" "2020-07-30"
[606] "2020-08-06" "2020-08-13" "2020-08-20" "2020-08-27" "2020-09-03"
[611] "2020-09-10" "2020-09-17" "2020-09-24" "2020-10-01" "2020-10-08"
[616] "2020-10-15" "2020-10-22" "2020-10-29" "2020-11-05" "2020-11-12"
[621] "2020-11-19" "2020-11-26" "2020-12-03" "2020-12-10" "2020-12-17"
[626] "2020-12-24" "2020-12-31" "2021-01-07" "2021-01-14" "2021-01-21"
[631] "2021-01-28" "2021-02-04" "2021-02-11" "2021-02-18" "2021-02-25"
[636] "2021-03-04" "2021-03-11" "2021-03-18" "2021-03-25" "2021-04-01"
[641] "2021-04-08" "2021-04-15" "2021-04-22" "2021-04-29" "2021-05-06"
[646] "2021-05-13" "2021-05-20" "2021-05-27" "2021-06-03" "2021-06-10"
[651] "2021-06-17" "2021-06-24" "2021-07-01" "2021-07-08" "2021-07-15"
[656] "2021-07-22" "2021-07-29" "2021-08-05" "2021-08-12" "2021-08-19"
[661] "2021-08-26" "2021-09-02" "2021-09-09" "2021-09-16" "2021-09-23"
[666] "2021-09-30" "2021-10-07" "2021-10-14" "2021-10-21" "2021-10-28"
[671] "2021-11-04" "2021-11-11" "2021-11-18" "2021-11-25" "2021-12-02"
[676] "2021-12-09" "2021-12-16" "2021-12-23" "2021-12-30" "2022-01-06"
[681] "2022-01-13" "2022-01-20" "2022-01-27" "2022-02-03" "2022-02-10"
[686] "2022-02-17" "2022-02-24" "2022-03-03" "2022-03-10" "2022-03-17"
[691] "2022-03-24" "2022-03-31" "2022-04-07" "2022-04-14" "2022-04-21"
[696] "2022-04-28" "2022-05-05" "2022-05-12" "2022-05-19" "2022-05-26"
[701] "2022-06-02" "2022-06-09" "2022-06-16" "2022-06-23" "2022-06-30"
[706] "2022-07-07" "2022-07-14" "2022-07-21" "2022-07-28" "2022-08-04"
[711] "2022-08-11" "2022-08-18" "2022-08-25" "2022-09-01" "2022-09-08"
[716] "2022-09-15" "2022-09-22" "2022-09-29" "2022-10-06" "2022-10-13"
[721] "2022-10-20" "2022-10-27" "2022-11-03" "2022-11-10" "2022-11-17"
[726] "2022-11-24" "2022-12-01" "2022-12-08" "2022-12-15" "2022-12-22"
[731] "2022-12-29"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{seq}\NormalTok{(}\FunctionTok{ymd}\NormalTok{(}\StringTok{"2009{-}1{-}1"}\NormalTok{), }\FunctionTok{ymd}\NormalTok{(}\StringTok{"2023{-}1{-}1"}\NormalTok{), }\AttributeTok{by =} \StringTok{"2 week"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  [1] "2009-01-01" "2009-01-15" "2009-01-29" "2009-02-12" "2009-02-26"
  [6] "2009-03-12" "2009-03-26" "2009-04-09" "2009-04-23" "2009-05-07"
 [11] "2009-05-21" "2009-06-04" "2009-06-18" "2009-07-02" "2009-07-16"
 [16] "2009-07-30" "2009-08-13" "2009-08-27" "2009-09-10" "2009-09-24"
 [21] "2009-10-08" "2009-10-22" "2009-11-05" "2009-11-19" "2009-12-03"
 [26] "2009-12-17" "2009-12-31" "2010-01-14" "2010-01-28" "2010-02-11"
 [31] "2010-02-25" "2010-03-11" "2010-03-25" "2010-04-08" "2010-04-22"
 [36] "2010-05-06" "2010-05-20" "2010-06-03" "2010-06-17" "2010-07-01"
 [41] "2010-07-15" "2010-07-29" "2010-08-12" "2010-08-26" "2010-09-09"
 [46] "2010-09-23" "2010-10-07" "2010-10-21" "2010-11-04" "2010-11-18"
 [51] "2010-12-02" "2010-12-16" "2010-12-30" "2011-01-13" "2011-01-27"
 [56] "2011-02-10" "2011-02-24" "2011-03-10" "2011-03-24" "2011-04-07"
 [61] "2011-04-21" "2011-05-05" "2011-05-19" "2011-06-02" "2011-06-16"
 [66] "2011-06-30" "2011-07-14" "2011-07-28" "2011-08-11" "2011-08-25"
 [71] "2011-09-08" "2011-09-22" "2011-10-06" "2011-10-20" "2011-11-03"
 [76] "2011-11-17" "2011-12-01" "2011-12-15" "2011-12-29" "2012-01-12"
 [81] "2012-01-26" "2012-02-09" "2012-02-23" "2012-03-08" "2012-03-22"
 [86] "2012-04-05" "2012-04-19" "2012-05-03" "2012-05-17" "2012-05-31"
 [91] "2012-06-14" "2012-06-28" "2012-07-12" "2012-07-26" "2012-08-09"
 [96] "2012-08-23" "2012-09-06" "2012-09-20" "2012-10-04" "2012-10-18"
[101] "2012-11-01" "2012-11-15" "2012-11-29" "2012-12-13" "2012-12-27"
[106] "2013-01-10" "2013-01-24" "2013-02-07" "2013-02-21" "2013-03-07"
[111] "2013-03-21" "2013-04-04" "2013-04-18" "2013-05-02" "2013-05-16"
[116] "2013-05-30" "2013-06-13" "2013-06-27" "2013-07-11" "2013-07-25"
[121] "2013-08-08" "2013-08-22" "2013-09-05" "2013-09-19" "2013-10-03"
[126] "2013-10-17" "2013-10-31" "2013-11-14" "2013-11-28" "2013-12-12"
[131] "2013-12-26" "2014-01-09" "2014-01-23" "2014-02-06" "2014-02-20"
[136] "2014-03-06" "2014-03-20" "2014-04-03" "2014-04-17" "2014-05-01"
[141] "2014-05-15" "2014-05-29" "2014-06-12" "2014-06-26" "2014-07-10"
[146] "2014-07-24" "2014-08-07" "2014-08-21" "2014-09-04" "2014-09-18"
[151] "2014-10-02" "2014-10-16" "2014-10-30" "2014-11-13" "2014-11-27"
[156] "2014-12-11" "2014-12-25" "2015-01-08" "2015-01-22" "2015-02-05"
[161] "2015-02-19" "2015-03-05" "2015-03-19" "2015-04-02" "2015-04-16"
[166] "2015-04-30" "2015-05-14" "2015-05-28" "2015-06-11" "2015-06-25"
[171] "2015-07-09" "2015-07-23" "2015-08-06" "2015-08-20" "2015-09-03"
[176] "2015-09-17" "2015-10-01" "2015-10-15" "2015-10-29" "2015-11-12"
[181] "2015-11-26" "2015-12-10" "2015-12-24" "2016-01-07" "2016-01-21"
[186] "2016-02-04" "2016-02-18" "2016-03-03" "2016-03-17" "2016-03-31"
[191] "2016-04-14" "2016-04-28" "2016-05-12" "2016-05-26" "2016-06-09"
[196] "2016-06-23" "2016-07-07" "2016-07-21" "2016-08-04" "2016-08-18"
[201] "2016-09-01" "2016-09-15" "2016-09-29" "2016-10-13" "2016-10-27"
[206] "2016-11-10" "2016-11-24" "2016-12-08" "2016-12-22" "2017-01-05"
[211] "2017-01-19" "2017-02-02" "2017-02-16" "2017-03-02" "2017-03-16"
[216] "2017-03-30" "2017-04-13" "2017-04-27" "2017-05-11" "2017-05-25"
[221] "2017-06-08" "2017-06-22" "2017-07-06" "2017-07-20" "2017-08-03"
[226] "2017-08-17" "2017-08-31" "2017-09-14" "2017-09-28" "2017-10-12"
[231] "2017-10-26" "2017-11-09" "2017-11-23" "2017-12-07" "2017-12-21"
[236] "2018-01-04" "2018-01-18" "2018-02-01" "2018-02-15" "2018-03-01"
[241] "2018-03-15" "2018-03-29" "2018-04-12" "2018-04-26" "2018-05-10"
[246] "2018-05-24" "2018-06-07" "2018-06-21" "2018-07-05" "2018-07-19"
[251] "2018-08-02" "2018-08-16" "2018-08-30" "2018-09-13" "2018-09-27"
[256] "2018-10-11" "2018-10-25" "2018-11-08" "2018-11-22" "2018-12-06"
[261] "2018-12-20" "2019-01-03" "2019-01-17" "2019-01-31" "2019-02-14"
[266] "2019-02-28" "2019-03-14" "2019-03-28" "2019-04-11" "2019-04-25"
[271] "2019-05-09" "2019-05-23" "2019-06-06" "2019-06-20" "2019-07-04"
[276] "2019-07-18" "2019-08-01" "2019-08-15" "2019-08-29" "2019-09-12"
[281] "2019-09-26" "2019-10-10" "2019-10-24" "2019-11-07" "2019-11-21"
[286] "2019-12-05" "2019-12-19" "2020-01-02" "2020-01-16" "2020-01-30"
[291] "2020-02-13" "2020-02-27" "2020-03-12" "2020-03-26" "2020-04-09"
[296] "2020-04-23" "2020-05-07" "2020-05-21" "2020-06-04" "2020-06-18"
[301] "2020-07-02" "2020-07-16" "2020-07-30" "2020-08-13" "2020-08-27"
[306] "2020-09-10" "2020-09-24" "2020-10-08" "2020-10-22" "2020-11-05"
[311] "2020-11-19" "2020-12-03" "2020-12-17" "2020-12-31" "2021-01-14"
[316] "2021-01-28" "2021-02-11" "2021-02-25" "2021-03-11" "2021-03-25"
[321] "2021-04-08" "2021-04-22" "2021-05-06" "2021-05-20" "2021-06-03"
[326] "2021-06-17" "2021-07-01" "2021-07-15" "2021-07-29" "2021-08-12"
[331] "2021-08-26" "2021-09-09" "2021-09-23" "2021-10-07" "2021-10-21"
[336] "2021-11-04" "2021-11-18" "2021-12-02" "2021-12-16" "2021-12-30"
[341] "2022-01-13" "2022-01-27" "2022-02-10" "2022-02-24" "2022-03-10"
[346] "2022-03-24" "2022-04-07" "2022-04-21" "2022-05-05" "2022-05-19"
[351] "2022-06-02" "2022-06-16" "2022-06-30" "2022-07-14" "2022-07-28"
[356] "2022-08-11" "2022-08-25" "2022-09-08" "2022-09-22" "2022-10-06"
[361] "2022-10-20" "2022-11-03" "2022-11-17" "2022-12-01" "2022-12-15"
[366] "2022-12-29"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{seq}\NormalTok{(}\FunctionTok{ymd}\NormalTok{(}\StringTok{"2009{-}1{-}1"}\NormalTok{), }\FunctionTok{ymd}\NormalTok{(}\StringTok{"2023{-}1{-}1"}\NormalTok{), }\AttributeTok{by =} \StringTok{"2 months"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] "2009-01-01" "2009-03-01" "2009-05-01" "2009-07-01" "2009-09-01"
 [6] "2009-11-01" "2010-01-01" "2010-03-01" "2010-05-01" "2010-07-01"
[11] "2010-09-01" "2010-11-01" "2011-01-01" "2011-03-01" "2011-05-01"
[16] "2011-07-01" "2011-09-01" "2011-11-01" "2012-01-01" "2012-03-01"
[21] "2012-05-01" "2012-07-01" "2012-09-01" "2012-11-01" "2013-01-01"
[26] "2013-03-01" "2013-05-01" "2013-07-01" "2013-09-01" "2013-11-01"
[31] "2014-01-01" "2014-03-01" "2014-05-01" "2014-07-01" "2014-09-01"
[36] "2014-11-01" "2015-01-01" "2015-03-01" "2015-05-01" "2015-07-01"
[41] "2015-09-01" "2015-11-01" "2016-01-01" "2016-03-01" "2016-05-01"
[46] "2016-07-01" "2016-09-01" "2016-11-01" "2017-01-01" "2017-03-01"
[51] "2017-05-01" "2017-07-01" "2017-09-01" "2017-11-01" "2018-01-01"
[56] "2018-03-01" "2018-05-01" "2018-07-01" "2018-09-01" "2018-11-01"
[61] "2019-01-01" "2019-03-01" "2019-05-01" "2019-07-01" "2019-09-01"
[66] "2019-11-01" "2020-01-01" "2020-03-01" "2020-05-01" "2020-07-01"
[71] "2020-09-01" "2020-11-01" "2021-01-01" "2021-03-01" "2021-05-01"
[76] "2021-07-01" "2021-09-01" "2021-11-01" "2022-01-01" "2022-03-01"
[81] "2022-05-01" "2022-07-01" "2022-09-01" "2022-11-01" "2023-01-01"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{seq}\NormalTok{(}\FunctionTok{ymd}\NormalTok{(}\StringTok{"2009{-}1{-}1"}\NormalTok{), }\FunctionTok{ymd}\NormalTok{(}\StringTok{"2023{-}1{-}1"}\NormalTok{), }\AttributeTok{by =} \StringTok{"1 day"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   [1] "2009-01-01" "2009-01-02" "2009-01-03" "2009-01-04" "2009-01-05"
   [6] "2009-01-06" "2009-01-07" "2009-01-08" "2009-01-09" "2009-01-10"
  [11] "2009-01-11" "2009-01-12" "2009-01-13" "2009-01-14" "2009-01-15"
  [16] "2009-01-16" "2009-01-17" "2009-01-18" "2009-01-19" "2009-01-20"
  [21] "2009-01-21" "2009-01-22" "2009-01-23" "2009-01-24" "2009-01-25"
  [26] "2009-01-26" "2009-01-27" "2009-01-28" "2009-01-29" "2009-01-30"
  [31] "2009-01-31" "2009-02-01" "2009-02-02" "2009-02-03" "2009-02-04"
  [36] "2009-02-05" "2009-02-06" "2009-02-07" "2009-02-08" "2009-02-09"
  [41] "2009-02-10" "2009-02-11" "2009-02-12" "2009-02-13" "2009-02-14"
  [46] "2009-02-15" "2009-02-16" "2009-02-17" "2009-02-18" "2009-02-19"
  [51] "2009-02-20" "2009-02-21" "2009-02-22" "2009-02-23" "2009-02-24"
  [56] "2009-02-25" "2009-02-26" "2009-02-27" "2009-02-28" "2009-03-01"
  [61] "2009-03-02" "2009-03-03" "2009-03-04" "2009-03-05" "2009-03-06"
  [66] "2009-03-07" "2009-03-08" "2009-03-09" "2009-03-10" "2009-03-11"
  [71] "2009-03-12" "2009-03-13" "2009-03-14" "2009-03-15" "2009-03-16"
  [76] "2009-03-17" "2009-03-18" "2009-03-19" "2009-03-20" "2009-03-21"
  [81] "2009-03-22" "2009-03-23" "2009-03-24" "2009-03-25" "2009-03-26"
  [86] "2009-03-27" "2009-03-28" "2009-03-29" "2009-03-30" "2009-03-31"
  [91] "2009-04-01" "2009-04-02" "2009-04-03" "2009-04-04" "2009-04-05"
  [96] "2009-04-06" "2009-04-07" "2009-04-08" "2009-04-09" "2009-04-10"
 [101] "2009-04-11" "2009-04-12" "2009-04-13" "2009-04-14" "2009-04-15"
 [106] "2009-04-16" "2009-04-17" "2009-04-18" "2009-04-19" "2009-04-20"
 [111] "2009-04-21" "2009-04-22" "2009-04-23" "2009-04-24" "2009-04-25"
 [116] "2009-04-26" "2009-04-27" "2009-04-28" "2009-04-29" "2009-04-30"
 [121] "2009-05-01" "2009-05-02" "2009-05-03" "2009-05-04" "2009-05-05"
 [126] "2009-05-06" "2009-05-07" "2009-05-08" "2009-05-09" "2009-05-10"
 [131] "2009-05-11" "2009-05-12" "2009-05-13" "2009-05-14" "2009-05-15"
 [136] "2009-05-16" "2009-05-17" "2009-05-18" "2009-05-19" "2009-05-20"
 [141] "2009-05-21" "2009-05-22" "2009-05-23" "2009-05-24" "2009-05-25"
 [146] "2009-05-26" "2009-05-27" "2009-05-28" "2009-05-29" "2009-05-30"
 [151] "2009-05-31" "2009-06-01" "2009-06-02" "2009-06-03" "2009-06-04"
 [156] "2009-06-05" "2009-06-06" "2009-06-07" "2009-06-08" "2009-06-09"
 [161] "2009-06-10" "2009-06-11" "2009-06-12" "2009-06-13" "2009-06-14"
 [166] "2009-06-15" "2009-06-16" "2009-06-17" "2009-06-18" "2009-06-19"
 [171] "2009-06-20" "2009-06-21" "2009-06-22" "2009-06-23" "2009-06-24"
 [176] "2009-06-25" "2009-06-26" "2009-06-27" "2009-06-28" "2009-06-29"
 [181] "2009-06-30" "2009-07-01" "2009-07-02" "2009-07-03" "2009-07-04"
 [186] "2009-07-05" "2009-07-06" "2009-07-07" "2009-07-08" "2009-07-09"
 [191] "2009-07-10" "2009-07-11" "2009-07-12" "2009-07-13" "2009-07-14"
 [196] "2009-07-15" "2009-07-16" "2009-07-17" "2009-07-18" "2009-07-19"
 [201] "2009-07-20" "2009-07-21" "2009-07-22" "2009-07-23" "2009-07-24"
 [206] "2009-07-25" "2009-07-26" "2009-07-27" "2009-07-28" "2009-07-29"
 [211] "2009-07-30" "2009-07-31" "2009-08-01" "2009-08-02" "2009-08-03"
 [216] "2009-08-04" "2009-08-05" "2009-08-06" "2009-08-07" "2009-08-08"
 [221] "2009-08-09" "2009-08-10" "2009-08-11" "2009-08-12" "2009-08-13"
 [226] "2009-08-14" "2009-08-15" "2009-08-16" "2009-08-17" "2009-08-18"
 [231] "2009-08-19" "2009-08-20" "2009-08-21" "2009-08-22" "2009-08-23"
 [236] "2009-08-24" "2009-08-25" "2009-08-26" "2009-08-27" "2009-08-28"
 [241] "2009-08-29" "2009-08-30" "2009-08-31" "2009-09-01" "2009-09-02"
 [246] "2009-09-03" "2009-09-04" "2009-09-05" "2009-09-06" "2009-09-07"
 [251] "2009-09-08" "2009-09-09" "2009-09-10" "2009-09-11" "2009-09-12"
 [256] "2009-09-13" "2009-09-14" "2009-09-15" "2009-09-16" "2009-09-17"
 [261] "2009-09-18" "2009-09-19" "2009-09-20" "2009-09-21" "2009-09-22"
 [266] "2009-09-23" "2009-09-24" "2009-09-25" "2009-09-26" "2009-09-27"
 [271] "2009-09-28" "2009-09-29" "2009-09-30" "2009-10-01" "2009-10-02"
 [276] "2009-10-03" "2009-10-04" "2009-10-05" "2009-10-06" "2009-10-07"
 [281] "2009-10-08" "2009-10-09" "2009-10-10" "2009-10-11" "2009-10-12"
 [286] "2009-10-13" "2009-10-14" "2009-10-15" "2009-10-16" "2009-10-17"
 [291] "2009-10-18" "2009-10-19" "2009-10-20" "2009-10-21" "2009-10-22"
 [296] "2009-10-23" "2009-10-24" "2009-10-25" "2009-10-26" "2009-10-27"
 [301] "2009-10-28" "2009-10-29" "2009-10-30" "2009-10-31" "2009-11-01"
 [306] "2009-11-02" "2009-11-03" "2009-11-04" "2009-11-05" "2009-11-06"
 [311] "2009-11-07" "2009-11-08" "2009-11-09" "2009-11-10" "2009-11-11"
 [316] "2009-11-12" "2009-11-13" "2009-11-14" "2009-11-15" "2009-11-16"
 [321] "2009-11-17" "2009-11-18" "2009-11-19" "2009-11-20" "2009-11-21"
 [326] "2009-11-22" "2009-11-23" "2009-11-24" "2009-11-25" "2009-11-26"
 [331] "2009-11-27" "2009-11-28" "2009-11-29" "2009-11-30" "2009-12-01"
 [336] "2009-12-02" "2009-12-03" "2009-12-04" "2009-12-05" "2009-12-06"
 [341] "2009-12-07" "2009-12-08" "2009-12-09" "2009-12-10" "2009-12-11"
 [346] "2009-12-12" "2009-12-13" "2009-12-14" "2009-12-15" "2009-12-16"
 [351] "2009-12-17" "2009-12-18" "2009-12-19" "2009-12-20" "2009-12-21"
 [356] "2009-12-22" "2009-12-23" "2009-12-24" "2009-12-25" "2009-12-26"
 [361] "2009-12-27" "2009-12-28" "2009-12-29" "2009-12-30" "2009-12-31"
 [366] "2010-01-01" "2010-01-02" "2010-01-03" "2010-01-04" "2010-01-05"
 [371] "2010-01-06" "2010-01-07" "2010-01-08" "2010-01-09" "2010-01-10"
 [376] "2010-01-11" "2010-01-12" "2010-01-13" "2010-01-14" "2010-01-15"
 [381] "2010-01-16" "2010-01-17" "2010-01-18" "2010-01-19" "2010-01-20"
 [386] "2010-01-21" "2010-01-22" "2010-01-23" "2010-01-24" "2010-01-25"
 [391] "2010-01-26" "2010-01-27" "2010-01-28" "2010-01-29" "2010-01-30"
 [396] "2010-01-31" "2010-02-01" "2010-02-02" "2010-02-03" "2010-02-04"
 [401] "2010-02-05" "2010-02-06" "2010-02-07" "2010-02-08" "2010-02-09"
 [406] "2010-02-10" "2010-02-11" "2010-02-12" "2010-02-13" "2010-02-14"
 [411] "2010-02-15" "2010-02-16" "2010-02-17" "2010-02-18" "2010-02-19"
 [416] "2010-02-20" "2010-02-21" "2010-02-22" "2010-02-23" "2010-02-24"
 [421] "2010-02-25" "2010-02-26" "2010-02-27" "2010-02-28" "2010-03-01"
 [426] "2010-03-02" "2010-03-03" "2010-03-04" "2010-03-05" "2010-03-06"
 [431] "2010-03-07" "2010-03-08" "2010-03-09" "2010-03-10" "2010-03-11"
 [436] "2010-03-12" "2010-03-13" "2010-03-14" "2010-03-15" "2010-03-16"
 [441] "2010-03-17" "2010-03-18" "2010-03-19" "2010-03-20" "2010-03-21"
 [446] "2010-03-22" "2010-03-23" "2010-03-24" "2010-03-25" "2010-03-26"
 [451] "2010-03-27" "2010-03-28" "2010-03-29" "2010-03-30" "2010-03-31"
 [456] "2010-04-01" "2010-04-02" "2010-04-03" "2010-04-04" "2010-04-05"
 [461] "2010-04-06" "2010-04-07" "2010-04-08" "2010-04-09" "2010-04-10"
 [466] "2010-04-11" "2010-04-12" "2010-04-13" "2010-04-14" "2010-04-15"
 [471] "2010-04-16" "2010-04-17" "2010-04-18" "2010-04-19" "2010-04-20"
 [476] "2010-04-21" "2010-04-22" "2010-04-23" "2010-04-24" "2010-04-25"
 [481] "2010-04-26" "2010-04-27" "2010-04-28" "2010-04-29" "2010-04-30"
 [486] "2010-05-01" "2010-05-02" "2010-05-03" "2010-05-04" "2010-05-05"
 [491] "2010-05-06" "2010-05-07" "2010-05-08" "2010-05-09" "2010-05-10"
 [496] "2010-05-11" "2010-05-12" "2010-05-13" "2010-05-14" "2010-05-15"
 [501] "2010-05-16" "2010-05-17" "2010-05-18" "2010-05-19" "2010-05-20"
 [506] "2010-05-21" "2010-05-22" "2010-05-23" "2010-05-24" "2010-05-25"
 [511] "2010-05-26" "2010-05-27" "2010-05-28" "2010-05-29" "2010-05-30"
 [516] "2010-05-31" "2010-06-01" "2010-06-02" "2010-06-03" "2010-06-04"
 [521] "2010-06-05" "2010-06-06" "2010-06-07" "2010-06-08" "2010-06-09"
 [526] "2010-06-10" "2010-06-11" "2010-06-12" "2010-06-13" "2010-06-14"
 [531] "2010-06-15" "2010-06-16" "2010-06-17" "2010-06-18" "2010-06-19"
 [536] "2010-06-20" "2010-06-21" "2010-06-22" "2010-06-23" "2010-06-24"
 [541] "2010-06-25" "2010-06-26" "2010-06-27" "2010-06-28" "2010-06-29"
 [546] "2010-06-30" "2010-07-01" "2010-07-02" "2010-07-03" "2010-07-04"
 [551] "2010-07-05" "2010-07-06" "2010-07-07" "2010-07-08" "2010-07-09"
 [556] "2010-07-10" "2010-07-11" "2010-07-12" "2010-07-13" "2010-07-14"
 [561] "2010-07-15" "2010-07-16" "2010-07-17" "2010-07-18" "2010-07-19"
 [566] "2010-07-20" "2010-07-21" "2010-07-22" "2010-07-23" "2010-07-24"
 [571] "2010-07-25" "2010-07-26" "2010-07-27" "2010-07-28" "2010-07-29"
 [576] "2010-07-30" "2010-07-31" "2010-08-01" "2010-08-02" "2010-08-03"
 [581] "2010-08-04" "2010-08-05" "2010-08-06" "2010-08-07" "2010-08-08"
 [586] "2010-08-09" "2010-08-10" "2010-08-11" "2010-08-12" "2010-08-13"
 [591] "2010-08-14" "2010-08-15" "2010-08-16" "2010-08-17" "2010-08-18"
 [596] "2010-08-19" "2010-08-20" "2010-08-21" "2010-08-22" "2010-08-23"
 [601] "2010-08-24" "2010-08-25" "2010-08-26" "2010-08-27" "2010-08-28"
 [606] "2010-08-29" "2010-08-30" "2010-08-31" "2010-09-01" "2010-09-02"
 [611] "2010-09-03" "2010-09-04" "2010-09-05" "2010-09-06" "2010-09-07"
 [616] "2010-09-08" "2010-09-09" "2010-09-10" "2010-09-11" "2010-09-12"
 [621] "2010-09-13" "2010-09-14" "2010-09-15" "2010-09-16" "2010-09-17"
 [626] "2010-09-18" "2010-09-19" "2010-09-20" "2010-09-21" "2010-09-22"
 [631] "2010-09-23" "2010-09-24" "2010-09-25" "2010-09-26" "2010-09-27"
 [636] "2010-09-28" "2010-09-29" "2010-09-30" "2010-10-01" "2010-10-02"
 [641] "2010-10-03" "2010-10-04" "2010-10-05" "2010-10-06" "2010-10-07"
 [646] "2010-10-08" "2010-10-09" "2010-10-10" "2010-10-11" "2010-10-12"
 [651] "2010-10-13" "2010-10-14" "2010-10-15" "2010-10-16" "2010-10-17"
 [656] "2010-10-18" "2010-10-19" "2010-10-20" "2010-10-21" "2010-10-22"
 [661] "2010-10-23" "2010-10-24" "2010-10-25" "2010-10-26" "2010-10-27"
 [666] "2010-10-28" "2010-10-29" "2010-10-30" "2010-10-31" "2010-11-01"
 [671] "2010-11-02" "2010-11-03" "2010-11-04" "2010-11-05" "2010-11-06"
 [676] "2010-11-07" "2010-11-08" "2010-11-09" "2010-11-10" "2010-11-11"
 [681] "2010-11-12" "2010-11-13" "2010-11-14" "2010-11-15" "2010-11-16"
 [686] "2010-11-17" "2010-11-18" "2010-11-19" "2010-11-20" "2010-11-21"
 [691] "2010-11-22" "2010-11-23" "2010-11-24" "2010-11-25" "2010-11-26"
 [696] "2010-11-27" "2010-11-28" "2010-11-29" "2010-11-30" "2010-12-01"
 [701] "2010-12-02" "2010-12-03" "2010-12-04" "2010-12-05" "2010-12-06"
 [706] "2010-12-07" "2010-12-08" "2010-12-09" "2010-12-10" "2010-12-11"
 [711] "2010-12-12" "2010-12-13" "2010-12-14" "2010-12-15" "2010-12-16"
 [716] "2010-12-17" "2010-12-18" "2010-12-19" "2010-12-20" "2010-12-21"
 [721] "2010-12-22" "2010-12-23" "2010-12-24" "2010-12-25" "2010-12-26"
 [726] "2010-12-27" "2010-12-28" "2010-12-29" "2010-12-30" "2010-12-31"
 [731] "2011-01-01" "2011-01-02" "2011-01-03" "2011-01-04" "2011-01-05"
 [736] "2011-01-06" "2011-01-07" "2011-01-08" "2011-01-09" "2011-01-10"
 [741] "2011-01-11" "2011-01-12" "2011-01-13" "2011-01-14" "2011-01-15"
 [746] "2011-01-16" "2011-01-17" "2011-01-18" "2011-01-19" "2011-01-20"
 [751] "2011-01-21" "2011-01-22" "2011-01-23" "2011-01-24" "2011-01-25"
 [756] "2011-01-26" "2011-01-27" "2011-01-28" "2011-01-29" "2011-01-30"
 [761] "2011-01-31" "2011-02-01" "2011-02-02" "2011-02-03" "2011-02-04"
 [766] "2011-02-05" "2011-02-06" "2011-02-07" "2011-02-08" "2011-02-09"
 [771] "2011-02-10" "2011-02-11" "2011-02-12" "2011-02-13" "2011-02-14"
 [776] "2011-02-15" "2011-02-16" "2011-02-17" "2011-02-18" "2011-02-19"
 [781] "2011-02-20" "2011-02-21" "2011-02-22" "2011-02-23" "2011-02-24"
 [786] "2011-02-25" "2011-02-26" "2011-02-27" "2011-02-28" "2011-03-01"
 [791] "2011-03-02" "2011-03-03" "2011-03-04" "2011-03-05" "2011-03-06"
 [796] "2011-03-07" "2011-03-08" "2011-03-09" "2011-03-10" "2011-03-11"
 [801] "2011-03-12" "2011-03-13" "2011-03-14" "2011-03-15" "2011-03-16"
 [806] "2011-03-17" "2011-03-18" "2011-03-19" "2011-03-20" "2011-03-21"
 [811] "2011-03-22" "2011-03-23" "2011-03-24" "2011-03-25" "2011-03-26"
 [816] "2011-03-27" "2011-03-28" "2011-03-29" "2011-03-30" "2011-03-31"
 [821] "2011-04-01" "2011-04-02" "2011-04-03" "2011-04-04" "2011-04-05"
 [826] "2011-04-06" "2011-04-07" "2011-04-08" "2011-04-09" "2011-04-10"
 [831] "2011-04-11" "2011-04-12" "2011-04-13" "2011-04-14" "2011-04-15"
 [836] "2011-04-16" "2011-04-17" "2011-04-18" "2011-04-19" "2011-04-20"
 [841] "2011-04-21" "2011-04-22" "2011-04-23" "2011-04-24" "2011-04-25"
 [846] "2011-04-26" "2011-04-27" "2011-04-28" "2011-04-29" "2011-04-30"
 [851] "2011-05-01" "2011-05-02" "2011-05-03" "2011-05-04" "2011-05-05"
 [856] "2011-05-06" "2011-05-07" "2011-05-08" "2011-05-09" "2011-05-10"
 [861] "2011-05-11" "2011-05-12" "2011-05-13" "2011-05-14" "2011-05-15"
 [866] "2011-05-16" "2011-05-17" "2011-05-18" "2011-05-19" "2011-05-20"
 [871] "2011-05-21" "2011-05-22" "2011-05-23" "2011-05-24" "2011-05-25"
 [876] "2011-05-26" "2011-05-27" "2011-05-28" "2011-05-29" "2011-05-30"
 [881] "2011-05-31" "2011-06-01" "2011-06-02" "2011-06-03" "2011-06-04"
 [886] "2011-06-05" "2011-06-06" "2011-06-07" "2011-06-08" "2011-06-09"
 [891] "2011-06-10" "2011-06-11" "2011-06-12" "2011-06-13" "2011-06-14"
 [896] "2011-06-15" "2011-06-16" "2011-06-17" "2011-06-18" "2011-06-19"
 [901] "2011-06-20" "2011-06-21" "2011-06-22" "2011-06-23" "2011-06-24"
 [906] "2011-06-25" "2011-06-26" "2011-06-27" "2011-06-28" "2011-06-29"
 [911] "2011-06-30" "2011-07-01" "2011-07-02" "2011-07-03" "2011-07-04"
 [916] "2011-07-05" "2011-07-06" "2011-07-07" "2011-07-08" "2011-07-09"
 [921] "2011-07-10" "2011-07-11" "2011-07-12" "2011-07-13" "2011-07-14"
 [926] "2011-07-15" "2011-07-16" "2011-07-17" "2011-07-18" "2011-07-19"
 [931] "2011-07-20" "2011-07-21" "2011-07-22" "2011-07-23" "2011-07-24"
 [936] "2011-07-25" "2011-07-26" "2011-07-27" "2011-07-28" "2011-07-29"
 [941] "2011-07-30" "2011-07-31" "2011-08-01" "2011-08-02" "2011-08-03"
 [946] "2011-08-04" "2011-08-05" "2011-08-06" "2011-08-07" "2011-08-08"
 [951] "2011-08-09" "2011-08-10" "2011-08-11" "2011-08-12" "2011-08-13"
 [956] "2011-08-14" "2011-08-15" "2011-08-16" "2011-08-17" "2011-08-18"
 [961] "2011-08-19" "2011-08-20" "2011-08-21" "2011-08-22" "2011-08-23"
 [966] "2011-08-24" "2011-08-25" "2011-08-26" "2011-08-27" "2011-08-28"
 [971] "2011-08-29" "2011-08-30" "2011-08-31" "2011-09-01" "2011-09-02"
 [976] "2011-09-03" "2011-09-04" "2011-09-05" "2011-09-06" "2011-09-07"
 [981] "2011-09-08" "2011-09-09" "2011-09-10" "2011-09-11" "2011-09-12"
 [986] "2011-09-13" "2011-09-14" "2011-09-15" "2011-09-16" "2011-09-17"
 [991] "2011-09-18" "2011-09-19" "2011-09-20" "2011-09-21" "2011-09-22"
 [996] "2011-09-23" "2011-09-24" "2011-09-25" "2011-09-26" "2011-09-27"
[1001] "2011-09-28" "2011-09-29" "2011-09-30" "2011-10-01" "2011-10-02"
[1006] "2011-10-03" "2011-10-04" "2011-10-05" "2011-10-06" "2011-10-07"
[1011] "2011-10-08" "2011-10-09" "2011-10-10" "2011-10-11" "2011-10-12"
[1016] "2011-10-13" "2011-10-14" "2011-10-15" "2011-10-16" "2011-10-17"
[1021] "2011-10-18" "2011-10-19" "2011-10-20" "2011-10-21" "2011-10-22"
[1026] "2011-10-23" "2011-10-24" "2011-10-25" "2011-10-26" "2011-10-27"
[1031] "2011-10-28" "2011-10-29" "2011-10-30" "2011-10-31" "2011-11-01"
[1036] "2011-11-02" "2011-11-03" "2011-11-04" "2011-11-05" "2011-11-06"
[1041] "2011-11-07" "2011-11-08" "2011-11-09" "2011-11-10" "2011-11-11"
[1046] "2011-11-12" "2011-11-13" "2011-11-14" "2011-11-15" "2011-11-16"
[1051] "2011-11-17" "2011-11-18" "2011-11-19" "2011-11-20" "2011-11-21"
[1056] "2011-11-22" "2011-11-23" "2011-11-24" "2011-11-25" "2011-11-26"
[1061] "2011-11-27" "2011-11-28" "2011-11-29" "2011-11-30" "2011-12-01"
[1066] "2011-12-02" "2011-12-03" "2011-12-04" "2011-12-05" "2011-12-06"
[1071] "2011-12-07" "2011-12-08" "2011-12-09" "2011-12-10" "2011-12-11"
[1076] "2011-12-12" "2011-12-13" "2011-12-14" "2011-12-15" "2011-12-16"
[1081] "2011-12-17" "2011-12-18" "2011-12-19" "2011-12-20" "2011-12-21"
[1086] "2011-12-22" "2011-12-23" "2011-12-24" "2011-12-25" "2011-12-26"
[1091] "2011-12-27" "2011-12-28" "2011-12-29" "2011-12-30" "2011-12-31"
[1096] "2012-01-01" "2012-01-02" "2012-01-03" "2012-01-04" "2012-01-05"
[1101] "2012-01-06" "2012-01-07" "2012-01-08" "2012-01-09" "2012-01-10"
[1106] "2012-01-11" "2012-01-12" "2012-01-13" "2012-01-14" "2012-01-15"
[1111] "2012-01-16" "2012-01-17" "2012-01-18" "2012-01-19" "2012-01-20"
[1116] "2012-01-21" "2012-01-22" "2012-01-23" "2012-01-24" "2012-01-25"
[1121] "2012-01-26" "2012-01-27" "2012-01-28" "2012-01-29" "2012-01-30"
[1126] "2012-01-31" "2012-02-01" "2012-02-02" "2012-02-03" "2012-02-04"
[1131] "2012-02-05" "2012-02-06" "2012-02-07" "2012-02-08" "2012-02-09"
[1136] "2012-02-10" "2012-02-11" "2012-02-12" "2012-02-13" "2012-02-14"
[1141] "2012-02-15" "2012-02-16" "2012-02-17" "2012-02-18" "2012-02-19"
[1146] "2012-02-20" "2012-02-21" "2012-02-22" "2012-02-23" "2012-02-24"
[1151] "2012-02-25" "2012-02-26" "2012-02-27" "2012-02-28" "2012-02-29"
[1156] "2012-03-01" "2012-03-02" "2012-03-03" "2012-03-04" "2012-03-05"
[1161] "2012-03-06" "2012-03-07" "2012-03-08" "2012-03-09" "2012-03-10"
[1166] "2012-03-11" "2012-03-12" "2012-03-13" "2012-03-14" "2012-03-15"
[1171] "2012-03-16" "2012-03-17" "2012-03-18" "2012-03-19" "2012-03-20"
[1176] "2012-03-21" "2012-03-22" "2012-03-23" "2012-03-24" "2012-03-25"
[1181] "2012-03-26" "2012-03-27" "2012-03-28" "2012-03-29" "2012-03-30"
[1186] "2012-03-31" "2012-04-01" "2012-04-02" "2012-04-03" "2012-04-04"
[1191] "2012-04-05" "2012-04-06" "2012-04-07" "2012-04-08" "2012-04-09"
[1196] "2012-04-10" "2012-04-11" "2012-04-12" "2012-04-13" "2012-04-14"
[1201] "2012-04-15" "2012-04-16" "2012-04-17" "2012-04-18" "2012-04-19"
[1206] "2012-04-20" "2012-04-21" "2012-04-22" "2012-04-23" "2012-04-24"
[1211] "2012-04-25" "2012-04-26" "2012-04-27" "2012-04-28" "2012-04-29"
[1216] "2012-04-30" "2012-05-01" "2012-05-02" "2012-05-03" "2012-05-04"
[1221] "2012-05-05" "2012-05-06" "2012-05-07" "2012-05-08" "2012-05-09"
[1226] "2012-05-10" "2012-05-11" "2012-05-12" "2012-05-13" "2012-05-14"
[1231] "2012-05-15" "2012-05-16" "2012-05-17" "2012-05-18" "2012-05-19"
[1236] "2012-05-20" "2012-05-21" "2012-05-22" "2012-05-23" "2012-05-24"
[1241] "2012-05-25" "2012-05-26" "2012-05-27" "2012-05-28" "2012-05-29"
[1246] "2012-05-30" "2012-05-31" "2012-06-01" "2012-06-02" "2012-06-03"
[1251] "2012-06-04" "2012-06-05" "2012-06-06" "2012-06-07" "2012-06-08"
[1256] "2012-06-09" "2012-06-10" "2012-06-11" "2012-06-12" "2012-06-13"
[1261] "2012-06-14" "2012-06-15" "2012-06-16" "2012-06-17" "2012-06-18"
[1266] "2012-06-19" "2012-06-20" "2012-06-21" "2012-06-22" "2012-06-23"
[1271] "2012-06-24" "2012-06-25" "2012-06-26" "2012-06-27" "2012-06-28"
[1276] "2012-06-29" "2012-06-30" "2012-07-01" "2012-07-02" "2012-07-03"
[1281] "2012-07-04" "2012-07-05" "2012-07-06" "2012-07-07" "2012-07-08"
[1286] "2012-07-09" "2012-07-10" "2012-07-11" "2012-07-12" "2012-07-13"
[1291] "2012-07-14" "2012-07-15" "2012-07-16" "2012-07-17" "2012-07-18"
[1296] "2012-07-19" "2012-07-20" "2012-07-21" "2012-07-22" "2012-07-23"
[1301] "2012-07-24" "2012-07-25" "2012-07-26" "2012-07-27" "2012-07-28"
[1306] "2012-07-29" "2012-07-30" "2012-07-31" "2012-08-01" "2012-08-02"
[1311] "2012-08-03" "2012-08-04" "2012-08-05" "2012-08-06" "2012-08-07"
[1316] "2012-08-08" "2012-08-09" "2012-08-10" "2012-08-11" "2012-08-12"
[1321] "2012-08-13" "2012-08-14" "2012-08-15" "2012-08-16" "2012-08-17"
[1326] "2012-08-18" "2012-08-19" "2012-08-20" "2012-08-21" "2012-08-22"
[1331] "2012-08-23" "2012-08-24" "2012-08-25" "2012-08-26" "2012-08-27"
[1336] "2012-08-28" "2012-08-29" "2012-08-30" "2012-08-31" "2012-09-01"
[1341] "2012-09-02" "2012-09-03" "2012-09-04" "2012-09-05" "2012-09-06"
[1346] "2012-09-07" "2012-09-08" "2012-09-09" "2012-09-10" "2012-09-11"
[1351] "2012-09-12" "2012-09-13" "2012-09-14" "2012-09-15" "2012-09-16"
[1356] "2012-09-17" "2012-09-18" "2012-09-19" "2012-09-20" "2012-09-21"
[1361] "2012-09-22" "2012-09-23" "2012-09-24" "2012-09-25" "2012-09-26"
[1366] "2012-09-27" "2012-09-28" "2012-09-29" "2012-09-30" "2012-10-01"
[1371] "2012-10-02" "2012-10-03" "2012-10-04" "2012-10-05" "2012-10-06"
[1376] "2012-10-07" "2012-10-08" "2012-10-09" "2012-10-10" "2012-10-11"
[1381] "2012-10-12" "2012-10-13" "2012-10-14" "2012-10-15" "2012-10-16"
[1386] "2012-10-17" "2012-10-18" "2012-10-19" "2012-10-20" "2012-10-21"
[1391] "2012-10-22" "2012-10-23" "2012-10-24" "2012-10-25" "2012-10-26"
[1396] "2012-10-27" "2012-10-28" "2012-10-29" "2012-10-30" "2012-10-31"
[1401] "2012-11-01" "2012-11-02" "2012-11-03" "2012-11-04" "2012-11-05"
[1406] "2012-11-06" "2012-11-07" "2012-11-08" "2012-11-09" "2012-11-10"
[1411] "2012-11-11" "2012-11-12" "2012-11-13" "2012-11-14" "2012-11-15"
[1416] "2012-11-16" "2012-11-17" "2012-11-18" "2012-11-19" "2012-11-20"
[1421] "2012-11-21" "2012-11-22" "2012-11-23" "2012-11-24" "2012-11-25"
[1426] "2012-11-26" "2012-11-27" "2012-11-28" "2012-11-29" "2012-11-30"
[1431] "2012-12-01" "2012-12-02" "2012-12-03" "2012-12-04" "2012-12-05"
[1436] "2012-12-06" "2012-12-07" "2012-12-08" "2012-12-09" "2012-12-10"
[1441] "2012-12-11" "2012-12-12" "2012-12-13" "2012-12-14" "2012-12-15"
[1446] "2012-12-16" "2012-12-17" "2012-12-18" "2012-12-19" "2012-12-20"
[1451] "2012-12-21" "2012-12-22" "2012-12-23" "2012-12-24" "2012-12-25"
[1456] "2012-12-26" "2012-12-27" "2012-12-28" "2012-12-29" "2012-12-30"
[1461] "2012-12-31" "2013-01-01" "2013-01-02" "2013-01-03" "2013-01-04"
[1466] "2013-01-05" "2013-01-06" "2013-01-07" "2013-01-08" "2013-01-09"
[1471] "2013-01-10" "2013-01-11" "2013-01-12" "2013-01-13" "2013-01-14"
[1476] "2013-01-15" "2013-01-16" "2013-01-17" "2013-01-18" "2013-01-19"
[1481] "2013-01-20" "2013-01-21" "2013-01-22" "2013-01-23" "2013-01-24"
[1486] "2013-01-25" "2013-01-26" "2013-01-27" "2013-01-28" "2013-01-29"
[1491] "2013-01-30" "2013-01-31" "2013-02-01" "2013-02-02" "2013-02-03"
[1496] "2013-02-04" "2013-02-05" "2013-02-06" "2013-02-07" "2013-02-08"
[1501] "2013-02-09" "2013-02-10" "2013-02-11" "2013-02-12" "2013-02-13"
[1506] "2013-02-14" "2013-02-15" "2013-02-16" "2013-02-17" "2013-02-18"
[1511] "2013-02-19" "2013-02-20" "2013-02-21" "2013-02-22" "2013-02-23"
[1516] "2013-02-24" "2013-02-25" "2013-02-26" "2013-02-27" "2013-02-28"
[1521] "2013-03-01" "2013-03-02" "2013-03-03" "2013-03-04" "2013-03-05"
[1526] "2013-03-06" "2013-03-07" "2013-03-08" "2013-03-09" "2013-03-10"
[1531] "2013-03-11" "2013-03-12" "2013-03-13" "2013-03-14" "2013-03-15"
[1536] "2013-03-16" "2013-03-17" "2013-03-18" "2013-03-19" "2013-03-20"
[1541] "2013-03-21" "2013-03-22" "2013-03-23" "2013-03-24" "2013-03-25"
[1546] "2013-03-26" "2013-03-27" "2013-03-28" "2013-03-29" "2013-03-30"
[1551] "2013-03-31" "2013-04-01" "2013-04-02" "2013-04-03" "2013-04-04"
[1556] "2013-04-05" "2013-04-06" "2013-04-07" "2013-04-08" "2013-04-09"
[1561] "2013-04-10" "2013-04-11" "2013-04-12" "2013-04-13" "2013-04-14"
[1566] "2013-04-15" "2013-04-16" "2013-04-17" "2013-04-18" "2013-04-19"
[1571] "2013-04-20" "2013-04-21" "2013-04-22" "2013-04-23" "2013-04-24"
[1576] "2013-04-25" "2013-04-26" "2013-04-27" "2013-04-28" "2013-04-29"
[1581] "2013-04-30" "2013-05-01" "2013-05-02" "2013-05-03" "2013-05-04"
[1586] "2013-05-05" "2013-05-06" "2013-05-07" "2013-05-08" "2013-05-09"
[1591] "2013-05-10" "2013-05-11" "2013-05-12" "2013-05-13" "2013-05-14"
[1596] "2013-05-15" "2013-05-16" "2013-05-17" "2013-05-18" "2013-05-19"
[1601] "2013-05-20" "2013-05-21" "2013-05-22" "2013-05-23" "2013-05-24"
[1606] "2013-05-25" "2013-05-26" "2013-05-27" "2013-05-28" "2013-05-29"
[1611] "2013-05-30" "2013-05-31" "2013-06-01" "2013-06-02" "2013-06-03"
[1616] "2013-06-04" "2013-06-05" "2013-06-06" "2013-06-07" "2013-06-08"
[1621] "2013-06-09" "2013-06-10" "2013-06-11" "2013-06-12" "2013-06-13"
[1626] "2013-06-14" "2013-06-15" "2013-06-16" "2013-06-17" "2013-06-18"
[1631] "2013-06-19" "2013-06-20" "2013-06-21" "2013-06-22" "2013-06-23"
[1636] "2013-06-24" "2013-06-25" "2013-06-26" "2013-06-27" "2013-06-28"
[1641] "2013-06-29" "2013-06-30" "2013-07-01" "2013-07-02" "2013-07-03"
[1646] "2013-07-04" "2013-07-05" "2013-07-06" "2013-07-07" "2013-07-08"
[1651] "2013-07-09" "2013-07-10" "2013-07-11" "2013-07-12" "2013-07-13"
[1656] "2013-07-14" "2013-07-15" "2013-07-16" "2013-07-17" "2013-07-18"
[1661] "2013-07-19" "2013-07-20" "2013-07-21" "2013-07-22" "2013-07-23"
[1666] "2013-07-24" "2013-07-25" "2013-07-26" "2013-07-27" "2013-07-28"
[1671] "2013-07-29" "2013-07-30" "2013-07-31" "2013-08-01" "2013-08-02"
[1676] "2013-08-03" "2013-08-04" "2013-08-05" "2013-08-06" "2013-08-07"
[1681] "2013-08-08" "2013-08-09" "2013-08-10" "2013-08-11" "2013-08-12"
[1686] "2013-08-13" "2013-08-14" "2013-08-15" "2013-08-16" "2013-08-17"
[1691] "2013-08-18" "2013-08-19" "2013-08-20" "2013-08-21" "2013-08-22"
[1696] "2013-08-23" "2013-08-24" "2013-08-25" "2013-08-26" "2013-08-27"
[1701] "2013-08-28" "2013-08-29" "2013-08-30" "2013-08-31" "2013-09-01"
[1706] "2013-09-02" "2013-09-03" "2013-09-04" "2013-09-05" "2013-09-06"
[1711] "2013-09-07" "2013-09-08" "2013-09-09" "2013-09-10" "2013-09-11"
[1716] "2013-09-12" "2013-09-13" "2013-09-14" "2013-09-15" "2013-09-16"
[1721] "2013-09-17" "2013-09-18" "2013-09-19" "2013-09-20" "2013-09-21"
[1726] "2013-09-22" "2013-09-23" "2013-09-24" "2013-09-25" "2013-09-26"
[1731] "2013-09-27" "2013-09-28" "2013-09-29" "2013-09-30" "2013-10-01"
[1736] "2013-10-02" "2013-10-03" "2013-10-04" "2013-10-05" "2013-10-06"
[1741] "2013-10-07" "2013-10-08" "2013-10-09" "2013-10-10" "2013-10-11"
[1746] "2013-10-12" "2013-10-13" "2013-10-14" "2013-10-15" "2013-10-16"
[1751] "2013-10-17" "2013-10-18" "2013-10-19" "2013-10-20" "2013-10-21"
[1756] "2013-10-22" "2013-10-23" "2013-10-24" "2013-10-25" "2013-10-26"
[1761] "2013-10-27" "2013-10-28" "2013-10-29" "2013-10-30" "2013-10-31"
[1766] "2013-11-01" "2013-11-02" "2013-11-03" "2013-11-04" "2013-11-05"
[1771] "2013-11-06" "2013-11-07" "2013-11-08" "2013-11-09" "2013-11-10"
[1776] "2013-11-11" "2013-11-12" "2013-11-13" "2013-11-14" "2013-11-15"
[1781] "2013-11-16" "2013-11-17" "2013-11-18" "2013-11-19" "2013-11-20"
[1786] "2013-11-21" "2013-11-22" "2013-11-23" "2013-11-24" "2013-11-25"
[1791] "2013-11-26" "2013-11-27" "2013-11-28" "2013-11-29" "2013-11-30"
[1796] "2013-12-01" "2013-12-02" "2013-12-03" "2013-12-04" "2013-12-05"
[1801] "2013-12-06" "2013-12-07" "2013-12-08" "2013-12-09" "2013-12-10"
[1806] "2013-12-11" "2013-12-12" "2013-12-13" "2013-12-14" "2013-12-15"
[1811] "2013-12-16" "2013-12-17" "2013-12-18" "2013-12-19" "2013-12-20"
[1816] "2013-12-21" "2013-12-22" "2013-12-23" "2013-12-24" "2013-12-25"
[1821] "2013-12-26" "2013-12-27" "2013-12-28" "2013-12-29" "2013-12-30"
[1826] "2013-12-31" "2014-01-01" "2014-01-02" "2014-01-03" "2014-01-04"
[1831] "2014-01-05" "2014-01-06" "2014-01-07" "2014-01-08" "2014-01-09"
[1836] "2014-01-10" "2014-01-11" "2014-01-12" "2014-01-13" "2014-01-14"
[1841] "2014-01-15" "2014-01-16" "2014-01-17" "2014-01-18" "2014-01-19"
[1846] "2014-01-20" "2014-01-21" "2014-01-22" "2014-01-23" "2014-01-24"
[1851] "2014-01-25" "2014-01-26" "2014-01-27" "2014-01-28" "2014-01-29"
[1856] "2014-01-30" "2014-01-31" "2014-02-01" "2014-02-02" "2014-02-03"
[1861] "2014-02-04" "2014-02-05" "2014-02-06" "2014-02-07" "2014-02-08"
[1866] "2014-02-09" "2014-02-10" "2014-02-11" "2014-02-12" "2014-02-13"
[1871] "2014-02-14" "2014-02-15" "2014-02-16" "2014-02-17" "2014-02-18"
[1876] "2014-02-19" "2014-02-20" "2014-02-21" "2014-02-22" "2014-02-23"
[1881] "2014-02-24" "2014-02-25" "2014-02-26" "2014-02-27" "2014-02-28"
[1886] "2014-03-01" "2014-03-02" "2014-03-03" "2014-03-04" "2014-03-05"
[1891] "2014-03-06" "2014-03-07" "2014-03-08" "2014-03-09" "2014-03-10"
[1896] "2014-03-11" "2014-03-12" "2014-03-13" "2014-03-14" "2014-03-15"
[1901] "2014-03-16" "2014-03-17" "2014-03-18" "2014-03-19" "2014-03-20"
[1906] "2014-03-21" "2014-03-22" "2014-03-23" "2014-03-24" "2014-03-25"
[1911] "2014-03-26" "2014-03-27" "2014-03-28" "2014-03-29" "2014-03-30"
[1916] "2014-03-31" "2014-04-01" "2014-04-02" "2014-04-03" "2014-04-04"
[1921] "2014-04-05" "2014-04-06" "2014-04-07" "2014-04-08" "2014-04-09"
[1926] "2014-04-10" "2014-04-11" "2014-04-12" "2014-04-13" "2014-04-14"
[1931] "2014-04-15" "2014-04-16" "2014-04-17" "2014-04-18" "2014-04-19"
[1936] "2014-04-20" "2014-04-21" "2014-04-22" "2014-04-23" "2014-04-24"
[1941] "2014-04-25" "2014-04-26" "2014-04-27" "2014-04-28" "2014-04-29"
[1946] "2014-04-30" "2014-05-01" "2014-05-02" "2014-05-03" "2014-05-04"
[1951] "2014-05-05" "2014-05-06" "2014-05-07" "2014-05-08" "2014-05-09"
[1956] "2014-05-10" "2014-05-11" "2014-05-12" "2014-05-13" "2014-05-14"
[1961] "2014-05-15" "2014-05-16" "2014-05-17" "2014-05-18" "2014-05-19"
[1966] "2014-05-20" "2014-05-21" "2014-05-22" "2014-05-23" "2014-05-24"
[1971] "2014-05-25" "2014-05-26" "2014-05-27" "2014-05-28" "2014-05-29"
[1976] "2014-05-30" "2014-05-31" "2014-06-01" "2014-06-02" "2014-06-03"
[1981] "2014-06-04" "2014-06-05" "2014-06-06" "2014-06-07" "2014-06-08"
[1986] "2014-06-09" "2014-06-10" "2014-06-11" "2014-06-12" "2014-06-13"
[1991] "2014-06-14" "2014-06-15" "2014-06-16" "2014-06-17" "2014-06-18"
[1996] "2014-06-19" "2014-06-20" "2014-06-21" "2014-06-22" "2014-06-23"
[2001] "2014-06-24" "2014-06-25" "2014-06-26" "2014-06-27" "2014-06-28"
[2006] "2014-06-29" "2014-06-30" "2014-07-01" "2014-07-02" "2014-07-03"
[2011] "2014-07-04" "2014-07-05" "2014-07-06" "2014-07-07" "2014-07-08"
[2016] "2014-07-09" "2014-07-10" "2014-07-11" "2014-07-12" "2014-07-13"
[2021] "2014-07-14" "2014-07-15" "2014-07-16" "2014-07-17" "2014-07-18"
[2026] "2014-07-19" "2014-07-20" "2014-07-21" "2014-07-22" "2014-07-23"
[2031] "2014-07-24" "2014-07-25" "2014-07-26" "2014-07-27" "2014-07-28"
[2036] "2014-07-29" "2014-07-30" "2014-07-31" "2014-08-01" "2014-08-02"
[2041] "2014-08-03" "2014-08-04" "2014-08-05" "2014-08-06" "2014-08-07"
[2046] "2014-08-08" "2014-08-09" "2014-08-10" "2014-08-11" "2014-08-12"
[2051] "2014-08-13" "2014-08-14" "2014-08-15" "2014-08-16" "2014-08-17"
[2056] "2014-08-18" "2014-08-19" "2014-08-20" "2014-08-21" "2014-08-22"
[2061] "2014-08-23" "2014-08-24" "2014-08-25" "2014-08-26" "2014-08-27"
[2066] "2014-08-28" "2014-08-29" "2014-08-30" "2014-08-31" "2014-09-01"
[2071] "2014-09-02" "2014-09-03" "2014-09-04" "2014-09-05" "2014-09-06"
[2076] "2014-09-07" "2014-09-08" "2014-09-09" "2014-09-10" "2014-09-11"
[2081] "2014-09-12" "2014-09-13" "2014-09-14" "2014-09-15" "2014-09-16"
[2086] "2014-09-17" "2014-09-18" "2014-09-19" "2014-09-20" "2014-09-21"
[2091] "2014-09-22" "2014-09-23" "2014-09-24" "2014-09-25" "2014-09-26"
[2096] "2014-09-27" "2014-09-28" "2014-09-29" "2014-09-30" "2014-10-01"
[2101] "2014-10-02" "2014-10-03" "2014-10-04" "2014-10-05" "2014-10-06"
[2106] "2014-10-07" "2014-10-08" "2014-10-09" "2014-10-10" "2014-10-11"
[2111] "2014-10-12" "2014-10-13" "2014-10-14" "2014-10-15" "2014-10-16"
[2116] "2014-10-17" "2014-10-18" "2014-10-19" "2014-10-20" "2014-10-21"
[2121] "2014-10-22" "2014-10-23" "2014-10-24" "2014-10-25" "2014-10-26"
[2126] "2014-10-27" "2014-10-28" "2014-10-29" "2014-10-30" "2014-10-31"
[2131] "2014-11-01" "2014-11-02" "2014-11-03" "2014-11-04" "2014-11-05"
[2136] "2014-11-06" "2014-11-07" "2014-11-08" "2014-11-09" "2014-11-10"
[2141] "2014-11-11" "2014-11-12" "2014-11-13" "2014-11-14" "2014-11-15"
[2146] "2014-11-16" "2014-11-17" "2014-11-18" "2014-11-19" "2014-11-20"
[2151] "2014-11-21" "2014-11-22" "2014-11-23" "2014-11-24" "2014-11-25"
[2156] "2014-11-26" "2014-11-27" "2014-11-28" "2014-11-29" "2014-11-30"
[2161] "2014-12-01" "2014-12-02" "2014-12-03" "2014-12-04" "2014-12-05"
[2166] "2014-12-06" "2014-12-07" "2014-12-08" "2014-12-09" "2014-12-10"
[2171] "2014-12-11" "2014-12-12" "2014-12-13" "2014-12-14" "2014-12-15"
[2176] "2014-12-16" "2014-12-17" "2014-12-18" "2014-12-19" "2014-12-20"
[2181] "2014-12-21" "2014-12-22" "2014-12-23" "2014-12-24" "2014-12-25"
[2186] "2014-12-26" "2014-12-27" "2014-12-28" "2014-12-29" "2014-12-30"
[2191] "2014-12-31" "2015-01-01" "2015-01-02" "2015-01-03" "2015-01-04"
[2196] "2015-01-05" "2015-01-06" "2015-01-07" "2015-01-08" "2015-01-09"
[2201] "2015-01-10" "2015-01-11" "2015-01-12" "2015-01-13" "2015-01-14"
[2206] "2015-01-15" "2015-01-16" "2015-01-17" "2015-01-18" "2015-01-19"
[2211] "2015-01-20" "2015-01-21" "2015-01-22" "2015-01-23" "2015-01-24"
[2216] "2015-01-25" "2015-01-26" "2015-01-27" "2015-01-28" "2015-01-29"
[2221] "2015-01-30" "2015-01-31" "2015-02-01" "2015-02-02" "2015-02-03"
[2226] "2015-02-04" "2015-02-05" "2015-02-06" "2015-02-07" "2015-02-08"
[2231] "2015-02-09" "2015-02-10" "2015-02-11" "2015-02-12" "2015-02-13"
[2236] "2015-02-14" "2015-02-15" "2015-02-16" "2015-02-17" "2015-02-18"
[2241] "2015-02-19" "2015-02-20" "2015-02-21" "2015-02-22" "2015-02-23"
[2246] "2015-02-24" "2015-02-25" "2015-02-26" "2015-02-27" "2015-02-28"
[2251] "2015-03-01" "2015-03-02" "2015-03-03" "2015-03-04" "2015-03-05"
[2256] "2015-03-06" "2015-03-07" "2015-03-08" "2015-03-09" "2015-03-10"
[2261] "2015-03-11" "2015-03-12" "2015-03-13" "2015-03-14" "2015-03-15"
[2266] "2015-03-16" "2015-03-17" "2015-03-18" "2015-03-19" "2015-03-20"
[2271] "2015-03-21" "2015-03-22" "2015-03-23" "2015-03-24" "2015-03-25"
[2276] "2015-03-26" "2015-03-27" "2015-03-28" "2015-03-29" "2015-03-30"
[2281] "2015-03-31" "2015-04-01" "2015-04-02" "2015-04-03" "2015-04-04"
[2286] "2015-04-05" "2015-04-06" "2015-04-07" "2015-04-08" "2015-04-09"
[2291] "2015-04-10" "2015-04-11" "2015-04-12" "2015-04-13" "2015-04-14"
[2296] "2015-04-15" "2015-04-16" "2015-04-17" "2015-04-18" "2015-04-19"
[2301] "2015-04-20" "2015-04-21" "2015-04-22" "2015-04-23" "2015-04-24"
[2306] "2015-04-25" "2015-04-26" "2015-04-27" "2015-04-28" "2015-04-29"
[2311] "2015-04-30" "2015-05-01" "2015-05-02" "2015-05-03" "2015-05-04"
[2316] "2015-05-05" "2015-05-06" "2015-05-07" "2015-05-08" "2015-05-09"
[2321] "2015-05-10" "2015-05-11" "2015-05-12" "2015-05-13" "2015-05-14"
[2326] "2015-05-15" "2015-05-16" "2015-05-17" "2015-05-18" "2015-05-19"
[2331] "2015-05-20" "2015-05-21" "2015-05-22" "2015-05-23" "2015-05-24"
[2336] "2015-05-25" "2015-05-26" "2015-05-27" "2015-05-28" "2015-05-29"
[2341] "2015-05-30" "2015-05-31" "2015-06-01" "2015-06-02" "2015-06-03"
[2346] "2015-06-04" "2015-06-05" "2015-06-06" "2015-06-07" "2015-06-08"
[2351] "2015-06-09" "2015-06-10" "2015-06-11" "2015-06-12" "2015-06-13"
[2356] "2015-06-14" "2015-06-15" "2015-06-16" "2015-06-17" "2015-06-18"
[2361] "2015-06-19" "2015-06-20" "2015-06-21" "2015-06-22" "2015-06-23"
[2366] "2015-06-24" "2015-06-25" "2015-06-26" "2015-06-27" "2015-06-28"
[2371] "2015-06-29" "2015-06-30" "2015-07-01" "2015-07-02" "2015-07-03"
[2376] "2015-07-04" "2015-07-05" "2015-07-06" "2015-07-07" "2015-07-08"
[2381] "2015-07-09" "2015-07-10" "2015-07-11" "2015-07-12" "2015-07-13"
[2386] "2015-07-14" "2015-07-15" "2015-07-16" "2015-07-17" "2015-07-18"
[2391] "2015-07-19" "2015-07-20" "2015-07-21" "2015-07-22" "2015-07-23"
[2396] "2015-07-24" "2015-07-25" "2015-07-26" "2015-07-27" "2015-07-28"
[2401] "2015-07-29" "2015-07-30" "2015-07-31" "2015-08-01" "2015-08-02"
[2406] "2015-08-03" "2015-08-04" "2015-08-05" "2015-08-06" "2015-08-07"
[2411] "2015-08-08" "2015-08-09" "2015-08-10" "2015-08-11" "2015-08-12"
[2416] "2015-08-13" "2015-08-14" "2015-08-15" "2015-08-16" "2015-08-17"
[2421] "2015-08-18" "2015-08-19" "2015-08-20" "2015-08-21" "2015-08-22"
[2426] "2015-08-23" "2015-08-24" "2015-08-25" "2015-08-26" "2015-08-27"
[2431] "2015-08-28" "2015-08-29" "2015-08-30" "2015-08-31" "2015-09-01"
[2436] "2015-09-02" "2015-09-03" "2015-09-04" "2015-09-05" "2015-09-06"
[2441] "2015-09-07" "2015-09-08" "2015-09-09" "2015-09-10" "2015-09-11"
[2446] "2015-09-12" "2015-09-13" "2015-09-14" "2015-09-15" "2015-09-16"
[2451] "2015-09-17" "2015-09-18" "2015-09-19" "2015-09-20" "2015-09-21"
[2456] "2015-09-22" "2015-09-23" "2015-09-24" "2015-09-25" "2015-09-26"
[2461] "2015-09-27" "2015-09-28" "2015-09-29" "2015-09-30" "2015-10-01"
[2466] "2015-10-02" "2015-10-03" "2015-10-04" "2015-10-05" "2015-10-06"
[2471] "2015-10-07" "2015-10-08" "2015-10-09" "2015-10-10" "2015-10-11"
[2476] "2015-10-12" "2015-10-13" "2015-10-14" "2015-10-15" "2015-10-16"
[2481] "2015-10-17" "2015-10-18" "2015-10-19" "2015-10-20" "2015-10-21"
[2486] "2015-10-22" "2015-10-23" "2015-10-24" "2015-10-25" "2015-10-26"
[2491] "2015-10-27" "2015-10-28" "2015-10-29" "2015-10-30" "2015-10-31"
[2496] "2015-11-01" "2015-11-02" "2015-11-03" "2015-11-04" "2015-11-05"
[2501] "2015-11-06" "2015-11-07" "2015-11-08" "2015-11-09" "2015-11-10"
[2506] "2015-11-11" "2015-11-12" "2015-11-13" "2015-11-14" "2015-11-15"
[2511] "2015-11-16" "2015-11-17" "2015-11-18" "2015-11-19" "2015-11-20"
[2516] "2015-11-21" "2015-11-22" "2015-11-23" "2015-11-24" "2015-11-25"
[2521] "2015-11-26" "2015-11-27" "2015-11-28" "2015-11-29" "2015-11-30"
[2526] "2015-12-01" "2015-12-02" "2015-12-03" "2015-12-04" "2015-12-05"
[2531] "2015-12-06" "2015-12-07" "2015-12-08" "2015-12-09" "2015-12-10"
[2536] "2015-12-11" "2015-12-12" "2015-12-13" "2015-12-14" "2015-12-15"
[2541] "2015-12-16" "2015-12-17" "2015-12-18" "2015-12-19" "2015-12-20"
[2546] "2015-12-21" "2015-12-22" "2015-12-23" "2015-12-24" "2015-12-25"
[2551] "2015-12-26" "2015-12-27" "2015-12-28" "2015-12-29" "2015-12-30"
[2556] "2015-12-31" "2016-01-01" "2016-01-02" "2016-01-03" "2016-01-04"
[2561] "2016-01-05" "2016-01-06" "2016-01-07" "2016-01-08" "2016-01-09"
[2566] "2016-01-10" "2016-01-11" "2016-01-12" "2016-01-13" "2016-01-14"
[2571] "2016-01-15" "2016-01-16" "2016-01-17" "2016-01-18" "2016-01-19"
[2576] "2016-01-20" "2016-01-21" "2016-01-22" "2016-01-23" "2016-01-24"
[2581] "2016-01-25" "2016-01-26" "2016-01-27" "2016-01-28" "2016-01-29"
[2586] "2016-01-30" "2016-01-31" "2016-02-01" "2016-02-02" "2016-02-03"
[2591] "2016-02-04" "2016-02-05" "2016-02-06" "2016-02-07" "2016-02-08"
[2596] "2016-02-09" "2016-02-10" "2016-02-11" "2016-02-12" "2016-02-13"
[2601] "2016-02-14" "2016-02-15" "2016-02-16" "2016-02-17" "2016-02-18"
[2606] "2016-02-19" "2016-02-20" "2016-02-21" "2016-02-22" "2016-02-23"
[2611] "2016-02-24" "2016-02-25" "2016-02-26" "2016-02-27" "2016-02-28"
[2616] "2016-02-29" "2016-03-01" "2016-03-02" "2016-03-03" "2016-03-04"
[2621] "2016-03-05" "2016-03-06" "2016-03-07" "2016-03-08" "2016-03-09"
[2626] "2016-03-10" "2016-03-11" "2016-03-12" "2016-03-13" "2016-03-14"
[2631] "2016-03-15" "2016-03-16" "2016-03-17" "2016-03-18" "2016-03-19"
[2636] "2016-03-20" "2016-03-21" "2016-03-22" "2016-03-23" "2016-03-24"
[2641] "2016-03-25" "2016-03-26" "2016-03-27" "2016-03-28" "2016-03-29"
[2646] "2016-03-30" "2016-03-31" "2016-04-01" "2016-04-02" "2016-04-03"
[2651] "2016-04-04" "2016-04-05" "2016-04-06" "2016-04-07" "2016-04-08"
[2656] "2016-04-09" "2016-04-10" "2016-04-11" "2016-04-12" "2016-04-13"
[2661] "2016-04-14" "2016-04-15" "2016-04-16" "2016-04-17" "2016-04-18"
[2666] "2016-04-19" "2016-04-20" "2016-04-21" "2016-04-22" "2016-04-23"
[2671] "2016-04-24" "2016-04-25" "2016-04-26" "2016-04-27" "2016-04-28"
[2676] "2016-04-29" "2016-04-30" "2016-05-01" "2016-05-02" "2016-05-03"
[2681] "2016-05-04" "2016-05-05" "2016-05-06" "2016-05-07" "2016-05-08"
[2686] "2016-05-09" "2016-05-10" "2016-05-11" "2016-05-12" "2016-05-13"
[2691] "2016-05-14" "2016-05-15" "2016-05-16" "2016-05-17" "2016-05-18"
[2696] "2016-05-19" "2016-05-20" "2016-05-21" "2016-05-22" "2016-05-23"
[2701] "2016-05-24" "2016-05-25" "2016-05-26" "2016-05-27" "2016-05-28"
[2706] "2016-05-29" "2016-05-30" "2016-05-31" "2016-06-01" "2016-06-02"
[2711] "2016-06-03" "2016-06-04" "2016-06-05" "2016-06-06" "2016-06-07"
[2716] "2016-06-08" "2016-06-09" "2016-06-10" "2016-06-11" "2016-06-12"
[2721] "2016-06-13" "2016-06-14" "2016-06-15" "2016-06-16" "2016-06-17"
[2726] "2016-06-18" "2016-06-19" "2016-06-20" "2016-06-21" "2016-06-22"
[2731] "2016-06-23" "2016-06-24" "2016-06-25" "2016-06-26" "2016-06-27"
[2736] "2016-06-28" "2016-06-29" "2016-06-30" "2016-07-01" "2016-07-02"
[2741] "2016-07-03" "2016-07-04" "2016-07-05" "2016-07-06" "2016-07-07"
[2746] "2016-07-08" "2016-07-09" "2016-07-10" "2016-07-11" "2016-07-12"
[2751] "2016-07-13" "2016-07-14" "2016-07-15" "2016-07-16" "2016-07-17"
[2756] "2016-07-18" "2016-07-19" "2016-07-20" "2016-07-21" "2016-07-22"
[2761] "2016-07-23" "2016-07-24" "2016-07-25" "2016-07-26" "2016-07-27"
[2766] "2016-07-28" "2016-07-29" "2016-07-30" "2016-07-31" "2016-08-01"
[2771] "2016-08-02" "2016-08-03" "2016-08-04" "2016-08-05" "2016-08-06"
[2776] "2016-08-07" "2016-08-08" "2016-08-09" "2016-08-10" "2016-08-11"
[2781] "2016-08-12" "2016-08-13" "2016-08-14" "2016-08-15" "2016-08-16"
[2786] "2016-08-17" "2016-08-18" "2016-08-19" "2016-08-20" "2016-08-21"
[2791] "2016-08-22" "2016-08-23" "2016-08-24" "2016-08-25" "2016-08-26"
[2796] "2016-08-27" "2016-08-28" "2016-08-29" "2016-08-30" "2016-08-31"
[2801] "2016-09-01" "2016-09-02" "2016-09-03" "2016-09-04" "2016-09-05"
[2806] "2016-09-06" "2016-09-07" "2016-09-08" "2016-09-09" "2016-09-10"
[2811] "2016-09-11" "2016-09-12" "2016-09-13" "2016-09-14" "2016-09-15"
[2816] "2016-09-16" "2016-09-17" "2016-09-18" "2016-09-19" "2016-09-20"
[2821] "2016-09-21" "2016-09-22" "2016-09-23" "2016-09-24" "2016-09-25"
[2826] "2016-09-26" "2016-09-27" "2016-09-28" "2016-09-29" "2016-09-30"
[2831] "2016-10-01" "2016-10-02" "2016-10-03" "2016-10-04" "2016-10-05"
[2836] "2016-10-06" "2016-10-07" "2016-10-08" "2016-10-09" "2016-10-10"
[2841] "2016-10-11" "2016-10-12" "2016-10-13" "2016-10-14" "2016-10-15"
[2846] "2016-10-16" "2016-10-17" "2016-10-18" "2016-10-19" "2016-10-20"
[2851] "2016-10-21" "2016-10-22" "2016-10-23" "2016-10-24" "2016-10-25"
[2856] "2016-10-26" "2016-10-27" "2016-10-28" "2016-10-29" "2016-10-30"
[2861] "2016-10-31" "2016-11-01" "2016-11-02" "2016-11-03" "2016-11-04"
[2866] "2016-11-05" "2016-11-06" "2016-11-07" "2016-11-08" "2016-11-09"
[2871] "2016-11-10" "2016-11-11" "2016-11-12" "2016-11-13" "2016-11-14"
[2876] "2016-11-15" "2016-11-16" "2016-11-17" "2016-11-18" "2016-11-19"
[2881] "2016-11-20" "2016-11-21" "2016-11-22" "2016-11-23" "2016-11-24"
[2886] "2016-11-25" "2016-11-26" "2016-11-27" "2016-11-28" "2016-11-29"
[2891] "2016-11-30" "2016-12-01" "2016-12-02" "2016-12-03" "2016-12-04"
[2896] "2016-12-05" "2016-12-06" "2016-12-07" "2016-12-08" "2016-12-09"
[2901] "2016-12-10" "2016-12-11" "2016-12-12" "2016-12-13" "2016-12-14"
[2906] "2016-12-15" "2016-12-16" "2016-12-17" "2016-12-18" "2016-12-19"
[2911] "2016-12-20" "2016-12-21" "2016-12-22" "2016-12-23" "2016-12-24"
[2916] "2016-12-25" "2016-12-26" "2016-12-27" "2016-12-28" "2016-12-29"
[2921] "2016-12-30" "2016-12-31" "2017-01-01" "2017-01-02" "2017-01-03"
[2926] "2017-01-04" "2017-01-05" "2017-01-06" "2017-01-07" "2017-01-08"
[2931] "2017-01-09" "2017-01-10" "2017-01-11" "2017-01-12" "2017-01-13"
[2936] "2017-01-14" "2017-01-15" "2017-01-16" "2017-01-17" "2017-01-18"
[2941] "2017-01-19" "2017-01-20" "2017-01-21" "2017-01-22" "2017-01-23"
[2946] "2017-01-24" "2017-01-25" "2017-01-26" "2017-01-27" "2017-01-28"
[2951] "2017-01-29" "2017-01-30" "2017-01-31" "2017-02-01" "2017-02-02"
[2956] "2017-02-03" "2017-02-04" "2017-02-05" "2017-02-06" "2017-02-07"
[2961] "2017-02-08" "2017-02-09" "2017-02-10" "2017-02-11" "2017-02-12"
[2966] "2017-02-13" "2017-02-14" "2017-02-15" "2017-02-16" "2017-02-17"
[2971] "2017-02-18" "2017-02-19" "2017-02-20" "2017-02-21" "2017-02-22"
[2976] "2017-02-23" "2017-02-24" "2017-02-25" "2017-02-26" "2017-02-27"
[2981] "2017-02-28" "2017-03-01" "2017-03-02" "2017-03-03" "2017-03-04"
[2986] "2017-03-05" "2017-03-06" "2017-03-07" "2017-03-08" "2017-03-09"
[2991] "2017-03-10" "2017-03-11" "2017-03-12" "2017-03-13" "2017-03-14"
[2996] "2017-03-15" "2017-03-16" "2017-03-17" "2017-03-18" "2017-03-19"
[3001] "2017-03-20" "2017-03-21" "2017-03-22" "2017-03-23" "2017-03-24"
[3006] "2017-03-25" "2017-03-26" "2017-03-27" "2017-03-28" "2017-03-29"
[3011] "2017-03-30" "2017-03-31" "2017-04-01" "2017-04-02" "2017-04-03"
[3016] "2017-04-04" "2017-04-05" "2017-04-06" "2017-04-07" "2017-04-08"
[3021] "2017-04-09" "2017-04-10" "2017-04-11" "2017-04-12" "2017-04-13"
[3026] "2017-04-14" "2017-04-15" "2017-04-16" "2017-04-17" "2017-04-18"
[3031] "2017-04-19" "2017-04-20" "2017-04-21" "2017-04-22" "2017-04-23"
[3036] "2017-04-24" "2017-04-25" "2017-04-26" "2017-04-27" "2017-04-28"
[3041] "2017-04-29" "2017-04-30" "2017-05-01" "2017-05-02" "2017-05-03"
[3046] "2017-05-04" "2017-05-05" "2017-05-06" "2017-05-07" "2017-05-08"
[3051] "2017-05-09" "2017-05-10" "2017-05-11" "2017-05-12" "2017-05-13"
[3056] "2017-05-14" "2017-05-15" "2017-05-16" "2017-05-17" "2017-05-18"
[3061] "2017-05-19" "2017-05-20" "2017-05-21" "2017-05-22" "2017-05-23"
[3066] "2017-05-24" "2017-05-25" "2017-05-26" "2017-05-27" "2017-05-28"
[3071] "2017-05-29" "2017-05-30" "2017-05-31" "2017-06-01" "2017-06-02"
[3076] "2017-06-03" "2017-06-04" "2017-06-05" "2017-06-06" "2017-06-07"
[3081] "2017-06-08" "2017-06-09" "2017-06-10" "2017-06-11" "2017-06-12"
[3086] "2017-06-13" "2017-06-14" "2017-06-15" "2017-06-16" "2017-06-17"
[3091] "2017-06-18" "2017-06-19" "2017-06-20" "2017-06-21" "2017-06-22"
[3096] "2017-06-23" "2017-06-24" "2017-06-25" "2017-06-26" "2017-06-27"
[3101] "2017-06-28" "2017-06-29" "2017-06-30" "2017-07-01" "2017-07-02"
[3106] "2017-07-03" "2017-07-04" "2017-07-05" "2017-07-06" "2017-07-07"
[3111] "2017-07-08" "2017-07-09" "2017-07-10" "2017-07-11" "2017-07-12"
[3116] "2017-07-13" "2017-07-14" "2017-07-15" "2017-07-16" "2017-07-17"
[3121] "2017-07-18" "2017-07-19" "2017-07-20" "2017-07-21" "2017-07-22"
[3126] "2017-07-23" "2017-07-24" "2017-07-25" "2017-07-26" "2017-07-27"
[3131] "2017-07-28" "2017-07-29" "2017-07-30" "2017-07-31" "2017-08-01"
[3136] "2017-08-02" "2017-08-03" "2017-08-04" "2017-08-05" "2017-08-06"
[3141] "2017-08-07" "2017-08-08" "2017-08-09" "2017-08-10" "2017-08-11"
[3146] "2017-08-12" "2017-08-13" "2017-08-14" "2017-08-15" "2017-08-16"
[3151] "2017-08-17" "2017-08-18" "2017-08-19" "2017-08-20" "2017-08-21"
[3156] "2017-08-22" "2017-08-23" "2017-08-24" "2017-08-25" "2017-08-26"
[3161] "2017-08-27" "2017-08-28" "2017-08-29" "2017-08-30" "2017-08-31"
[3166] "2017-09-01" "2017-09-02" "2017-09-03" "2017-09-04" "2017-09-05"
[3171] "2017-09-06" "2017-09-07" "2017-09-08" "2017-09-09" "2017-09-10"
[3176] "2017-09-11" "2017-09-12" "2017-09-13" "2017-09-14" "2017-09-15"
[3181] "2017-09-16" "2017-09-17" "2017-09-18" "2017-09-19" "2017-09-20"
[3186] "2017-09-21" "2017-09-22" "2017-09-23" "2017-09-24" "2017-09-25"
[3191] "2017-09-26" "2017-09-27" "2017-09-28" "2017-09-29" "2017-09-30"
[3196] "2017-10-01" "2017-10-02" "2017-10-03" "2017-10-04" "2017-10-05"
[3201] "2017-10-06" "2017-10-07" "2017-10-08" "2017-10-09" "2017-10-10"
[3206] "2017-10-11" "2017-10-12" "2017-10-13" "2017-10-14" "2017-10-15"
[3211] "2017-10-16" "2017-10-17" "2017-10-18" "2017-10-19" "2017-10-20"
[3216] "2017-10-21" "2017-10-22" "2017-10-23" "2017-10-24" "2017-10-25"
[3221] "2017-10-26" "2017-10-27" "2017-10-28" "2017-10-29" "2017-10-30"
[3226] "2017-10-31" "2017-11-01" "2017-11-02" "2017-11-03" "2017-11-04"
[3231] "2017-11-05" "2017-11-06" "2017-11-07" "2017-11-08" "2017-11-09"
[3236] "2017-11-10" "2017-11-11" "2017-11-12" "2017-11-13" "2017-11-14"
[3241] "2017-11-15" "2017-11-16" "2017-11-17" "2017-11-18" "2017-11-19"
[3246] "2017-11-20" "2017-11-21" "2017-11-22" "2017-11-23" "2017-11-24"
[3251] "2017-11-25" "2017-11-26" "2017-11-27" "2017-11-28" "2017-11-29"
[3256] "2017-11-30" "2017-12-01" "2017-12-02" "2017-12-03" "2017-12-04"
[3261] "2017-12-05" "2017-12-06" "2017-12-07" "2017-12-08" "2017-12-09"
[3266] "2017-12-10" "2017-12-11" "2017-12-12" "2017-12-13" "2017-12-14"
[3271] "2017-12-15" "2017-12-16" "2017-12-17" "2017-12-18" "2017-12-19"
[3276] "2017-12-20" "2017-12-21" "2017-12-22" "2017-12-23" "2017-12-24"
[3281] "2017-12-25" "2017-12-26" "2017-12-27" "2017-12-28" "2017-12-29"
[3286] "2017-12-30" "2017-12-31" "2018-01-01" "2018-01-02" "2018-01-03"
[3291] "2018-01-04" "2018-01-05" "2018-01-06" "2018-01-07" "2018-01-08"
[3296] "2018-01-09" "2018-01-10" "2018-01-11" "2018-01-12" "2018-01-13"
[3301] "2018-01-14" "2018-01-15" "2018-01-16" "2018-01-17" "2018-01-18"
[3306] "2018-01-19" "2018-01-20" "2018-01-21" "2018-01-22" "2018-01-23"
[3311] "2018-01-24" "2018-01-25" "2018-01-26" "2018-01-27" "2018-01-28"
[3316] "2018-01-29" "2018-01-30" "2018-01-31" "2018-02-01" "2018-02-02"
[3321] "2018-02-03" "2018-02-04" "2018-02-05" "2018-02-06" "2018-02-07"
[3326] "2018-02-08" "2018-02-09" "2018-02-10" "2018-02-11" "2018-02-12"
[3331] "2018-02-13" "2018-02-14" "2018-02-15" "2018-02-16" "2018-02-17"
[3336] "2018-02-18" "2018-02-19" "2018-02-20" "2018-02-21" "2018-02-22"
[3341] "2018-02-23" "2018-02-24" "2018-02-25" "2018-02-26" "2018-02-27"
[3346] "2018-02-28" "2018-03-01" "2018-03-02" "2018-03-03" "2018-03-04"
[3351] "2018-03-05" "2018-03-06" "2018-03-07" "2018-03-08" "2018-03-09"
[3356] "2018-03-10" "2018-03-11" "2018-03-12" "2018-03-13" "2018-03-14"
[3361] "2018-03-15" "2018-03-16" "2018-03-17" "2018-03-18" "2018-03-19"
[3366] "2018-03-20" "2018-03-21" "2018-03-22" "2018-03-23" "2018-03-24"
[3371] "2018-03-25" "2018-03-26" "2018-03-27" "2018-03-28" "2018-03-29"
[3376] "2018-03-30" "2018-03-31" "2018-04-01" "2018-04-02" "2018-04-03"
[3381] "2018-04-04" "2018-04-05" "2018-04-06" "2018-04-07" "2018-04-08"
[3386] "2018-04-09" "2018-04-10" "2018-04-11" "2018-04-12" "2018-04-13"
[3391] "2018-04-14" "2018-04-15" "2018-04-16" "2018-04-17" "2018-04-18"
[3396] "2018-04-19" "2018-04-20" "2018-04-21" "2018-04-22" "2018-04-23"
[3401] "2018-04-24" "2018-04-25" "2018-04-26" "2018-04-27" "2018-04-28"
[3406] "2018-04-29" "2018-04-30" "2018-05-01" "2018-05-02" "2018-05-03"
[3411] "2018-05-04" "2018-05-05" "2018-05-06" "2018-05-07" "2018-05-08"
[3416] "2018-05-09" "2018-05-10" "2018-05-11" "2018-05-12" "2018-05-13"
[3421] "2018-05-14" "2018-05-15" "2018-05-16" "2018-05-17" "2018-05-18"
[3426] "2018-05-19" "2018-05-20" "2018-05-21" "2018-05-22" "2018-05-23"
[3431] "2018-05-24" "2018-05-25" "2018-05-26" "2018-05-27" "2018-05-28"
[3436] "2018-05-29" "2018-05-30" "2018-05-31" "2018-06-01" "2018-06-02"
[3441] "2018-06-03" "2018-06-04" "2018-06-05" "2018-06-06" "2018-06-07"
[3446] "2018-06-08" "2018-06-09" "2018-06-10" "2018-06-11" "2018-06-12"
[3451] "2018-06-13" "2018-06-14" "2018-06-15" "2018-06-16" "2018-06-17"
[3456] "2018-06-18" "2018-06-19" "2018-06-20" "2018-06-21" "2018-06-22"
[3461] "2018-06-23" "2018-06-24" "2018-06-25" "2018-06-26" "2018-06-27"
[3466] "2018-06-28" "2018-06-29" "2018-06-30" "2018-07-01" "2018-07-02"
[3471] "2018-07-03" "2018-07-04" "2018-07-05" "2018-07-06" "2018-07-07"
[3476] "2018-07-08" "2018-07-09" "2018-07-10" "2018-07-11" "2018-07-12"
[3481] "2018-07-13" "2018-07-14" "2018-07-15" "2018-07-16" "2018-07-17"
[3486] "2018-07-18" "2018-07-19" "2018-07-20" "2018-07-21" "2018-07-22"
[3491] "2018-07-23" "2018-07-24" "2018-07-25" "2018-07-26" "2018-07-27"
[3496] "2018-07-28" "2018-07-29" "2018-07-30" "2018-07-31" "2018-08-01"
[3501] "2018-08-02" "2018-08-03" "2018-08-04" "2018-08-05" "2018-08-06"
[3506] "2018-08-07" "2018-08-08" "2018-08-09" "2018-08-10" "2018-08-11"
[3511] "2018-08-12" "2018-08-13" "2018-08-14" "2018-08-15" "2018-08-16"
[3516] "2018-08-17" "2018-08-18" "2018-08-19" "2018-08-20" "2018-08-21"
[3521] "2018-08-22" "2018-08-23" "2018-08-24" "2018-08-25" "2018-08-26"
[3526] "2018-08-27" "2018-08-28" "2018-08-29" "2018-08-30" "2018-08-31"
[3531] "2018-09-01" "2018-09-02" "2018-09-03" "2018-09-04" "2018-09-05"
[3536] "2018-09-06" "2018-09-07" "2018-09-08" "2018-09-09" "2018-09-10"
[3541] "2018-09-11" "2018-09-12" "2018-09-13" "2018-09-14" "2018-09-15"
[3546] "2018-09-16" "2018-09-17" "2018-09-18" "2018-09-19" "2018-09-20"
[3551] "2018-09-21" "2018-09-22" "2018-09-23" "2018-09-24" "2018-09-25"
[3556] "2018-09-26" "2018-09-27" "2018-09-28" "2018-09-29" "2018-09-30"
[3561] "2018-10-01" "2018-10-02" "2018-10-03" "2018-10-04" "2018-10-05"
[3566] "2018-10-06" "2018-10-07" "2018-10-08" "2018-10-09" "2018-10-10"
[3571] "2018-10-11" "2018-10-12" "2018-10-13" "2018-10-14" "2018-10-15"
[3576] "2018-10-16" "2018-10-17" "2018-10-18" "2018-10-19" "2018-10-20"
[3581] "2018-10-21" "2018-10-22" "2018-10-23" "2018-10-24" "2018-10-25"
[3586] "2018-10-26" "2018-10-27" "2018-10-28" "2018-10-29" "2018-10-30"
[3591] "2018-10-31" "2018-11-01" "2018-11-02" "2018-11-03" "2018-11-04"
[3596] "2018-11-05" "2018-11-06" "2018-11-07" "2018-11-08" "2018-11-09"
[3601] "2018-11-10" "2018-11-11" "2018-11-12" "2018-11-13" "2018-11-14"
[3606] "2018-11-15" "2018-11-16" "2018-11-17" "2018-11-18" "2018-11-19"
[3611] "2018-11-20" "2018-11-21" "2018-11-22" "2018-11-23" "2018-11-24"
[3616] "2018-11-25" "2018-11-26" "2018-11-27" "2018-11-28" "2018-11-29"
[3621] "2018-11-30" "2018-12-01" "2018-12-02" "2018-12-03" "2018-12-04"
[3626] "2018-12-05" "2018-12-06" "2018-12-07" "2018-12-08" "2018-12-09"
[3631] "2018-12-10" "2018-12-11" "2018-12-12" "2018-12-13" "2018-12-14"
[3636] "2018-12-15" "2018-12-16" "2018-12-17" "2018-12-18" "2018-12-19"
[3641] "2018-12-20" "2018-12-21" "2018-12-22" "2018-12-23" "2018-12-24"
[3646] "2018-12-25" "2018-12-26" "2018-12-27" "2018-12-28" "2018-12-29"
[3651] "2018-12-30" "2018-12-31" "2019-01-01" "2019-01-02" "2019-01-03"
[3656] "2019-01-04" "2019-01-05" "2019-01-06" "2019-01-07" "2019-01-08"
[3661] "2019-01-09" "2019-01-10" "2019-01-11" "2019-01-12" "2019-01-13"
[3666] "2019-01-14" "2019-01-15" "2019-01-16" "2019-01-17" "2019-01-18"
[3671] "2019-01-19" "2019-01-20" "2019-01-21" "2019-01-22" "2019-01-23"
[3676] "2019-01-24" "2019-01-25" "2019-01-26" "2019-01-27" "2019-01-28"
[3681] "2019-01-29" "2019-01-30" "2019-01-31" "2019-02-01" "2019-02-02"
[3686] "2019-02-03" "2019-02-04" "2019-02-05" "2019-02-06" "2019-02-07"
[3691] "2019-02-08" "2019-02-09" "2019-02-10" "2019-02-11" "2019-02-12"
[3696] "2019-02-13" "2019-02-14" "2019-02-15" "2019-02-16" "2019-02-17"
[3701] "2019-02-18" "2019-02-19" "2019-02-20" "2019-02-21" "2019-02-22"
[3706] "2019-02-23" "2019-02-24" "2019-02-25" "2019-02-26" "2019-02-27"
[3711] "2019-02-28" "2019-03-01" "2019-03-02" "2019-03-03" "2019-03-04"
[3716] "2019-03-05" "2019-03-06" "2019-03-07" "2019-03-08" "2019-03-09"
[3721] "2019-03-10" "2019-03-11" "2019-03-12" "2019-03-13" "2019-03-14"
[3726] "2019-03-15" "2019-03-16" "2019-03-17" "2019-03-18" "2019-03-19"
[3731] "2019-03-20" "2019-03-21" "2019-03-22" "2019-03-23" "2019-03-24"
[3736] "2019-03-25" "2019-03-26" "2019-03-27" "2019-03-28" "2019-03-29"
[3741] "2019-03-30" "2019-03-31" "2019-04-01" "2019-04-02" "2019-04-03"
[3746] "2019-04-04" "2019-04-05" "2019-04-06" "2019-04-07" "2019-04-08"
[3751] "2019-04-09" "2019-04-10" "2019-04-11" "2019-04-12" "2019-04-13"
[3756] "2019-04-14" "2019-04-15" "2019-04-16" "2019-04-17" "2019-04-18"
[3761] "2019-04-19" "2019-04-20" "2019-04-21" "2019-04-22" "2019-04-23"
[3766] "2019-04-24" "2019-04-25" "2019-04-26" "2019-04-27" "2019-04-28"
[3771] "2019-04-29" "2019-04-30" "2019-05-01" "2019-05-02" "2019-05-03"
[3776] "2019-05-04" "2019-05-05" "2019-05-06" "2019-05-07" "2019-05-08"
[3781] "2019-05-09" "2019-05-10" "2019-05-11" "2019-05-12" "2019-05-13"
[3786] "2019-05-14" "2019-05-15" "2019-05-16" "2019-05-17" "2019-05-18"
[3791] "2019-05-19" "2019-05-20" "2019-05-21" "2019-05-22" "2019-05-23"
[3796] "2019-05-24" "2019-05-25" "2019-05-26" "2019-05-27" "2019-05-28"
[3801] "2019-05-29" "2019-05-30" "2019-05-31" "2019-06-01" "2019-06-02"
[3806] "2019-06-03" "2019-06-04" "2019-06-05" "2019-06-06" "2019-06-07"
[3811] "2019-06-08" "2019-06-09" "2019-06-10" "2019-06-11" "2019-06-12"
[3816] "2019-06-13" "2019-06-14" "2019-06-15" "2019-06-16" "2019-06-17"
[3821] "2019-06-18" "2019-06-19" "2019-06-20" "2019-06-21" "2019-06-22"
[3826] "2019-06-23" "2019-06-24" "2019-06-25" "2019-06-26" "2019-06-27"
[3831] "2019-06-28" "2019-06-29" "2019-06-30" "2019-07-01" "2019-07-02"
[3836] "2019-07-03" "2019-07-04" "2019-07-05" "2019-07-06" "2019-07-07"
[3841] "2019-07-08" "2019-07-09" "2019-07-10" "2019-07-11" "2019-07-12"
[3846] "2019-07-13" "2019-07-14" "2019-07-15" "2019-07-16" "2019-07-17"
[3851] "2019-07-18" "2019-07-19" "2019-07-20" "2019-07-21" "2019-07-22"
[3856] "2019-07-23" "2019-07-24" "2019-07-25" "2019-07-26" "2019-07-27"
[3861] "2019-07-28" "2019-07-29" "2019-07-30" "2019-07-31" "2019-08-01"
[3866] "2019-08-02" "2019-08-03" "2019-08-04" "2019-08-05" "2019-08-06"
[3871] "2019-08-07" "2019-08-08" "2019-08-09" "2019-08-10" "2019-08-11"
[3876] "2019-08-12" "2019-08-13" "2019-08-14" "2019-08-15" "2019-08-16"
[3881] "2019-08-17" "2019-08-18" "2019-08-19" "2019-08-20" "2019-08-21"
[3886] "2019-08-22" "2019-08-23" "2019-08-24" "2019-08-25" "2019-08-26"
[3891] "2019-08-27" "2019-08-28" "2019-08-29" "2019-08-30" "2019-08-31"
[3896] "2019-09-01" "2019-09-02" "2019-09-03" "2019-09-04" "2019-09-05"
[3901] "2019-09-06" "2019-09-07" "2019-09-08" "2019-09-09" "2019-09-10"
[3906] "2019-09-11" "2019-09-12" "2019-09-13" "2019-09-14" "2019-09-15"
[3911] "2019-09-16" "2019-09-17" "2019-09-18" "2019-09-19" "2019-09-20"
[3916] "2019-09-21" "2019-09-22" "2019-09-23" "2019-09-24" "2019-09-25"
[3921] "2019-09-26" "2019-09-27" "2019-09-28" "2019-09-29" "2019-09-30"
[3926] "2019-10-01" "2019-10-02" "2019-10-03" "2019-10-04" "2019-10-05"
[3931] "2019-10-06" "2019-10-07" "2019-10-08" "2019-10-09" "2019-10-10"
[3936] "2019-10-11" "2019-10-12" "2019-10-13" "2019-10-14" "2019-10-15"
[3941] "2019-10-16" "2019-10-17" "2019-10-18" "2019-10-19" "2019-10-20"
[3946] "2019-10-21" "2019-10-22" "2019-10-23" "2019-10-24" "2019-10-25"
[3951] "2019-10-26" "2019-10-27" "2019-10-28" "2019-10-29" "2019-10-30"
[3956] "2019-10-31" "2019-11-01" "2019-11-02" "2019-11-03" "2019-11-04"
[3961] "2019-11-05" "2019-11-06" "2019-11-07" "2019-11-08" "2019-11-09"
[3966] "2019-11-10" "2019-11-11" "2019-11-12" "2019-11-13" "2019-11-14"
[3971] "2019-11-15" "2019-11-16" "2019-11-17" "2019-11-18" "2019-11-19"
[3976] "2019-11-20" "2019-11-21" "2019-11-22" "2019-11-23" "2019-11-24"
[3981] "2019-11-25" "2019-11-26" "2019-11-27" "2019-11-28" "2019-11-29"
[3986] "2019-11-30" "2019-12-01" "2019-12-02" "2019-12-03" "2019-12-04"
[3991] "2019-12-05" "2019-12-06" "2019-12-07" "2019-12-08" "2019-12-09"
[3996] "2019-12-10" "2019-12-11" "2019-12-12" "2019-12-13" "2019-12-14"
[4001] "2019-12-15" "2019-12-16" "2019-12-17" "2019-12-18" "2019-12-19"
[4006] "2019-12-20" "2019-12-21" "2019-12-22" "2019-12-23" "2019-12-24"
[4011] "2019-12-25" "2019-12-26" "2019-12-27" "2019-12-28" "2019-12-29"
[4016] "2019-12-30" "2019-12-31" "2020-01-01" "2020-01-02" "2020-01-03"
[4021] "2020-01-04" "2020-01-05" "2020-01-06" "2020-01-07" "2020-01-08"
[4026] "2020-01-09" "2020-01-10" "2020-01-11" "2020-01-12" "2020-01-13"
[4031] "2020-01-14" "2020-01-15" "2020-01-16" "2020-01-17" "2020-01-18"
[4036] "2020-01-19" "2020-01-20" "2020-01-21" "2020-01-22" "2020-01-23"
[4041] "2020-01-24" "2020-01-25" "2020-01-26" "2020-01-27" "2020-01-28"
[4046] "2020-01-29" "2020-01-30" "2020-01-31" "2020-02-01" "2020-02-02"
[4051] "2020-02-03" "2020-02-04" "2020-02-05" "2020-02-06" "2020-02-07"
[4056] "2020-02-08" "2020-02-09" "2020-02-10" "2020-02-11" "2020-02-12"
[4061] "2020-02-13" "2020-02-14" "2020-02-15" "2020-02-16" "2020-02-17"
[4066] "2020-02-18" "2020-02-19" "2020-02-20" "2020-02-21" "2020-02-22"
[4071] "2020-02-23" "2020-02-24" "2020-02-25" "2020-02-26" "2020-02-27"
[4076] "2020-02-28" "2020-02-29" "2020-03-01" "2020-03-02" "2020-03-03"
[4081] "2020-03-04" "2020-03-05" "2020-03-06" "2020-03-07" "2020-03-08"
[4086] "2020-03-09" "2020-03-10" "2020-03-11" "2020-03-12" "2020-03-13"
[4091] "2020-03-14" "2020-03-15" "2020-03-16" "2020-03-17" "2020-03-18"
[4096] "2020-03-19" "2020-03-20" "2020-03-21" "2020-03-22" "2020-03-23"
[4101] "2020-03-24" "2020-03-25" "2020-03-26" "2020-03-27" "2020-03-28"
[4106] "2020-03-29" "2020-03-30" "2020-03-31" "2020-04-01" "2020-04-02"
[4111] "2020-04-03" "2020-04-04" "2020-04-05" "2020-04-06" "2020-04-07"
[4116] "2020-04-08" "2020-04-09" "2020-04-10" "2020-04-11" "2020-04-12"
[4121] "2020-04-13" "2020-04-14" "2020-04-15" "2020-04-16" "2020-04-17"
[4126] "2020-04-18" "2020-04-19" "2020-04-20" "2020-04-21" "2020-04-22"
[4131] "2020-04-23" "2020-04-24" "2020-04-25" "2020-04-26" "2020-04-27"
[4136] "2020-04-28" "2020-04-29" "2020-04-30" "2020-05-01" "2020-05-02"
[4141] "2020-05-03" "2020-05-04" "2020-05-05" "2020-05-06" "2020-05-07"
[4146] "2020-05-08" "2020-05-09" "2020-05-10" "2020-05-11" "2020-05-12"
[4151] "2020-05-13" "2020-05-14" "2020-05-15" "2020-05-16" "2020-05-17"
[4156] "2020-05-18" "2020-05-19" "2020-05-20" "2020-05-21" "2020-05-22"
[4161] "2020-05-23" "2020-05-24" "2020-05-25" "2020-05-26" "2020-05-27"
[4166] "2020-05-28" "2020-05-29" "2020-05-30" "2020-05-31" "2020-06-01"
[4171] "2020-06-02" "2020-06-03" "2020-06-04" "2020-06-05" "2020-06-06"
[4176] "2020-06-07" "2020-06-08" "2020-06-09" "2020-06-10" "2020-06-11"
[4181] "2020-06-12" "2020-06-13" "2020-06-14" "2020-06-15" "2020-06-16"
[4186] "2020-06-17" "2020-06-18" "2020-06-19" "2020-06-20" "2020-06-21"
[4191] "2020-06-22" "2020-06-23" "2020-06-24" "2020-06-25" "2020-06-26"
[4196] "2020-06-27" "2020-06-28" "2020-06-29" "2020-06-30" "2020-07-01"
[4201] "2020-07-02" "2020-07-03" "2020-07-04" "2020-07-05" "2020-07-06"
[4206] "2020-07-07" "2020-07-08" "2020-07-09" "2020-07-10" "2020-07-11"
[4211] "2020-07-12" "2020-07-13" "2020-07-14" "2020-07-15" "2020-07-16"
[4216] "2020-07-17" "2020-07-18" "2020-07-19" "2020-07-20" "2020-07-21"
[4221] "2020-07-22" "2020-07-23" "2020-07-24" "2020-07-25" "2020-07-26"
[4226] "2020-07-27" "2020-07-28" "2020-07-29" "2020-07-30" "2020-07-31"
[4231] "2020-08-01" "2020-08-02" "2020-08-03" "2020-08-04" "2020-08-05"
[4236] "2020-08-06" "2020-08-07" "2020-08-08" "2020-08-09" "2020-08-10"
[4241] "2020-08-11" "2020-08-12" "2020-08-13" "2020-08-14" "2020-08-15"
[4246] "2020-08-16" "2020-08-17" "2020-08-18" "2020-08-19" "2020-08-20"
[4251] "2020-08-21" "2020-08-22" "2020-08-23" "2020-08-24" "2020-08-25"
[4256] "2020-08-26" "2020-08-27" "2020-08-28" "2020-08-29" "2020-08-30"
[4261] "2020-08-31" "2020-09-01" "2020-09-02" "2020-09-03" "2020-09-04"
[4266] "2020-09-05" "2020-09-06" "2020-09-07" "2020-09-08" "2020-09-09"
[4271] "2020-09-10" "2020-09-11" "2020-09-12" "2020-09-13" "2020-09-14"
[4276] "2020-09-15" "2020-09-16" "2020-09-17" "2020-09-18" "2020-09-19"
[4281] "2020-09-20" "2020-09-21" "2020-09-22" "2020-09-23" "2020-09-24"
[4286] "2020-09-25" "2020-09-26" "2020-09-27" "2020-09-28" "2020-09-29"
[4291] "2020-09-30" "2020-10-01" "2020-10-02" "2020-10-03" "2020-10-04"
[4296] "2020-10-05" "2020-10-06" "2020-10-07" "2020-10-08" "2020-10-09"
[4301] "2020-10-10" "2020-10-11" "2020-10-12" "2020-10-13" "2020-10-14"
[4306] "2020-10-15" "2020-10-16" "2020-10-17" "2020-10-18" "2020-10-19"
[4311] "2020-10-20" "2020-10-21" "2020-10-22" "2020-10-23" "2020-10-24"
[4316] "2020-10-25" "2020-10-26" "2020-10-27" "2020-10-28" "2020-10-29"
[4321] "2020-10-30" "2020-10-31" "2020-11-01" "2020-11-02" "2020-11-03"
[4326] "2020-11-04" "2020-11-05" "2020-11-06" "2020-11-07" "2020-11-08"
[4331] "2020-11-09" "2020-11-10" "2020-11-11" "2020-11-12" "2020-11-13"
[4336] "2020-11-14" "2020-11-15" "2020-11-16" "2020-11-17" "2020-11-18"
[4341] "2020-11-19" "2020-11-20" "2020-11-21" "2020-11-22" "2020-11-23"
[4346] "2020-11-24" "2020-11-25" "2020-11-26" "2020-11-27" "2020-11-28"
[4351] "2020-11-29" "2020-11-30" "2020-12-01" "2020-12-02" "2020-12-03"
[4356] "2020-12-04" "2020-12-05" "2020-12-06" "2020-12-07" "2020-12-08"
[4361] "2020-12-09" "2020-12-10" "2020-12-11" "2020-12-12" "2020-12-13"
[4366] "2020-12-14" "2020-12-15" "2020-12-16" "2020-12-17" "2020-12-18"
[4371] "2020-12-19" "2020-12-20" "2020-12-21" "2020-12-22" "2020-12-23"
[4376] "2020-12-24" "2020-12-25" "2020-12-26" "2020-12-27" "2020-12-28"
[4381] "2020-12-29" "2020-12-30" "2020-12-31" "2021-01-01" "2021-01-02"
[4386] "2021-01-03" "2021-01-04" "2021-01-05" "2021-01-06" "2021-01-07"
[4391] "2021-01-08" "2021-01-09" "2021-01-10" "2021-01-11" "2021-01-12"
[4396] "2021-01-13" "2021-01-14" "2021-01-15" "2021-01-16" "2021-01-17"
[4401] "2021-01-18" "2021-01-19" "2021-01-20" "2021-01-21" "2021-01-22"
[4406] "2021-01-23" "2021-01-24" "2021-01-25" "2021-01-26" "2021-01-27"
[4411] "2021-01-28" "2021-01-29" "2021-01-30" "2021-01-31" "2021-02-01"
[4416] "2021-02-02" "2021-02-03" "2021-02-04" "2021-02-05" "2021-02-06"
[4421] "2021-02-07" "2021-02-08" "2021-02-09" "2021-02-10" "2021-02-11"
[4426] "2021-02-12" "2021-02-13" "2021-02-14" "2021-02-15" "2021-02-16"
[4431] "2021-02-17" "2021-02-18" "2021-02-19" "2021-02-20" "2021-02-21"
[4436] "2021-02-22" "2021-02-23" "2021-02-24" "2021-02-25" "2021-02-26"
[4441] "2021-02-27" "2021-02-28" "2021-03-01" "2021-03-02" "2021-03-03"
[4446] "2021-03-04" "2021-03-05" "2021-03-06" "2021-03-07" "2021-03-08"
[4451] "2021-03-09" "2021-03-10" "2021-03-11" "2021-03-12" "2021-03-13"
[4456] "2021-03-14" "2021-03-15" "2021-03-16" "2021-03-17" "2021-03-18"
[4461] "2021-03-19" "2021-03-20" "2021-03-21" "2021-03-22" "2021-03-23"
[4466] "2021-03-24" "2021-03-25" "2021-03-26" "2021-03-27" "2021-03-28"
[4471] "2021-03-29" "2021-03-30" "2021-03-31" "2021-04-01" "2021-04-02"
[4476] "2021-04-03" "2021-04-04" "2021-04-05" "2021-04-06" "2021-04-07"
[4481] "2021-04-08" "2021-04-09" "2021-04-10" "2021-04-11" "2021-04-12"
[4486] "2021-04-13" "2021-04-14" "2021-04-15" "2021-04-16" "2021-04-17"
[4491] "2021-04-18" "2021-04-19" "2021-04-20" "2021-04-21" "2021-04-22"
[4496] "2021-04-23" "2021-04-24" "2021-04-25" "2021-04-26" "2021-04-27"
[4501] "2021-04-28" "2021-04-29" "2021-04-30" "2021-05-01" "2021-05-02"
[4506] "2021-05-03" "2021-05-04" "2021-05-05" "2021-05-06" "2021-05-07"
[4511] "2021-05-08" "2021-05-09" "2021-05-10" "2021-05-11" "2021-05-12"
[4516] "2021-05-13" "2021-05-14" "2021-05-15" "2021-05-16" "2021-05-17"
[4521] "2021-05-18" "2021-05-19" "2021-05-20" "2021-05-21" "2021-05-22"
[4526] "2021-05-23" "2021-05-24" "2021-05-25" "2021-05-26" "2021-05-27"
[4531] "2021-05-28" "2021-05-29" "2021-05-30" "2021-05-31" "2021-06-01"
[4536] "2021-06-02" "2021-06-03" "2021-06-04" "2021-06-05" "2021-06-06"
[4541] "2021-06-07" "2021-06-08" "2021-06-09" "2021-06-10" "2021-06-11"
[4546] "2021-06-12" "2021-06-13" "2021-06-14" "2021-06-15" "2021-06-16"
[4551] "2021-06-17" "2021-06-18" "2021-06-19" "2021-06-20" "2021-06-21"
[4556] "2021-06-22" "2021-06-23" "2021-06-24" "2021-06-25" "2021-06-26"
[4561] "2021-06-27" "2021-06-28" "2021-06-29" "2021-06-30" "2021-07-01"
[4566] "2021-07-02" "2021-07-03" "2021-07-04" "2021-07-05" "2021-07-06"
[4571] "2021-07-07" "2021-07-08" "2021-07-09" "2021-07-10" "2021-07-11"
[4576] "2021-07-12" "2021-07-13" "2021-07-14" "2021-07-15" "2021-07-16"
[4581] "2021-07-17" "2021-07-18" "2021-07-19" "2021-07-20" "2021-07-21"
[4586] "2021-07-22" "2021-07-23" "2021-07-24" "2021-07-25" "2021-07-26"
[4591] "2021-07-27" "2021-07-28" "2021-07-29" "2021-07-30" "2021-07-31"
[4596] "2021-08-01" "2021-08-02" "2021-08-03" "2021-08-04" "2021-08-05"
[4601] "2021-08-06" "2021-08-07" "2021-08-08" "2021-08-09" "2021-08-10"
[4606] "2021-08-11" "2021-08-12" "2021-08-13" "2021-08-14" "2021-08-15"
[4611] "2021-08-16" "2021-08-17" "2021-08-18" "2021-08-19" "2021-08-20"
[4616] "2021-08-21" "2021-08-22" "2021-08-23" "2021-08-24" "2021-08-25"
[4621] "2021-08-26" "2021-08-27" "2021-08-28" "2021-08-29" "2021-08-30"
[4626] "2021-08-31" "2021-09-01" "2021-09-02" "2021-09-03" "2021-09-04"
[4631] "2021-09-05" "2021-09-06" "2021-09-07" "2021-09-08" "2021-09-09"
[4636] "2021-09-10" "2021-09-11" "2021-09-12" "2021-09-13" "2021-09-14"
[4641] "2021-09-15" "2021-09-16" "2021-09-17" "2021-09-18" "2021-09-19"
[4646] "2021-09-20" "2021-09-21" "2021-09-22" "2021-09-23" "2021-09-24"
[4651] "2021-09-25" "2021-09-26" "2021-09-27" "2021-09-28" "2021-09-29"
[4656] "2021-09-30" "2021-10-01" "2021-10-02" "2021-10-03" "2021-10-04"
[4661] "2021-10-05" "2021-10-06" "2021-10-07" "2021-10-08" "2021-10-09"
[4666] "2021-10-10" "2021-10-11" "2021-10-12" "2021-10-13" "2021-10-14"
[4671] "2021-10-15" "2021-10-16" "2021-10-17" "2021-10-18" "2021-10-19"
[4676] "2021-10-20" "2021-10-21" "2021-10-22" "2021-10-23" "2021-10-24"
[4681] "2021-10-25" "2021-10-26" "2021-10-27" "2021-10-28" "2021-10-29"
[4686] "2021-10-30" "2021-10-31" "2021-11-01" "2021-11-02" "2021-11-03"
[4691] "2021-11-04" "2021-11-05" "2021-11-06" "2021-11-07" "2021-11-08"
[4696] "2021-11-09" "2021-11-10" "2021-11-11" "2021-11-12" "2021-11-13"
[4701] "2021-11-14" "2021-11-15" "2021-11-16" "2021-11-17" "2021-11-18"
[4706] "2021-11-19" "2021-11-20" "2021-11-21" "2021-11-22" "2021-11-23"
[4711] "2021-11-24" "2021-11-25" "2021-11-26" "2021-11-27" "2021-11-28"
[4716] "2021-11-29" "2021-11-30" "2021-12-01" "2021-12-02" "2021-12-03"
[4721] "2021-12-04" "2021-12-05" "2021-12-06" "2021-12-07" "2021-12-08"
[4726] "2021-12-09" "2021-12-10" "2021-12-11" "2021-12-12" "2021-12-13"
[4731] "2021-12-14" "2021-12-15" "2021-12-16" "2021-12-17" "2021-12-18"
[4736] "2021-12-19" "2021-12-20" "2021-12-21" "2021-12-22" "2021-12-23"
[4741] "2021-12-24" "2021-12-25" "2021-12-26" "2021-12-27" "2021-12-28"
[4746] "2021-12-29" "2021-12-30" "2021-12-31" "2022-01-01" "2022-01-02"
[4751] "2022-01-03" "2022-01-04" "2022-01-05" "2022-01-06" "2022-01-07"
[4756] "2022-01-08" "2022-01-09" "2022-01-10" "2022-01-11" "2022-01-12"
[4761] "2022-01-13" "2022-01-14" "2022-01-15" "2022-01-16" "2022-01-17"
[4766] "2022-01-18" "2022-01-19" "2022-01-20" "2022-01-21" "2022-01-22"
[4771] "2022-01-23" "2022-01-24" "2022-01-25" "2022-01-26" "2022-01-27"
[4776] "2022-01-28" "2022-01-29" "2022-01-30" "2022-01-31" "2022-02-01"
[4781] "2022-02-02" "2022-02-03" "2022-02-04" "2022-02-05" "2022-02-06"
[4786] "2022-02-07" "2022-02-08" "2022-02-09" "2022-02-10" "2022-02-11"
[4791] "2022-02-12" "2022-02-13" "2022-02-14" "2022-02-15" "2022-02-16"
[4796] "2022-02-17" "2022-02-18" "2022-02-19" "2022-02-20" "2022-02-21"
[4801] "2022-02-22" "2022-02-23" "2022-02-24" "2022-02-25" "2022-02-26"
[4806] "2022-02-27" "2022-02-28" "2022-03-01" "2022-03-02" "2022-03-03"
[4811] "2022-03-04" "2022-03-05" "2022-03-06" "2022-03-07" "2022-03-08"
[4816] "2022-03-09" "2022-03-10" "2022-03-11" "2022-03-12" "2022-03-13"
[4821] "2022-03-14" "2022-03-15" "2022-03-16" "2022-03-17" "2022-03-18"
[4826] "2022-03-19" "2022-03-20" "2022-03-21" "2022-03-22" "2022-03-23"
[4831] "2022-03-24" "2022-03-25" "2022-03-26" "2022-03-27" "2022-03-28"
[4836] "2022-03-29" "2022-03-30" "2022-03-31" "2022-04-01" "2022-04-02"
[4841] "2022-04-03" "2022-04-04" "2022-04-05" "2022-04-06" "2022-04-07"
[4846] "2022-04-08" "2022-04-09" "2022-04-10" "2022-04-11" "2022-04-12"
[4851] "2022-04-13" "2022-04-14" "2022-04-15" "2022-04-16" "2022-04-17"
[4856] "2022-04-18" "2022-04-19" "2022-04-20" "2022-04-21" "2022-04-22"
[4861] "2022-04-23" "2022-04-24" "2022-04-25" "2022-04-26" "2022-04-27"
[4866] "2022-04-28" "2022-04-29" "2022-04-30" "2022-05-01" "2022-05-02"
[4871] "2022-05-03" "2022-05-04" "2022-05-05" "2022-05-06" "2022-05-07"
[4876] "2022-05-08" "2022-05-09" "2022-05-10" "2022-05-11" "2022-05-12"
[4881] "2022-05-13" "2022-05-14" "2022-05-15" "2022-05-16" "2022-05-17"
[4886] "2022-05-18" "2022-05-19" "2022-05-20" "2022-05-21" "2022-05-22"
[4891] "2022-05-23" "2022-05-24" "2022-05-25" "2022-05-26" "2022-05-27"
[4896] "2022-05-28" "2022-05-29" "2022-05-30" "2022-05-31" "2022-06-01"
[4901] "2022-06-02" "2022-06-03" "2022-06-04" "2022-06-05" "2022-06-06"
[4906] "2022-06-07" "2022-06-08" "2022-06-09" "2022-06-10" "2022-06-11"
[4911] "2022-06-12" "2022-06-13" "2022-06-14" "2022-06-15" "2022-06-16"
[4916] "2022-06-17" "2022-06-18" "2022-06-19" "2022-06-20" "2022-06-21"
[4921] "2022-06-22" "2022-06-23" "2022-06-24" "2022-06-25" "2022-06-26"
[4926] "2022-06-27" "2022-06-28" "2022-06-29" "2022-06-30" "2022-07-01"
[4931] "2022-07-02" "2022-07-03" "2022-07-04" "2022-07-05" "2022-07-06"
[4936] "2022-07-07" "2022-07-08" "2022-07-09" "2022-07-10" "2022-07-11"
[4941] "2022-07-12" "2022-07-13" "2022-07-14" "2022-07-15" "2022-07-16"
[4946] "2022-07-17" "2022-07-18" "2022-07-19" "2022-07-20" "2022-07-21"
[4951] "2022-07-22" "2022-07-23" "2022-07-24" "2022-07-25" "2022-07-26"
[4956] "2022-07-27" "2022-07-28" "2022-07-29" "2022-07-30" "2022-07-31"
[4961] "2022-08-01" "2022-08-02" "2022-08-03" "2022-08-04" "2022-08-05"
[4966] "2022-08-06" "2022-08-07" "2022-08-08" "2022-08-09" "2022-08-10"
[4971] "2022-08-11" "2022-08-12" "2022-08-13" "2022-08-14" "2022-08-15"
[4976] "2022-08-16" "2022-08-17" "2022-08-18" "2022-08-19" "2022-08-20"
[4981] "2022-08-21" "2022-08-22" "2022-08-23" "2022-08-24" "2022-08-25"
[4986] "2022-08-26" "2022-08-27" "2022-08-28" "2022-08-29" "2022-08-30"
[4991] "2022-08-31" "2022-09-01" "2022-09-02" "2022-09-03" "2022-09-04"
[4996] "2022-09-05" "2022-09-06" "2022-09-07" "2022-09-08" "2022-09-09"
[5001] "2022-09-10" "2022-09-11" "2022-09-12" "2022-09-13" "2022-09-14"
[5006] "2022-09-15" "2022-09-16" "2022-09-17" "2022-09-18" "2022-09-19"
[5011] "2022-09-20" "2022-09-21" "2022-09-22" "2022-09-23" "2022-09-24"
[5016] "2022-09-25" "2022-09-26" "2022-09-27" "2022-09-28" "2022-09-29"
[5021] "2022-09-30" "2022-10-01" "2022-10-02" "2022-10-03" "2022-10-04"
[5026] "2022-10-05" "2022-10-06" "2022-10-07" "2022-10-08" "2022-10-09"
[5031] "2022-10-10" "2022-10-11" "2022-10-12" "2022-10-13" "2022-10-14"
[5036] "2022-10-15" "2022-10-16" "2022-10-17" "2022-10-18" "2022-10-19"
[5041] "2022-10-20" "2022-10-21" "2022-10-22" "2022-10-23" "2022-10-24"
[5046] "2022-10-25" "2022-10-26" "2022-10-27" "2022-10-28" "2022-10-29"
[5051] "2022-10-30" "2022-10-31" "2022-11-01" "2022-11-02" "2022-11-03"
[5056] "2022-11-04" "2022-11-05" "2022-11-06" "2022-11-07" "2022-11-08"
[5061] "2022-11-09" "2022-11-10" "2022-11-11" "2022-11-12" "2022-11-13"
[5066] "2022-11-14" "2022-11-15" "2022-11-16" "2022-11-17" "2022-11-18"
[5071] "2022-11-19" "2022-11-20" "2022-11-21" "2022-11-22" "2022-11-23"
[5076] "2022-11-24" "2022-11-25" "2022-11-26" "2022-11-27" "2022-11-28"
[5081] "2022-11-29" "2022-11-30" "2022-12-01" "2022-12-02" "2022-12-03"
[5086] "2022-12-04" "2022-12-05" "2022-12-06" "2022-12-07" "2022-12-08"
[5091] "2022-12-09" "2022-12-10" "2022-12-11" "2022-12-12" "2022-12-13"
[5096] "2022-12-14" "2022-12-15" "2022-12-16" "2022-12-17" "2022-12-18"
[5101] "2022-12-19" "2022-12-20" "2022-12-21" "2022-12-22" "2022-12-23"
[5106] "2022-12-24" "2022-12-25" "2022-12-26" "2022-12-27" "2022-12-28"
[5111] "2022-12-29" "2022-12-30" "2022-12-31" "2023-01-01"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{seq}\NormalTok{(}\FunctionTok{ymd\_hm}\NormalTok{(}\StringTok{"2015{-}1{-}1 0:00"}\NormalTok{), }\FunctionTok{ymd\_hm}\NormalTok{(}\StringTok{"2015{-}1{-}1 12:00"}\NormalTok{), }\AttributeTok{by =} \StringTok{"hour"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] "2015-01-01 00:00:00 UTC" "2015-01-01 01:00:00 UTC"
 [3] "2015-01-01 02:00:00 UTC" "2015-01-01 03:00:00 UTC"
 [5] "2015-01-01 04:00:00 UTC" "2015-01-01 05:00:00 UTC"
 [7] "2015-01-01 06:00:00 UTC" "2015-01-01 07:00:00 UTC"
 [9] "2015-01-01 08:00:00 UTC" "2015-01-01 09:00:00 UTC"
[11] "2015-01-01 10:00:00 UTC" "2015-01-01 11:00:00 UTC"
[13] "2015-01-01 12:00:00 UTC"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y.earnings }\OtherTok{\textless{}{-}}\NormalTok{ earnings }\SpecialCharTok{|\textgreater{}} \FunctionTok{mutate}\NormalTok{(}\AttributeTok{Date =} \FunctionTok{seq}\NormalTok{(}\FunctionTok{ymd\_hm}\NormalTok{(}\StringTok{"2009{-}1{-}1 0:00"}\NormalTok{), }\FunctionTok{ymd\_hm}\NormalTok{(}\StringTok{"2023{-}12{-}1 12:00"}\NormalTok{), }\AttributeTok{by =} \StringTok{"month"}\NormalTok{))}
\NormalTok{y.earnings}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 180 x 4
   Month     Year  Earnings Date               
   <chr>     <chr>    <dbl> <dttm>             
 1 January   2009      30   2009-01-01 00:00:00
 2 February  2009      26.7 2009-02-01 00:00:00
 3 March     2009      26.6 2009-03-01 00:00:00
 4 April     2009      20.3 2009-04-01 00:00:00
 5 May       2009      19.3 2009-05-01 00:00:00
 6 June      2009      23.6 2009-06-01 00:00:00
 7 July      2009      33   2009-07-01 00:00:00
 8 August    2009      32.2 2009-08-01 00:00:00
 9 September 2009      29.6 2009-09-01 00:00:00
10 October   2009      29.3 2009-10-01 00:00:00
# i 170 more rows
\end{verbatim}

Create year-month column

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y.earnings }\OtherTok{\textless{}{-}}\NormalTok{ y.earnings }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{select}\NormalTok{(Earnings, Date) }\SpecialCharTok{|\textgreater{}} \FunctionTok{mutate}\NormalTok{(}\AttributeTok{Time =} \FunctionTok{yearmonth}\NormalTok{(Date))}
\NormalTok{y.earnings}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 180 x 3
   Earnings Date                    Time
      <dbl> <dttm>                 <mth>
 1     30   2009-01-01 00:00:00 2009 Jan
 2     26.7 2009-02-01 00:00:00 2009 Feb
 3     26.6 2009-03-01 00:00:00 2009 Mar
 4     20.3 2009-04-01 00:00:00 2009 Apr
 5     19.3 2009-05-01 00:00:00 2009 May
 6     23.6 2009-06-01 00:00:00 2009 Jun
 7     33   2009-07-01 00:00:00 2009 Jul
 8     32.2 2009-08-01 00:00:00 2009 Aug
 9     29.6 2009-09-01 00:00:00 2009 Sep
10     29.3 2009-10-01 00:00:00 2009 Oct
# i 170 more rows
\end{verbatim}

Convert it to tsibble

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ts.earnings }\OtherTok{\textless{}{-}}\NormalTok{ y.earnings }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{select}\NormalTok{(Earnings, Time) }\SpecialCharTok{|\textgreater{}} \FunctionTok{as\_tsibble}\NormalTok{(}\AttributeTok{index=}\NormalTok{Time)}
\NormalTok{ts.earnings}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tsibble: 180 x 2 [1M]
   Earnings     Time
      <dbl>    <mth>
 1     30   2009 Jan
 2     26.7 2009 Feb
 3     26.6 2009 Mar
 4     20.3 2009 Apr
 5     19.3 2009 May
 6     23.6 2009 Jun
 7     33   2009 Jul
 8     32.2 2009 Aug
 9     29.6 2009 Sep
10     29.3 2009 Oct
# i 170 more rows
\end{verbatim}

\#\#Other time class functions

Quarterly: yearquarter()

Weekly: yearweek()

Your turn: Find about other time class functions.

Help: https://otexts.com/fpp3/tsibbles.html

\section{Data Visualisation}\label{data-visualisation}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(feasts)}
\NormalTok{ts.earnings }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{autoplot}\NormalTok{(Earnings) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{y =} \StringTok{"Earnings from tourism (USD Mn)"}\NormalTok{, }\AttributeTok{x=}\StringTok{"Time"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{05-chap5_files/figure-pdf/unnamed-chunk-19-1.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{tail}\NormalTok{(ts.earnings)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tsibble: 6 x 2 [1M]
  Earnings     Time
     <dbl>    <mth>
1     219  2023 Jul
2     210. 2023 Aug
3     152. 2023 Sep
4     137. 2023 Oct
5     205. 2023 Nov
6     269. 2023 Dec
\end{verbatim}

\section{Obtain ACF and PACF}\label{obtain-acf-and-pacf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{end\_time }\OtherTok{\textless{}{-}} \FunctionTok{max}\NormalTok{(ts.earnings}\SpecialCharTok{$}\NormalTok{Time)}
\NormalTok{end\_time }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<yearmonth[1]>
[1] "2023 Dec"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train }\OtherTok{\textless{}{-}}\NormalTok{ ts.earnings }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(Time }\SpecialCharTok{\textless{}=}\NormalTok{ end\_time }\SpecialCharTok{{-}} \DecValTok{12}\NormalTok{)}

\NormalTok{test }\OtherTok{\textless{}{-}}\NormalTok{ ts.earnings }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(Time }\SpecialCharTok{\textgreater{}}\NormalTok{ end\_time }\SpecialCharTok{{-}} \DecValTok{12}\NormalTok{)}

\FunctionTok{head}\NormalTok{(train)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tsibble: 6 x 2 [1M]
  Earnings     Time
     <dbl>    <mth>
1     30   2009 Jan
2     26.7 2009 Feb
3     26.6 2009 Mar
4     20.3 2009 Apr
5     19.3 2009 May
6     23.6 2009 Jun
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{tail}\NormalTok{(train)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tsibble: 6 x 2 [1M]
  Earnings     Time
     <dbl>    <mth>
1     85   2022 Jul
2     67.9 2022 Aug
3     40.5 2022 Sep
4     54.9 2022 Oct
5     81   2022 Nov
6    127.  2022 Dec
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{head}\NormalTok{(test)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tsibble: 6 x 2 [1M]
  Earnings     Time
     <dbl>    <mth>
1     154. 2023 Jan
2     162. 2023 Feb
3     189. 2023 Mar
4     148. 2023 Apr
5     100  2023 May
6     123. 2023 Jun
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{tail}\NormalTok{(test)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tsibble: 6 x 2 [1M]
  Earnings     Time
     <dbl>    <mth>
1     219  2023 Jul
2     210. 2023 Aug
3     152. 2023 Sep
4     137. 2023 Oct
5     205. 2023 Nov
6     269. 2023 Dec
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(feasts)}
\NormalTok{train }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{autoplot}\NormalTok{(Earnings)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{05-chap5_files/figure-pdf/unnamed-chunk-21-1.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ACF}\NormalTok{(Earnings) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{autoplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"ACF Plot of Value"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{05-chap5_files/figure-pdf/unnamed-chunk-22-1.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{PACF}\NormalTok{(Earnings) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{autoplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"PACF Plot of Value"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{05-chap5_files/figure-pdf/unnamed-chunk-23-1.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{Value\_diff =} \FunctionTok{difference}\NormalTok{(Earnings)) }\SpecialCharTok{|\textgreater{}}  \CommentTok{\# Take first difference}
  \FunctionTok{ACF}\NormalTok{(Value\_diff, }\AttributeTok{na\_action =} \StringTok{"omit"}\NormalTok{, }\AttributeTok{lag\_max=}\DecValTok{37}\NormalTok{) }\SpecialCharTok{|\textgreater{}}    \CommentTok{\# Compute ACF}
  \FunctionTok{autoplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"ACF Plot of Differenced Value"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{05-chap5_files/figure-pdf/unnamed-chunk-24-1.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{Value\_diff =} \FunctionTok{difference}\NormalTok{(Earnings)) }\SpecialCharTok{|\textgreater{}}  \CommentTok{\# Take first difference}
  \FunctionTok{PACF}\NormalTok{(Value\_diff, }\AttributeTok{na\_action =} \StringTok{"omit"}\NormalTok{, }\AttributeTok{lag\_max=}\DecValTok{37}\NormalTok{) }\SpecialCharTok{|\textgreater{}}    \CommentTok{\# Compute ACF}
  \FunctionTok{autoplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"PACF Plot of Differenced Value"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{05-chap5_files/figure-pdf/unnamed-chunk-25-1.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{sdiff1 =} \FunctionTok{difference}\NormalTok{(Earnings, }\AttributeTok{lag =} \DecValTok{12}\NormalTok{)) }\SpecialCharTok{|\textgreater{}}  \CommentTok{\# Take first difference}
  \FunctionTok{ACF}\NormalTok{(sdiff1, }\AttributeTok{na\_action =} \StringTok{"omit"}\NormalTok{) }\SpecialCharTok{|\textgreater{}}    \CommentTok{\# Compute ACF}
  \FunctionTok{autoplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"ACF Plot of Seasonally Differenced Value"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{05-chap5_files/figure-pdf/unnamed-chunk-26-1.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{sdiff1 =} \FunctionTok{difference}\NormalTok{(Earnings, }\AttributeTok{lag =} \DecValTok{12}\NormalTok{)) }\SpecialCharTok{|\textgreater{}}  \CommentTok{\# Take first difference}
  \FunctionTok{PACF}\NormalTok{(sdiff1, }\AttributeTok{na\_action =} \StringTok{"omit"}\NormalTok{) }\SpecialCharTok{|\textgreater{}}    \CommentTok{\# Compute ACF}
  \FunctionTok{autoplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"PACF Plot of Seasonally Differenced Value"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{05-chap5_files/figure-pdf/unnamed-chunk-27-1.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{diff\_both =} \FunctionTok{difference}\NormalTok{(}\FunctionTok{difference}\NormalTok{(Earnings, }\AttributeTok{lag =} \DecValTok{1}\NormalTok{), }\AttributeTok{lag =} \DecValTok{12}\NormalTok{)}
\NormalTok{  ) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ACF}\NormalTok{(diff\_both, }\AttributeTok{na\_action =} \StringTok{"omit"}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{autoplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"ACF: First + Seasonal Differenced Earnings"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{05-chap5_files/figure-pdf/unnamed-chunk-28-1.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{diff\_both =} \FunctionTok{difference}\NormalTok{(}\FunctionTok{difference}\NormalTok{(Earnings, }\AttributeTok{lag =} \DecValTok{1}\NormalTok{), }\AttributeTok{lag =} \DecValTok{12}\NormalTok{)}
\NormalTok{  ) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{PACF}\NormalTok{(diff\_both, }\AttributeTok{na\_action =} \StringTok{"omit"}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{autoplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"PACF: First + Seasonal Differenced Earnings"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{05-chap5_files/figure-pdf/unnamed-chunk-29-1.pdf}}

\section{Fitting a SARIMA model:
Auto}\label{fitting-a-sarima-model-auto}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sarima\_auto }\OtherTok{\textless{}{-}}\NormalTok{ train }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{model}\NormalTok{(}
    \AttributeTok{auto =} \FunctionTok{ARIMA}\NormalTok{(Earnings }\SpecialCharTok{\textasciitilde{}} \FunctionTok{pdq}\NormalTok{() }\SpecialCharTok{+} \FunctionTok{PDQ}\NormalTok{(}\AttributeTok{period =} \DecValTok{12}\NormalTok{))}
\NormalTok{  )}

\CommentTok{\# View model summary}
\FunctionTok{report}\NormalTok{(sarima\_auto)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Series: Earnings 
Model: ARIMA(0,1,3)(0,1,0)[12] 

Coefficients:
         ma1     ma2      ma3
      0.1602  0.2117  -0.1468
s.e.  0.0921  0.0851   0.1187

sigma^2 estimated as 1712:  log likelihood=-762.53
AIC=1533.06   AICc=1533.33   BIC=1545.24
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{h\_test }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(test)}

\NormalTok{fc }\OtherTok{\textless{}{-}}\NormalTok{ sarima\_auto }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{forecast}\NormalTok{(}\AttributeTok{h =}\NormalTok{ h\_test)}
\NormalTok{fc}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A fable: 12 x 4 [1M]
# Key:     .model [1]
   .model     Time
   <chr>     <mth>
 1 auto   2023 Jan
 2 auto   2023 Feb
 3 auto   2023 Mar
 4 auto   2023 Apr
 5 auto   2023 May
 6 auto   2023 Jun
 7 auto   2023 Jul
 8 auto   2023 Aug
 9 auto   2023 Sep
10 auto   2023 Oct
11 auto   2023 Nov
12 auto   2023 Dec
# i 2 more variables: Earnings <dist>, .mean <dbl>
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#library(fabletools)}

\FunctionTok{accuracy}\NormalTok{(fc, test)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 1 x 10
  .model .type    ME  RMSE   MAE   MPE  MAPE  MASE RMSSE  ACF1
  <chr>  <chr> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>
1 auto   Test   205.  211.  205.  124.  124.   NaN   NaN 0.695
\end{verbatim}

\section{Fitting a SARIMA model:
Manual}\label{fitting-a-sarima-model-manual}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sarima\_111\_110 }\OtherTok{\textless{}{-}}\NormalTok{ train }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{model}\NormalTok{(}
    \AttributeTok{SARIMA =} \FunctionTok{ARIMA}\NormalTok{(}
\NormalTok{      Earnings }\SpecialCharTok{\textasciitilde{}} 
        \FunctionTok{pdq}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{) }\SpecialCharTok{+} 
        \FunctionTok{PDQ}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{, }\AttributeTok{period =} \DecValTok{12}\NormalTok{)}
\NormalTok{    )}
\NormalTok{  )}

\FunctionTok{report}\NormalTok{(sarima\_111\_110)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Series: Earnings 
Model: ARIMA(2,1,2)(0,1,0)[12] 

Coefficients:
          ar1      ar2     ma1     ma2
      -0.7291  -0.5999  0.8454  0.8495
s.e.   0.3588   0.2701  0.2574  0.1881

sigma^2 estimated as 1681:  log likelihood=-760.7
AIC=1531.39   AICc=1531.8   BIC=1546.61
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fcmanual }\OtherTok{\textless{}{-}}\NormalTok{ sarima\_111\_110 }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{forecast}\NormalTok{(}\AttributeTok{h =}\NormalTok{ h\_test)}
\NormalTok{fcmanual}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A fable: 12 x 4 [1M]
# Key:     .model [1]
   .model     Time
   <chr>     <mth>
 1 SARIMA 2023 Jan
 2 SARIMA 2023 Feb
 3 SARIMA 2023 Mar
 4 SARIMA 2023 Apr
 5 SARIMA 2023 May
 6 SARIMA 2023 Jun
 7 SARIMA 2023 Jul
 8 SARIMA 2023 Aug
 9 SARIMA 2023 Sep
10 SARIMA 2023 Oct
11 SARIMA 2023 Nov
12 SARIMA 2023 Dec
# i 2 more variables: Earnings <dist>, .mean <dbl>
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{accuracy}\NormalTok{(fcmanual, test)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 1 x 10
  .model .type    ME  RMSE   MAE   MPE  MAPE  MASE RMSSE  ACF1
  <chr>  <chr> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>
1 SARIMA Test   195.  201.  195.  117.  117.   NaN   NaN 0.707
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sarima\_111\_110 }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{gg\_tsresiduals}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{05-chap5_files/figure-pdf/unnamed-chunk-33-1.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sarima\_313\_100 }\OtherTok{\textless{}{-}}\NormalTok{ train }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{model}\NormalTok{(}
    \AttributeTok{SARIMA =} \FunctionTok{ARIMA}\NormalTok{(}
\NormalTok{      Earnings }\SpecialCharTok{\textasciitilde{}} 
        \FunctionTok{pdq}\NormalTok{(}\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{3}\NormalTok{) }\SpecialCharTok{+} 
        \FunctionTok{PDQ}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, }\AttributeTok{period =} \DecValTok{12}\NormalTok{)}
\NormalTok{    )}
\NormalTok{  )}

\FunctionTok{report}\NormalTok{(sarima\_313\_100)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Series: Earnings 
Model: NULL model 
NULL model
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fcmanual2 }\OtherTok{\textless{}{-}}\NormalTok{ sarima\_313\_100 }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{forecast}\NormalTok{(}\AttributeTok{h =}\NormalTok{ h\_test)}
\NormalTok{fcmanual2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A fable: 12 x 4 [1M]
# Key:     .model [1]
   .model     Time Earnings .mean
   <chr>     <mth>   <dist> <dbl>
 1 SARIMA 2023 Jan       NA    NA
 2 SARIMA 2023 Feb       NA    NA
 3 SARIMA 2023 Mar       NA    NA
 4 SARIMA 2023 Apr       NA    NA
 5 SARIMA 2023 May       NA    NA
 6 SARIMA 2023 Jun       NA    NA
 7 SARIMA 2023 Jul       NA    NA
 8 SARIMA 2023 Aug       NA    NA
 9 SARIMA 2023 Sep       NA    NA
10 SARIMA 2023 Oct       NA    NA
11 SARIMA 2023 Nov       NA    NA
12 SARIMA 2023 Dec       NA    NA
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{accuracy}\NormalTok{(fcmanual2, test)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 1 x 10
  .model .type    ME  RMSE   MAE   MPE  MAPE  MASE RMSSE  ACF1
  <chr>  <chr> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>
1 SARIMA Test    NaN   NaN   NaN   NaN   NaN   NaN   NaN    NA
\end{verbatim}

\bookmarksetup{startatroot}

\chapter{Spatial Data Visualisation}\label{spatial-data-visualisation}

\section{R packages for spatial data
analysis}\label{r-packages-for-spatial-data-analysis}

\begin{itemize}
\item
  rgdal
\item
  sp
\item
  rgeos
\item
  raster
\item
  sf
\item
  tmap
\item
  leaflet
\item
  ggmap
\item
  maptools
\item
  gstat
\item
  spatstat
\item
  stars
\item
  geosphere
\item
  RgoogleMaps
\item
  rasterVis
\end{itemize}

\section{Geospatial vector data
structures}\label{geospatial-vector-data-structures}

\begin{itemize}
\item
  Point: Individual longitude and latitude of locations

  Eg: Locations, Buildings
\item
  Lines: Two or more vertices or points that are connected

  Eg: Roads, rivers
\item
  Polygons: Three or more vertices and closed

  Eg: Area of a country, state, district
\end{itemize}

\section{Challenge in Spatial Data
Viualisation}\label{challenge-in-spatial-data-viualisation}

Move from

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/globe-world.gif}}

to

\pandocbounded{\includegraphics[keepaspectratio]{06-chap6_files/figure-pdf/unnamed-chunk-1-1.pdf}}

How to transform this three dimensional angular system to a two
dimensional cartesian system?

Solution: Spatial Projections

\section{Map Projection}\label{map-projection}

\begin{itemize}
\item
  A projection is about the geometric transformation from 3D to 2D.
\item
  A map projection is a method or mathematical formula to represent the
  curved surface of the Earth on a flat map.
\item
  It focuses on how the Earth's surface is ``flattened'', which always
  introduces some distortion in area, shape, distance, or direction.
\end{itemize}

Examples:

Mercator (preserves direction)

Albers Equal-Area Conic (preserves area)

Goode Homolosine (minimizes distortion globally)

\section{Types of Map Projections}\label{types-of-map-projections}

\subsection{Cylindrical Projections}\label{cylindrical-projections}

Imagine wrapping a cylinder around the Earth and projecting the surface
onto it.

Characteristics:

Meridians and parallels are straight and perpendicular.

Distortion increases away from the equator.

Example:

Mercator Projection -- preserves direction, but greatly distorts area
near the poles.

\subsection{Conical Projections}\label{conical-projections}

Imagine wrapping a cone over the Earth, usually touching at one or two
standard parallels.

Characteristics:

Parallels appear as arcs; meridians converge toward a point.

Best for mid-latitude regions with an east--west extent.

Example:

Albers Equal-Area Conic -- preserves area, commonly used for countries
or regions.

\subsection{Planar (Azimuthal)
Projections}\label{planar-azimuthal-projections}

The Earth's surface is projected onto a flat plane, usually touching at
a single point.

Characteristics:

Distortion increases outward from the point of tangency.

Can preserve distance, area, or shape depending on the type.

Example:

Goode Homolosine -- minimizes global distortion by combining multiple
projection methods.

Visit
\href{https://johnedevans.files.wordpress.com/2019/01/map-projections-explained.jpg}{here}
to see the visual illustration.

\section{Example maps}\label{example-maps}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p1}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{06-chap6_files/figure-pdf/unnamed-chunk-4-1.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p2}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{06-chap6_files/figure-pdf/unnamed-chunk-4-2.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p3}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{06-chap6_files/figure-pdf/unnamed-chunk-4-3.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p4}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{06-chap6_files/figure-pdf/unnamed-chunk-4-4.pdf}}

\section{Why Multiple Map Projection Types
Exist}\label{why-multiple-map-projection-types-exist}

The Earth is round, but maps are flat. Because no flat map can perfectly
preserve all properties of the globe, every projection introduces some
distortion. Different projections are therefore designed to preserve
certain properties depending on the map's purpose.

\subsection{Key Reasons for Multiple Projection
Types}\label{key-reasons-for-multiple-projection-types}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Different Types of Distortion
\end{enumerate}

Shape (conformal) -- keeps angles and shapes correct (e.g., Mercator).

Area (equal-area / equivalent) -- keeps relative sizes correct (e.g.,
Albers Equal-Area Conic).

Distance (equidistant) -- preserves distances from a point or along
certain lines (e.g., Azimuthal Equidistant).

Direction (azimuthal / navigational) -- preserves angles and compass
bearings (e.g., Mercator for navigation).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Geographical Focus
\end{enumerate}

Some projections are better for global maps, others for regional or
local maps.

Example: Conical projections work well for mid-latitude countries, while
planar projections work for polar regions.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Practical Applications
\end{enumerate}

Navigation -- need accurate direction ‚Üí Mercator.

Thematic / statistical maps -- need accurate area ‚Üí Albers Equal-Area.

Minimizing overall distortion -- Goode Homolosine for global thematic
maps.

\section{Quick Comparison Table}\label{quick-comparison-table}

In-class

\section{Coordinate Reference System
(CRS)}\label{coordinate-reference-system-crs}

A CRS is a complete spatial reference framework that defines:

\begin{itemize}
\item
  How coordinates relate to the Earth (datum)

  A datum defines the mathematical Earth model and reference point for
  coordinates, ensuring that latitude, longitude, and height correspond
  to real positions on the Earth.)
\item
  The map projection used (if any)
\end{itemize}

\section{What is a Datum?}\label{what-is-a-datum}

A datum is a mathematical model of the Earth that defines:

The size and shape of the Earth (ellipsoid or spheroid)

The origin and orientation of the coordinate system (where latitude 0¬∞,
longitude 0¬∞ are defined)

In short, a datum tells us where ``zero'' is and how the coordinates are
measured on the Earth's surface.

\section{Why is a Datum Important?}\label{why-is-a-datum-important}

Different datums model the Earth slightly differently, so the same
latitude/longitude may correspond to different locations depending on
the datum.

Example:

WGS84 ‚Üí used by GPS

NAD83 ‚Üí used in North America

A coordinate of 40¬∞N, 75¬∞W will be slightly different on WGS84 vs NAD83
because the reference ellipsoid is slightly shifted.

\section{Projection vs CRS}\label{projection-vs-crs}

\begin{itemize}
\item
  Projection = method to flatten the Earth
\item
  CRS = full system that defines the Earth model + projection +
  coordinate rules
\end{itemize}

\section{Shapefile}\label{shapefile}

A shapefile is a popular geospatial vector data format used to store
geographic features like points, lines, and polygons, along with their
attributes. It's commonly used in GIS (Geographic Information Systems)
and mapping software, including R (sf or rgdal packages).

A shapefile actually consists of several files that work together. The
main ones are:

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.6400}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.3600}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
File Extension
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Purpose
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
.shp & Geometry of features (points, lines, polygons) \\
.shx & Shape index (helps software find features quickly) \\
.dbf & Attribute data (like a spreadsheet) \\
.prj & Projection information (coordinate reference system) \\
.cpg & Encoding of text attributes (optional) \\
\end{longtable}

\subsection{R Example 1}\label{r-example-1}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Read shapefile}
\NormalTok{world }\OtherTok{\textless{}{-}} \FunctionTok{ne\_countries}\NormalTok{(}\AttributeTok{scale =} \StringTok{"medium"}\NormalTok{, }\AttributeTok{returnclass =} \StringTok{"sf"}\NormalTok{)}
\FunctionTok{head}\NormalTok{(world)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Simple feature collection with 6 features and 168 fields
Geometry type: MULTIPOLYGON
Dimension:     XY
Bounding box:  xmin: -73.36621 ymin: -22.40205 xmax: 109.4449 ymax: 41.9062
Geodetic CRS:  WGS 84
       featurecla scalerank labelrank sovereignt sov_a3 adm0_dif level
1 Admin-0 country         1         3   Zimbabwe    ZWE        0     2
2 Admin-0 country         1         3     Zambia    ZMB        0     2
3 Admin-0 country         1         3      Yemen    YEM        0     2
4 Admin-0 country         3         2    Vietnam    VNM        0     2
5 Admin-0 country         5         3  Venezuela    VEN        0     2
6 Admin-0 country         6         6    Vatican    VAT        0     2
               type tlc     admin adm0_a3 geou_dif   geounit gu_a3 su_dif
1 Sovereign country   1  Zimbabwe     ZWE        0  Zimbabwe   ZWE      0
2 Sovereign country   1    Zambia     ZMB        0    Zambia   ZMB      0
3 Sovereign country   1     Yemen     YEM        0     Yemen   YEM      0
4 Sovereign country   1   Vietnam     VNM        0   Vietnam   VNM      0
5 Sovereign country   1 Venezuela     VEN        0 Venezuela   VEN      0
6 Sovereign country   1   Vatican     VAT        0   Vatican   VAT      0
    subunit su_a3 brk_diff      name name_long brk_a3  brk_name brk_group
1  Zimbabwe   ZWE        0  Zimbabwe  Zimbabwe    ZWE  Zimbabwe      <NA>
2    Zambia   ZMB        0    Zambia    Zambia    ZMB    Zambia      <NA>
3     Yemen   YEM        0     Yemen     Yemen    YEM     Yemen      <NA>
4   Vietnam   VNM        0   Vietnam   Vietnam    VNM   Vietnam      <NA>
5 Venezuela   VEN        0 Venezuela Venezuela    VEN Venezuela      <NA>
6   Vatican   VAT        0   Vatican   Vatican    VAT   Vatican      <NA>
  abbrev postal                        formal_en
1  Zimb.     ZW             Republic of Zimbabwe
2 Zambia     ZM               Republic of Zambia
3   Yem.     YE                Republic of Yemen
4  Viet.     VN    Socialist Republic of Vietnam
5   Ven.     VE Bolivarian Republic of Venezuela
6   Vat.      V        State of the Vatican City
                           formal_fr              name_ciawf note_adm0 note_brk
1                               <NA>                Zimbabwe      <NA>     <NA>
2                               <NA>                  Zambia      <NA>     <NA>
3                               <NA>                   Yemen      <NA>     <NA>
4                               <NA>                 Vietnam      <NA>     <NA>
5 Rep√∫blica Bolivariana de Venezuela               Venezuela      <NA>     <NA>
6                               <NA> Holy See (Vatican City)      <NA>     <NA>
           name_sort name_alt mapcolor7 mapcolor8 mapcolor9 mapcolor13  pop_est
1           Zimbabwe     <NA>         1         5         3          9 14645468
2             Zambia     <NA>         5         8         5         13 17861030
3        Yemen, Rep.     <NA>         5         3         3         11 29161922
4            Vietnam     <NA>         5         6         5          4 96462106
5      Venezuela, RB     <NA>         1         3         1          4 28515829
6 Vatican (Holy See) Holy See         1         3         4          2      825
  pop_rank pop_year gdp_md gdp_year                    economy
1       14     2019  21440     2019    5. Emerging region: G20
2       14     2019  23309     2019  7. Least developed region
3       15     2019  22581     2019  7. Least developed region
4       16     2019 261921     2019    5. Emerging region: G20
5       15     2019 482359     2014    5. Emerging region: G20
6        2     2019    -99     2019 2. Developed region: nonG7
               income_grp fips_10 iso_a2 iso_a2_eh iso_a3 iso_a3_eh iso_n3
1           5. Low income      ZI     ZW        ZW    ZWE       ZWE    716
2  4. Lower middle income      ZA     ZM        ZM    ZMB       ZMB    894
3  4. Lower middle income      YM     YE        YE    YEM       YEM    887
4  4. Lower middle income      VM     VN        VN    VNM       VNM    704
5  3. Upper middle income      VE     VE        VE    VEN       VEN    862
6 2. High income: nonOECD      VT     VA        VA    VAT       VAT    336
  iso_n3_eh un_a3 wb_a2 wb_a3   woe_id woe_id_eh                   woe_note
1       716   716    ZW   ZWE 23425004  23425004 Exact WOE match as country
2       894   894    ZM   ZMB 23425003  23425003 Exact WOE match as country
3       887   887    RY   YEM 23425002  23425002 Exact WOE match as country
4       704   704    VN   VNM 23424984  23424984 Exact WOE match as country
5       862   862    VE   VEN 23424982  23424982 Exact WOE match as country
6       336   336   -99   -99 23424986  23424986 Exact WOE match as country
  adm0_iso adm0_diff adm0_tlc adm0_a3_us adm0_a3_fr adm0_a3_ru adm0_a3_es
1      ZWE      <NA>      ZWE        ZWE        ZWE        ZWE        ZWE
2      ZMB      <NA>      ZMB        ZMB        ZMB        ZMB        ZMB
3      YEM      <NA>      YEM        YEM        YEM        YEM        YEM
4      VNM      <NA>      VNM        VNM        VNM        VNM        VNM
5      VEN      <NA>      VEN        VEN        VEN        VEN        VEN
6      VAT      <NA>      VAT        VAT        VAT        VAT        VAT
  adm0_a3_cn adm0_a3_tw adm0_a3_in adm0_a3_np adm0_a3_pk adm0_a3_de adm0_a3_gb
1        ZWE        ZWE        ZWE        ZWE        ZWE        ZWE        ZWE
2        ZMB        ZMB        ZMB        ZMB        ZMB        ZMB        ZMB
3        YEM        YEM        YEM        YEM        YEM        YEM        YEM
4        VNM        VNM        VNM        VNM        VNM        VNM        VNM
5        VEN        VEN        VEN        VEN        VEN        VEN        VEN
6        VAT        VAT        VAT        VAT        VAT        VAT        VAT
  adm0_a3_br adm0_a3_il adm0_a3_ps adm0_a3_sa adm0_a3_eg adm0_a3_ma adm0_a3_pt
1        ZWE        ZWE        ZWE        ZWE        ZWE        ZWE        ZWE
2        ZMB        ZMB        ZMB        ZMB        ZMB        ZMB        ZMB
3        YEM        YEM        YEM        YEM        YEM        YEM        YEM
4        VNM        VNM        VNM        VNM        VNM        VNM        VNM
5        VEN        VEN        VEN        VEN        VEN        VEN        VEN
6        VAT        VAT        VAT        VAT        VAT        VAT        VAT
  adm0_a3_ar adm0_a3_jp adm0_a3_ko adm0_a3_vn adm0_a3_tr adm0_a3_id adm0_a3_pl
1        ZWE        ZWE        ZWE        ZWE        ZWE        ZWE        ZWE
2        ZMB        ZMB        ZMB        ZMB        ZMB        ZMB        ZMB
3        YEM        YEM        YEM        YEM        YEM        YEM        YEM
4        VNM        VNM        VNM        VNM        VNM        VNM        VNM
5        VEN        VEN        VEN        VEN        VEN        VEN        VEN
6        VAT        VAT        VAT        VAT        VAT        VAT        VAT
  adm0_a3_gr adm0_a3_it adm0_a3_nl adm0_a3_se adm0_a3_bd adm0_a3_ua adm0_a3_un
1        ZWE        ZWE        ZWE        ZWE        ZWE        ZWE        -99
2        ZMB        ZMB        ZMB        ZMB        ZMB        ZMB        -99
3        YEM        YEM        YEM        YEM        YEM        YEM        -99
4        VNM        VNM        VNM        VNM        VNM        VNM        -99
5        VEN        VEN        VEN        VEN        VEN        VEN        -99
6        VAT        VAT        VAT        VAT        VAT        VAT        -99
  adm0_a3_wb     continent region_un          subregion
1        -99        Africa    Africa     Eastern Africa
2        -99        Africa    Africa     Eastern Africa
3        -99          Asia      Asia       Western Asia
4        -99          Asia      Asia South-Eastern Asia
5        -99 South America  Americas      South America
6        -99        Europe    Europe    Southern Europe
                   region_wb name_len long_len abbrev_len tiny homepart
1         Sub-Saharan Africa        8        8          5  -99        1
2         Sub-Saharan Africa        6        6          6  -99        1
3 Middle East & North Africa        5        5          4  -99        1
4        East Asia & Pacific        7        7          5    2        1
5  Latin America & Caribbean        9        9          4  -99        1
6      Europe & Central Asia        7        7          4    4        1
  min_zoom min_label max_label   label_x    label_y      ne_id wikidataid
1        0       2.5       8.0  29.92544 -18.911640 1159321441       Q954
2        0       3.0       8.0  26.39530 -14.660804 1159321439       Q953
3        0       3.0       8.0  45.87438  15.328226 1159321425       Q805
4        0       2.0       7.0 105.38729  21.715416 1159321417       Q881
5        0       2.5       7.5 -64.59938   7.182476 1159321411       Q717
6        0       5.0      10.0  12.45342  41.903323 1159321407       Q237
    name_ar       name_bn      name_de      name_en             name_es
1  ÿ≤ŸäŸÖÿ®ÿßÿ®ŸàŸä      ‡¶ú‡¶ø‡¶Æ‡ßç‡¶¨‡¶æ‡¶¨‡ßÅ‡¶Ø‡¶º‡ßá     Simbabwe     Zimbabwe            Zimbabue
2    ÿ≤ÿßŸÖÿ®Ÿäÿß       ‡¶ú‡¶æ‡¶Æ‡ßç‡¶¨‡¶ø‡¶Ø‡¶º‡¶æ       Sambia       Zambia              Zambia
3     ÿßŸÑŸäŸÖŸÜ        ‡¶á‡¶Ø‡¶º‡ßá‡¶Æ‡ßá‡¶®        Jemen        Yemen               Yemen
4    ŸÅŸäÿ™ŸÜÿßŸÖ      ‡¶≠‡¶ø‡¶Ø‡¶º‡ßá‡¶§‡¶®‡¶æ‡¶Æ      Vietnam      Vietnam             Vietnam
5   ŸÅŸÜÿ≤ŸàŸäŸÑÿß     ‡¶≠‡ßá‡¶®‡ßá‡¶ú‡ßÅ‡¶Ø‡¶º‡ßá‡¶≤‡¶æ    Venezuela    Venezuela           Venezuela
6 ÿßŸÑŸÅÿßÿ™ŸäŸÉÿßŸÜ ‡¶≠‡ßç‡¶Ø‡¶æ‡¶ü‡¶ø‡¶ï‡¶æ‡¶® ‡¶∏‡¶ø‡¶ü‡¶ø Vatikanstadt Vatican City Ciudad del Vaticano
   name_fa         name_fr    name_el       name_he   name_hi   name_hu
1 ÿ≤€åŸÖÿ®ÿßÿ®ŸàŸá        Zimbabwe ŒñŒπŒºœÄŒ¨ŒºœÄŒøœÖŒµ      ◊ñ◊ô◊û◊ë◊ë◊ï◊ê◊î   ‡§ú‡§º‡§ø‡§Æ‡•ç‡§¨‡§æ‡§¨‡•ç‡§µ‡•á  Zimbabwe
2   ÿ≤ÿßŸÖÿ®€åÿß          Zambie     ŒñŒ¨ŒºœÄŒπŒ±         ◊ñ◊û◊ë◊ô◊î   ‡§ú‡§º‡§æ‡§Æ‡•ç‡§¨‡§ø‡§Ø‡§æ    Zambia
3      €åŸÖŸÜ           Y√©men     Œ•ŒµŒºŒ≠ŒΩŒ∑          ◊™◊ô◊û◊ü       ‡§Ø‡§Æ‡§®     Jemen
4   Ÿà€åÿ™ŸÜÿßŸÖ        Vi√™t Nam    ŒíŒπŒµœÑŒΩŒ¨Œº       ◊ï◊ô◊ô◊ò◊†◊ê◊ù   ‡§µ‡§ø‡§Ø‡§§‡§®‡§æ‡§Æ   Vietn√°m
5  ŸàŸÜÿ≤Ÿàÿ¶ŸÑÿß       Venezuela ŒíŒµŒΩŒµŒ∂ŒøœÖŒ≠ŒªŒ±       ◊ï◊†◊¶◊ï◊ê◊ú◊î    ‡§µ‡•á‡§®‡•á‡§ú‡§º‡•Å‡§è‡§≤‡§æ Venezuela
6  Ÿàÿßÿ™€å⁄©ÿßŸÜ Cit√© du Vatican   ŒíŒ±œÑŒπŒ∫Œ±ŒΩœå ◊ß◊®◊ô◊ô◊™ ◊î◊ï◊ï◊™◊ô◊ß◊ü ‡§µ‡•à‡§ü‡§ø‡§ï‡§® ‡§®‡§ó‡§∞   Vatik√°n
    name_id            name_it    name_ja     name_ko      name_nl   name_pl
1  Zimbabwe           Zimbabwe „Ç∏„É≥„Éê„Éñ„Ç®    ÏßêÎ∞îÎ∏åÏõ®     Zimbabwe  Zimbabwe
2    Zambia             Zambia   „Ç∂„É≥„Éì„Ç¢      Ïû†ÎπÑÏïÑ       Zambia    Zambia
3     Yaman              Yemen   „Ç§„Ç®„É°„É≥        ÏòàÎ©ò        Jemen     Jemen
4   Vietnam            Vietnam   „Éô„Éà„Éä„É†      Î≤†Ìä∏ÎÇ®      Vietnam   Wietnam
5 Venezuela          Venezuela „Éô„Éç„Ç∫„Ç®„É©  Î≤†ÎÑ§ÏàòÏóòÎùº    Venezuela Wenezuela
6   Vatikan Citt√† del Vaticano   „Éê„ÉÅ„Ç´„É≥ Î∞îÌã∞Ïπ∏ ÏãúÍµ≠ Vaticaanstad   Watykan
    name_pt   name_ru       name_sv   name_tr   name_uk    name_ur
1  Zimb√°bue  –ó–∏–º–±–∞–±–≤–µ      Zimbabwe  Zimbabve  –ó—ñ–º–±–∞–±–≤–µ    ÿ≤ŸÖÿ®ÿßÿ®Ÿà€í
2    Z√¢mbia    –ó–∞–º–±–∏—è        Zambia   Zambiya    –ó–∞–º–±—ñ—è     ÿ≤€åŸÖÿ®€åÿß
3     I√©men     –ô–µ–º–µ–Ω         Jemen     Yemen      –Ñ–º–µ–Ω        €åŸÖŸÜ
4  Vietname   –í—å–µ—Ç–Ω–∞–º       Vietnam   Vietnam   –í'—î—Ç–Ω–∞–º     Ÿà€åÿ™ŸÜÿßŸÖ
5 Venezuela –í–µ–Ω–µ—Å—É—ç–ª–∞     Venezuela Venezuela –í–µ–Ω–µ—Å—É–µ–ª–∞  Ÿà€åŸÜ€åÿ≤Ÿà€åŸÑÿß
6  Vaticano   –í–∞—Ç–∏–∫–∞–Ω Vatikanstaten   Vatikan   –í–∞—Ç–∏–∫–∞–Ω Ÿà€åŸπ€å⁄©ŸÜ ÿ≥Ÿπ€å
        name_vi  name_zh name_zht      fclass_iso tlc_diff      fclass_tlc
1      Zimbabwe Ê¥•Â∑¥Â∏ÉÈü¶   ËæõÂ∑¥Â®Å Admin-0 country     <NA> Admin-0 country
2        Zambia   ËµûÊØî‰∫ö   Â∞öÊØî‰∫û Admin-0 country     <NA> Admin-0 country
3         Yemen     ‰πüÈó®     ËëâÈñÄ Admin-0 country     <NA> Admin-0 country
4      Vi·ªát Nam     Ë∂äÂçó     Ë∂äÂçó Admin-0 country     <NA> Admin-0 country
5     Venezuela ÂßîÂÜÖÁëûÊãâ ÂßîÂÖßÁëûÊãâ Admin-0 country     <NA> Admin-0 country
6 Th√†nh Vatican   Ê¢µËíÇÂÜà   Ê¢µËíÇÂ≤° Admin-0 country     <NA> Admin-0 country
  fclass_us fclass_fr fclass_ru fclass_es fclass_cn fclass_tw fclass_in
1      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>
2      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>
3      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>
4      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>
5      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>
6      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>
  fclass_np fclass_pk fclass_de fclass_gb fclass_br fclass_il fclass_ps
1      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>
2      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>
3      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>
4      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>
5      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>
6      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>
  fclass_sa fclass_eg fclass_ma fclass_pt fclass_ar fclass_jp fclass_ko
1      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>
2      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>
3      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>
4      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>
5      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>
6      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>
  fclass_vn fclass_tr fclass_id fclass_pl fclass_gr fclass_it fclass_nl
1      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>
2      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>
3      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>
4      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>
5      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>
6      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>
  fclass_se fclass_bd fclass_ua                       geometry
1      <NA>      <NA>      <NA> MULTIPOLYGON (((31.28789 -2...
2      <NA>      <NA>      <NA> MULTIPOLYGON (((30.39609 -1...
3      <NA>      <NA>      <NA> MULTIPOLYGON (((53.08564 16...
4      <NA>      <NA>      <NA> MULTIPOLYGON (((104.064 10....
5      <NA>      <NA>      <NA> MULTIPOLYGON (((-60.82119 9...
6      <NA>      <NA>      <NA> MULTIPOLYGON (((12.43916 41...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Check CRS}
\FunctionTok{st\_crs}\NormalTok{(world)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Coordinate Reference System:
  User input: WGS 84 
  wkt:
GEOGCRS["WGS 84",
    DATUM["World Geodetic System 1984",
        ELLIPSOID["WGS 84",6378137,298.257223563,
            LENGTHUNIT["metre",1]]],
    PRIMEM["Greenwich",0,
        ANGLEUNIT["degree",0.0174532925199433]],
    CS[ellipsoidal,2],
        AXIS["latitude",north,
            ORDER[1],
            ANGLEUNIT["degree",0.0174532925199433]],
        AXIS["longitude",east,
            ORDER[2],
            ANGLEUNIT["degree",0.0174532925199433]],
    ID["EPSG",4326]]
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\textgreater{} CRS: EPSG:4326 (WGS84) ‚Üí unprojected lat/lon in degrees}

\CommentTok{\# Project to UTM}
\NormalTok{world\_utm }\OtherTok{\textless{}{-}} \FunctionTok{st\_transform}\NormalTok{(world, }\AttributeTok{crs =} \DecValTok{32633}\NormalTok{)}
\CommentTok{\#\textgreater{} CRS: EPSG:32633 ‚Üí projected in meters}
\end{Highlighting}
\end{Shaded}

\subsection{R Example 2}\label{r-example-2}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#devtools::install\_github("thiyangt/ceylon")}
\FunctionTok{library}\NormalTok{(ceylon)}
\FunctionTok{data}\NormalTok{(sf\_sl\_0)}
\FunctionTok{class}\NormalTok{(sf\_sl\_0)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "sf"         "tbl_df"     "tbl"        "data.frame"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sf\_sl\_0}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Simple feature collection with 1 feature and 1 field
Geometry type: MULTIPOLYGON
Dimension:     XY
Bounding box:  xmin: 362203.3 ymin: 380301.9 xmax: 621918.1 ymax: 813560.9
Projected CRS: SLD99 / Sri Lanka Grid 1999
# A tibble: 1 x 2
                                                                geometry COUNTRY
                                                      <MULTIPOLYGON [m]> <chr>  
1 (((481925.5 381353.7, 481922.9 381350.3, 481919 381348.2, 481914.6 38~ SRI LA~
\end{verbatim}

or

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{st\_crs}\NormalTok{(sf\_sl\_0)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Coordinate Reference System:
  User input: EPSG:5235 
  wkt:
PROJCRS["SLD99 / Sri Lanka Grid 1999",
    BASEGEOGCRS["SLD99",
        DATUM["Sri Lanka Datum 1999",
            ELLIPSOID["Everest 1830 (1937 Adjustment)",6377276.345,300.8017,
                LENGTHUNIT["metre",1]]],
        PRIMEM["Greenwich",0,
            ANGLEUNIT["degree",0.0174532925199433]],
        ID["EPSG",5233]],
    CONVERSION["Sri Lanka Grid 1999",
        METHOD["Transverse Mercator",
            ID["EPSG",9807]],
        PARAMETER["Latitude of natural origin",7.00047152777778,
            ANGLEUNIT["degree",0.0174532925199433],
            ID["EPSG",8801]],
        PARAMETER["Longitude of natural origin",80.7717130833333,
            ANGLEUNIT["degree",0.0174532925199433],
            ID["EPSG",8802]],
        PARAMETER["Scale factor at natural origin",0.9999238418,
            SCALEUNIT["unity",1],
            ID["EPSG",8805]],
        PARAMETER["False easting",500000,
            LENGTHUNIT["metre",1],
            ID["EPSG",8806]],
        PARAMETER["False northing",500000,
            LENGTHUNIT["metre",1],
            ID["EPSG",8807]]],
    CS[Cartesian,2],
        AXIS["(E)",east,
            ORDER[1],
            LENGTHUNIT["metre",1]],
        AXIS["(N)",north,
            ORDER[2],
            LENGTHUNIT["metre",1]],
    USAGE[
        SCOPE["unknown"],
        AREA["Sri Lanka - onshore"],
        BBOX[5.86,79.64,9.88,81.95]],
    ID["EPSG",5235]]
\end{verbatim}

Visualizing using shapefiles: map of Sri Lanka

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(sf\_sl\_0) }\SpecialCharTok{+}
  \FunctionTok{geom\_sf}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{06-chap6_files/figure-pdf/unnamed-chunk-12-1.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(sf\_sl\_0) }\SpecialCharTok{+}
  \FunctionTok{geom\_sf}\NormalTok{(}\AttributeTok{fill=}\StringTok{\textquotesingle{}beige\textquotesingle{}}\NormalTok{) }\SpecialCharTok{+}
\FunctionTok{theme\_minimal}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{06-chap6_files/figure-pdf/unnamed-chunk-13-1.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(knitr)}
\NormalTok{sf\_sl\_0 }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{kable}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
geometry & COUNTRY \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
MULTIPOLYGON (((481925.5 38\ldots{} & SRI LANKA \\
\end{longtable}

\section{Exercise}\label{exercise-2}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Draw district and province maps
\end{enumerate}

data:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{province}
\NormalTok{district}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Guess the output.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_sf}\NormalTok{(}\AttributeTok{data=}\NormalTok{province, }\AttributeTok{lwd=}\DecValTok{2}\NormalTok{, }\AttributeTok{col=}\StringTok{"black"}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{geom\_sf}\NormalTok{(}\AttributeTok{data=}\NormalTok{district, }\AttributeTok{linetype=}\DecValTok{21}\NormalTok{, }\AttributeTok{col=}\StringTok{"red"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Colour provinces according to the population.
\end{enumerate}

\section{Annotations}\label{annotations}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(sf\_sl\_0) }\SpecialCharTok{+}
  \FunctionTok{geom\_sf}\NormalTok{(}\AttributeTok{fill=}\StringTok{\textquotesingle{}beige\textquotesingle{}}\NormalTok{) }\SpecialCharTok{+}
\NormalTok{ggspatial}\SpecialCharTok{::}\FunctionTok{annotation\_north\_arrow}\NormalTok{(}\AttributeTok{location =} \StringTok{"br"}\NormalTok{)}\SpecialCharTok{+}
\NormalTok{  ggspatial}\SpecialCharTok{::}\FunctionTok{annotation\_scale}\NormalTok{(}\AttributeTok{location =} \StringTok{"bl"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{06-chap6_files/figure-pdf/unnamed-chunk-16-1.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(sf\_sl\_0) }\SpecialCharTok{+}
  \FunctionTok{geom\_sf}\NormalTok{(}\AttributeTok{fill=}\StringTok{\textquotesingle{}beige\textquotesingle{}}\NormalTok{) }\SpecialCharTok{+}
\NormalTok{ggspatial}\SpecialCharTok{::}\FunctionTok{annotation\_north\_arrow}\NormalTok{(}\AttributeTok{location =} \StringTok{"br"}\NormalTok{)}\SpecialCharTok{+}
\NormalTok{  ggspatial}\SpecialCharTok{::}\FunctionTok{annotation\_scale}\NormalTok{(}\AttributeTok{location =} \StringTok{"bl"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{06-chap6_files/figure-pdf/unnamed-chunk-17-1.pdf}}

\section{Spatial Data Wrangling}\label{spatial-data-wrangling}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Convert regular data frame to sf
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Example data frame: cities with lat/lon}
\NormalTok{cities }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{name =} \FunctionTok{c}\NormalTok{(}\StringTok{"New York"}\NormalTok{, }\StringTok{"London"}\NormalTok{, }\StringTok{"Tokyo"}\NormalTok{),}
  \AttributeTok{lon =} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{74.0060}\NormalTok{, }\SpecialCharTok{{-}}\FloatTok{0.1276}\NormalTok{, }\FloatTok{139.6917}\NormalTok{),}
  \AttributeTok{lat =} \FunctionTok{c}\NormalTok{(}\FloatTok{40.7128}\NormalTok{, }\FloatTok{51.5074}\NormalTok{, }\FloatTok{35.6895}\NormalTok{)}
\NormalTok{)}

\CommentTok{\# Convert to sf object}
\NormalTok{cities\_sf }\OtherTok{\textless{}{-}} \FunctionTok{st\_as\_sf}\NormalTok{(cities, }\AttributeTok{coords =} \FunctionTok{c}\NormalTok{(}\StringTok{"lon"}\NormalTok{, }\StringTok{"lat"}\NormalTok{), }\AttributeTok{crs =} \DecValTok{4326}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{st\_crs}\NormalTok{(cities\_sf)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Coordinate Reference System:
  User input: EPSG:4326 
  wkt:
GEOGCRS["WGS 84",
    ENSEMBLE["World Geodetic System 1984 ensemble",
        MEMBER["World Geodetic System 1984 (Transit)"],
        MEMBER["World Geodetic System 1984 (G730)"],
        MEMBER["World Geodetic System 1984 (G873)"],
        MEMBER["World Geodetic System 1984 (G1150)"],
        MEMBER["World Geodetic System 1984 (G1674)"],
        MEMBER["World Geodetic System 1984 (G1762)"],
        MEMBER["World Geodetic System 1984 (G2139)"],
        MEMBER["World Geodetic System 1984 (G2296)"],
        ELLIPSOID["WGS 84",6378137,298.257223563,
            LENGTHUNIT["metre",1]],
        ENSEMBLEACCURACY[2.0]],
    PRIMEM["Greenwich",0,
        ANGLEUNIT["degree",0.0174532925199433]],
    CS[ellipsoidal,2],
        AXIS["geodetic latitude (Lat)",north,
            ORDER[1],
            ANGLEUNIT["degree",0.0174532925199433]],
        AXIS["geodetic longitude (Lon)",east,
            ORDER[2],
            ANGLEUNIT["degree",0.0174532925199433]],
    USAGE[
        SCOPE["Horizontal component of 3D system."],
        AREA["World."],
        BBOX[-90,-180,90,180]],
    ID["EPSG",4326]]
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\textgreater{} EPSG:4326 (WGS84)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Transforming coordinates
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Transform to UTM (meters)}
\NormalTok{cities\_utm }\OtherTok{\textless{}{-}} \FunctionTok{st\_transform}\NormalTok{(cities\_sf, }\AttributeTok{crs =} \DecValTok{32618}\NormalTok{)  }\CommentTok{\# UTM zone 18N}

\FunctionTok{st\_crs}\NormalTok{(cities\_utm)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Coordinate Reference System:
  User input: EPSG:32618 
  wkt:
PROJCRS["WGS 84 / UTM zone 18N",
    BASEGEOGCRS["WGS 84",
        ENSEMBLE["World Geodetic System 1984 ensemble",
            MEMBER["World Geodetic System 1984 (Transit)"],
            MEMBER["World Geodetic System 1984 (G730)"],
            MEMBER["World Geodetic System 1984 (G873)"],
            MEMBER["World Geodetic System 1984 (G1150)"],
            MEMBER["World Geodetic System 1984 (G1674)"],
            MEMBER["World Geodetic System 1984 (G1762)"],
            MEMBER["World Geodetic System 1984 (G2139)"],
            MEMBER["World Geodetic System 1984 (G2296)"],
            ELLIPSOID["WGS 84",6378137,298.257223563,
                LENGTHUNIT["metre",1]],
            ENSEMBLEACCURACY[2.0]],
        PRIMEM["Greenwich",0,
            ANGLEUNIT["degree",0.0174532925199433]],
        ID["EPSG",4326]],
    CONVERSION["UTM zone 18N",
        METHOD["Transverse Mercator",
            ID["EPSG",9807]],
        PARAMETER["Latitude of natural origin",0,
            ANGLEUNIT["degree",0.0174532925199433],
            ID["EPSG",8801]],
        PARAMETER["Longitude of natural origin",-75,
            ANGLEUNIT["degree",0.0174532925199433],
            ID["EPSG",8802]],
        PARAMETER["Scale factor at natural origin",0.9996,
            SCALEUNIT["unity",1],
            ID["EPSG",8805]],
        PARAMETER["False easting",500000,
            LENGTHUNIT["metre",1],
            ID["EPSG",8806]],
        PARAMETER["False northing",0,
            LENGTHUNIT["metre",1],
            ID["EPSG",8807]]],
    CS[Cartesian,2],
        AXIS["(E)",east,
            ORDER[1],
            LENGTHUNIT["metre",1]],
        AXIS["(N)",north,
            ORDER[2],
            LENGTHUNIT["metre",1]],
    USAGE[
        SCOPE["Navigation and medium accuracy spatial referencing."],
        AREA["Between 78¬∞W and 72¬∞W, northern hemisphere between equator and 84¬∞N, onshore and offshore. Bahamas. Canada - Nunavut; Ontario; Quebec. Colombia. Cuba. Ecuador. Greenland. Haiti. Jamaica. Panama. Turks and Caicos Islands. United States (USA). Venezuela."],
        BBOX[0,-78,84,-72]],
    ID["EPSG",32618]]
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\textgreater{} EPSG:32618 ‚Üí coordinates in meters}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Original coordinates (degrees)}
\NormalTok{cities\_sf}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Simple feature collection with 3 features and 1 field
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: -74.006 ymin: 35.6895 xmax: 139.6917 ymax: 51.5074
Geodetic CRS:  WGS 84
      name                 geometry
1 New York  POINT (-74.006 40.7128)
2   London  POINT (-0.1276 51.5074)
3    Tokyo POINT (139.6917 35.6895)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Transformed coordinates (meters)}
\NormalTok{cities\_utm}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Simple feature collection with 3 features and 1 field
Geometry type: POINT
Dimension:     XY
Bounding box:  xmin: -2693059 ymin: 4507351 xmax: 4935636 ymax: 15438700
Projected CRS: WGS 84 / UTM zone 18N
      name                  geometry
1 New York  POINT (583959.4 4507351)
2   London   POINT (4935636 8691571)
3    Tokyo POINT (-2693059 15438701)
\end{verbatim}

\section{Two types of maps}\label{two-types-of-maps}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Simple feature map
\item
  Polygon maps
\end{enumerate}

\section{Simple feature map}\label{simple-feature-map}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(sf\_sl\_0) }\SpecialCharTok{+}
  \FunctionTok{geom\_sf}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{coord\_sf}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{06-chap6_files/figure-pdf/unnamed-chunk-22-1.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(sf\_sl\_0) }\SpecialCharTok{+}
  \FunctionTok{geom\_sf}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{coord\_sf}\NormalTok{(}\AttributeTok{crs =} \FunctionTok{st\_crs}\NormalTok{(}\DecValTok{3577}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{06-chap6_files/figure-pdf/unnamed-chunk-23-1.pdf}}

\section{Polygon map}\label{polygon-map}

Example 1

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(ggplot2)}
\FunctionTok{library}\NormalTok{(sf)}

\CommentTok{\# Create a simple polygon (square) as sf object}
\NormalTok{coords }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{c}\NormalTok{(}
  \DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{,}
  \DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{,}
  \DecValTok{0}\NormalTok{, }\DecValTok{0}  \CommentTok{\# close the polygon}
\NormalTok{), }\AttributeTok{ncol =} \DecValTok{2}\NormalTok{, }\AttributeTok{byrow =} \ConstantTok{TRUE}\NormalTok{)}

\NormalTok{polygon\_sf }\OtherTok{\textless{}{-}} \FunctionTok{st\_sf}\NormalTok{(}
  \AttributeTok{geometry =} \FunctionTok{st\_sfc}\NormalTok{(}\FunctionTok{st\_polygon}\NormalTok{(}\FunctionTok{list}\NormalTok{(coords)))}
\NormalTok{)}
\NormalTok{polygon\_sf}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Simple feature collection with 1 feature and 0 fields
Geometry type: POLYGON
Dimension:     XY
Bounding box:  xmin: 0 ymin: 0 xmax: 1 ymax: 1
CRS:           NA
                        geometry
1 POLYGON ((0 0, 0 1, 1 1, 1 ...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Extract coordinates for geom\_point}
\NormalTok{polygon\_points }\OtherTok{\textless{}{-}} \FunctionTok{st\_coordinates}\NormalTok{(polygon\_sf)}
\NormalTok{polygon\_points}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     X Y L1 L2
[1,] 0 0  1  1
[2,] 0 1  1  1
[3,] 1 1  1  1
[4,] 1 0  1  1
[5,] 0 0  1  1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Convert to data frame}
\NormalTok{polygon\_df }\OtherTok{\textless{}{-}} \FunctionTok{as.data.frame}\NormalTok{(polygon\_points)}
\FunctionTok{head}\NormalTok{(polygon\_df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  X Y L1 L2
1 0 0  1  1
2 0 1  1  1
3 1 1  1  1
4 1 0  1  1
5 0 0  1  1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Plot using geom\_point}
\FunctionTok{ggplot}\NormalTok{(polygon\_df, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ X, }\AttributeTok{y =}\NormalTok{ Y)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{color =} \StringTok{"blue"}\NormalTok{, }\AttributeTok{size =} \DecValTok{3}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{coord\_fixed}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"Polygon represented by points"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{06-chap6_files/figure-pdf/unnamed-chunk-24-1.pdf}}

Example 2

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{devtools}\SpecialCharTok{::}\FunctionTok{install\_github}\NormalTok{(}\StringTok{"UrbanInstitute/urbnmapr"}\NormalTok{)}
\FunctionTok{library}\NormalTok{(urbnmapr)}
\NormalTok{statepop1 }\OtherTok{\textless{}{-}}\NormalTok{ statepop }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{rename}\NormalTok{(}\AttributeTok{state\_name =}\NormalTok{ full)}
\FunctionTok{head}\NormalTok{(statepop1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 6 x 4
  fips  abbr  state_name pop_2022
  <chr> <chr> <chr>         <dbl>
1 01    AL    Alabama     5074296
2 02    AK    Alaska       733583
3 04    AZ    Arizona     7359197
4 05    AR    Arkansas    3045637
5 06    CA    California 39029342
6 08    CO    Colorado    5839926
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{statepop2 }\OtherTok{\textless{}{-}} \FunctionTok{full\_join}\NormalTok{(statepop1, states, }\AttributeTok{by =} \StringTok{"state\_name"}\NormalTok{)}
\FunctionTok{head}\NormalTok{(statepop2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 6 x 12
  fips  abbr  state_name pop_2022  long   lat order hole  piece group state_fips
  <chr> <chr> <chr>         <dbl> <dbl> <dbl> <int> <lgl> <fct> <fct> <chr>     
1 01    AL    Alabama     5074296 -88.5  31.9     1 FALSE 1     01.1  01        
2 01    AL    Alabama     5074296 -88.5  31.9     2 FALSE 1     01.1  01        
3 01    AL    Alabama     5074296 -88.5  31.9     3 FALSE 1     01.1  01        
4 01    AL    Alabama     5074296 -88.5  32.0     4 FALSE 1     01.1  01        
5 01    AL    Alabama     5074296 -88.5  32.0     5 FALSE 1     01.1  01        
6 01    AL    Alabama     5074296 -88.5  32.1     6 FALSE 1     01.1  01        
# i 1 more variable: state_abbv <chr>
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+} 
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{data =}\NormalTok{ statepop2, }\AttributeTok{mapping =} \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ long, }\AttributeTok{y =}\NormalTok{ lat, }\AttributeTok{group =}\NormalTok{ group), }\AttributeTok{fill =} \StringTok{"grey"}\NormalTok{, }\AttributeTok{color =} \StringTok{"black"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{06-chap6_files/figure-pdf/unnamed-chunk-27-1.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+} 
  \FunctionTok{geom\_polygon}\NormalTok{(}\AttributeTok{data =}\NormalTok{ statepop2, }\AttributeTok{mapping =} \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ long, }\AttributeTok{y =}\NormalTok{ lat, }\AttributeTok{group =}\NormalTok{ group),}\AttributeTok{fill =} \StringTok{"grey"}\NormalTok{, }\AttributeTok{color =} \StringTok{"black"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{06-chap6_files/figure-pdf/unnamed-chunk-28-1.pdf}}

Example 3

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mi\_counties }\OtherTok{\textless{}{-}} \FunctionTok{map\_data}\NormalTok{(}\StringTok{"county"}\NormalTok{, }\StringTok{"michigan"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{select}\NormalTok{(}\AttributeTok{lon =}\NormalTok{ long, lat, group, }\AttributeTok{id =}\NormalTok{ subregion)}
\FunctionTok{head}\NormalTok{(mi\_counties)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
        lon      lat group     id
1 -83.88675 44.85686     1 alcona
2 -83.36536 44.86832     1 alcona
3 -83.36536 44.86832     1 alcona
4 -83.33098 44.83968     1 alcona
5 -83.30806 44.80530     1 alcona
6 -83.30233 44.77665     1 alcona
\end{verbatim}

Plot: in class

Example 4: Does as.data.frame(sf\_object) work?

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(ceylon)}
\FunctionTok{data}\NormalTok{(sf\_sl\_0)}
\NormalTok{sf\_sl\_0}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Simple feature collection with 1 feature and 1 field
Geometry type: MULTIPOLYGON
Dimension:     XY
Bounding box:  xmin: 362203.3 ymin: 380301.9 xmax: 621918.1 ymax: 813560.9
Projected CRS: SLD99 / Sri Lanka Grid 1999
# A tibble: 1 x 2
                                                                geometry COUNTRY
                                                      <MULTIPOLYGON [m]> <chr>  
1 (((481925.5 381353.7, 481922.9 381350.3, 481919 381348.2, 481914.6 38~ SRI LA~
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Convert to data frame}
\NormalTok{polygon\_df\_sl }\OtherTok{\textless{}{-}} \FunctionTok{as.data.frame}\NormalTok{(sf\_sl\_0)}
\NormalTok{polygon\_df\_sl}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
                        geometry   COUNTRY
1 MULTIPOLYGON (((481925.5 38... SRI LANKA
\end{verbatim}

\section{rnaturalearth}\label{rnaturalearth}

rnaturalearth is an R package that provides ready-to-use maps of the
world, countries, and regions as sf (spatial) or data frames. It's a
super convenient way to get geographic data without downloading
shapefiles manually.

Example 1

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(ggplot2)}
\FunctionTok{library}\NormalTok{(dplyr)}
\FunctionTok{library}\NormalTok{(rnaturalearth)}
\FunctionTok{library}\NormalTok{(rnaturalearthdata)}
\CommentTok{\# Get Sri Lanka admin{-}1 regions (provinces)}
\NormalTok{sri\_lanka }\OtherTok{\textless{}{-}} \FunctionTok{ne\_states}\NormalTok{(}\AttributeTok{country =} \StringTok{"Sri Lanka"}\NormalTok{, }\AttributeTok{returnclass =} \StringTok{"sf"}\NormalTok{)}

\CommentTok{\# Check the first few rows}
\FunctionTok{head}\NormalTok{(sri\_lanka)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Simple feature collection with 6 features and 121 fields
Geometry type: MULTIPOLYGON
Dimension:     XY
Bounding box:  xmin: 79.65577 ymin: 7.272089 xmax: 81.41668 ymax: 9.829576
Geodetic CRS:  WGS 84
                         featurecla scalerank adm1_code diss_me iso_3166_2
1860 Admin-1 states provinces lakes         9  LKA-2454    2454      LK-53
1861 Admin-1 states provinces lakes         9  LKA-2458    2458      LK-45
1862 Admin-1 states provinces lakes         9  LKA-2459    2459      LK-41
1863 Admin-1 states provinces lakes         9  LKA-2460    2460      LK-42
1864 Admin-1 states provinces lakes         9  LKA-2457    2457      LK-43
1865 Admin-1 states provinces lakes         9  LKA-2462    2462      LK-62
     wikipedia iso_a2 adm0_sr          name            name_alt name_local
1860      <NA>     LK       1 Triku·πáƒÅmalaya         Trincomalee       <NA>
1861      <NA>     LK       1       Mulativ Mulativu|Mullaitivu       <NA>
1862      <NA>     LK       3      YƒÅpanaya              Jaffna       <NA>
1863      <NA>     LK       1   Kilin≈èchchi         Kilinochchi       <NA>
1864      <NA>     LK       3     MannƒÅrama              Mannar       <NA>
1865      <NA>     LK       1     Puttalama            Puttalam       <NA>
            type  type_en code_local code_hasc
1860 Distrikkaya District       <NA>     LK.TC
1861 Distrikkaya District       <NA>     LK.MP
1862 Distrikkaya District       <NA>     LK.JA
1863 Distrikkaya District       <NA>     LK.KL
1864 Distrikkaya District       <NA>     LK.MB
1865 Distrikkaya District       <NA>     LK.PX
                                  note hasc_maybe            region region_cod
1860                              <NA>       <NA> N√¶ÃÜgƒïnahira pa·∏∑ƒÅta       LK-5
1861                              <NA>       <NA>      Uturu pa·∏∑ƒÅta       LK-4
1862 Split into Jaffna and Kilinochchi       <NA>      Uturu pa·∏∑ƒÅta       LK-4
1863                              <NA>       <NA>      Uturu pa·∏∑ƒÅta       LK-4
1864                              <NA>       <NA>      Uturu pa·∏∑ƒÅta       LK-4
1865                              <NA>       <NA>    Vayamba pa·∏∑ƒÅta       LK-6
     provnum_ne gadm_level check_me datarank abbrev postal area_sqkm sameascity
1860      20013          1       10        6   <NA>     TC         0          7
1861      20005          1       10        6   <NA>     MP         0        -99
1862      20002          1       10        6   <NA>     JA         0        -99
1863      20001          1        0        6   <NA>     KL         0        -99
1864      20004          1       10        6   <NA>     MB         0        -99
1865      20006          1       10        6   <NA>     PX         0        -99
     labelrank name_len mapcolor9 mapcolor13 fips fips_alt   woe_id woe_label
1860         7       13         4          9 CE21     <NA> 23706507      <NA>
1861         9        7         4          9 CE27     <NA> 23706505      <NA>
1862         9        8         4          9 CE25     <NA> 23706489      <NA>
1863         9       11         4          9 <NA>     <NA> 23706490      <NA>
1864         9        9         4          9 CE26     <NA> 23706506      <NA>
1865         9        9         4          9 CE19     <NA> 23706502      <NA>
        woe_name latitude longitude sov_a3 adm0_a3 adm0_label     admin
1860 Trincomalee  8.56202   81.0848    LKA     LKA          2 Sri Lanka
1861  Mullaitivu  9.24043   80.5667    LKA     LKA          2 Sri Lanka
1862      Jaffna  9.50669   79.6933    LKA     LKA          2 Sri Lanka
1863 Kilinochchi  9.38429   80.3341    LKA     LKA          2 Sri Lanka
1864      Mannar  8.84371   80.0854    LKA     LKA          2 Sri Lanka
1865    Puttalam  7.94944   79.9111    LKA     LKA          2 Sri Lanka
      geonunit gu_a3   gn_id              gn_name   gns_id             gns_name
1860 Sri Lanka   LKA 1226258 Trincomalee District -2237626 Trincomalee District
1861 Sri Lanka   LKA 1234392 Mullaittivu District -2229490 Mullaittivu District
1862 Sri Lanka   LKA 1242831      Jaffna District -2221042      Jaffna District
1863 Sri Lanka   LKA 1240371 Kilinochchi District -2223504 Kilinochchi District
1864 Sri Lanka   LKA 1236148      Mannar District -2227730      Mannar District
1865 Sri Lanka   LKA 1229292    Puttalam District -2234591             Puttalam
     gn_level gn_region gn_a1_code region_sub sub_code gns_level gns_lang
1860        2      <NA> LK.1226258       <NA>     <NA>         2     <NA>
1861        2      <NA> LK.1234392       <NA>     <NA>         2     <NA>
1862        2      <NA> LK.1242831       <NA>     <NA>         2     <NA>
1863        2      <NA> LK.1240371       <NA>     <NA>         2     <NA>
1864        2      <NA> LK.1236148       <NA>     <NA>         2     <NA>
1865        2      <NA> LK.1229292       <NA>     <NA>         2     <NA>
     gns_adm1 gns_region min_label max_label min_zoom wikidataid
1860     <NA>       CE37       8.7        11      8.7   Q1493318
1861     <NA>       CE38       8.7        11      8.7   Q1587508
1862     <NA>       CE38       8.7        11      8.7   Q1520182
1863     <NA>       CE38       8.7        11      8.7   Q1584007
1864     <NA>       CE38       8.7        11      8.7    Q178003
1865     <NA>       CE32       8.7        11      8.7   Q1665318
               name_ar        name_bn     name_de     name_en     name_es
1860 ŸÖÿØŸäÿ±Ÿäÿ© ÿ™ÿ±ŸäŸÜŸÉŸàŸÖÿßŸÑŸä       ‡¶§‡ßç‡¶∞‡¶ø‡¶ï‡ßÅ‡¶Æ‡¶æ‡¶≤‡¶Ø‡¶º Trincomalee Trincomalee Trincomalee
1861  ŸÖÿØŸäÿ±Ÿäÿ© ŸÖŸàŸÑÿßŸäÿ™ŸäŸÅŸà ‡¶Æ‡ßã‡¶≤‡¶æ‡¶á‡¶§‡¶ø‡¶¨‡ßã ‡¶ú‡ßá‡¶≤‡¶æ  Mullaitivu  Mullaitivu  Mullaitivu
1862      ŸÖÿØŸäÿ±Ÿäÿ© ÿ¨ÿßŸÅŸÜÿß       ‡¶á‡ßü‡¶æ‡¶™‡¶æ‡¶®‡¶æ‡¶Ø‡¶º      Jaffna      Jaffna      Jaffna
1863  ŸÖÿØŸäÿ±Ÿäÿ© ŸÉŸäŸÑŸäŸÜŸàÿ™ÿ¥Ÿä ‡¶ï‡ßç‡¶≤‡¶ø‡¶®‡ßã‡¶ï‡¶æ‡¶ö‡¶ø ‡¶ú‡ßá‡¶≤‡¶æ Kilinochchi Kilinochchi Kilinochchi
1864       ŸÖÿØŸäÿ±Ÿäÿ© ŸÖŸÜÿßÿ±     ‡¶Æ‡¶æ‡¶®‡¶æ‡¶∞ ‡¶ú‡ßá‡¶≤‡¶æ      Mannar      Mannar      Mannar
1865    ŸÖÿØŸäÿ±Ÿäÿ© ÿ®Ÿàÿ™ÿßŸÑÿßŸÖ   ‡¶™‡ßã‡¶§‡¶æ‡¶≤‡¶æ‡¶Æ ‡¶ú‡ßá‡¶≤‡¶æ    Puttalam    Puttalam    Puttalam
          name_fr        name_el         name_hi       name_hu       name_id
1860 Trinquemalay Œ§œÅŒπŒ∫ŒøœÖŒºŒ±ŒºŒ±ŒªŒ¨ŒπŒ± ‡§§‡•ç‡§∞‡§ø‡§Ç‡§ï‡•ã‡§®‡•ç‡§Æ‡§æ‡§≤‡•Ä ‡§ú‡§ø‡§≤‡§æ Triku·πáƒÅmalaya Triku·πáamalaya
1861   Mullaitivu   ŒúŒøœÖŒªŒ±œäœÑŒπŒ≤ŒøœçŒΩ      ‡§Æ‡•Å‡§≤‡•à‡§§‡§ø‡§µ‡•Å ‡§ú‡§ø‡§≤‡§æ    Mullaitivu    Mullaitivu
1862       Jaffna      ŒìŒπŒ±œÄŒ±ŒΩŒ¨ŒπŒ±       ‡§ú‡§´‡§º‡§®‡§æ ‡§ú‡§ø‡§≤‡§æ      YƒÅpanaya      Yapanaya
1863  Kilinochchi      ŒöŒπŒªŒπŒΩœåœÑœÉŒπ  ‡§ï‡§ø‡§≤‡§ø‡§®‡•ã‡§ö‡•ç‡§ö‡§ø ‡§ú‡§ø‡§≤‡§æ   Kilin≈èchchi   Kilinochchi
1864       Mannar          ŒúŒ±ŒΩŒ¨œÅ      ‡§Æ‡§®‡•ç‡§®‡§æ‡§∞ ‡§ú‡§ø‡§≤‡§æ     MannƒÅrama        Mannar
1865     Puttalam      Œ†ŒøœÖœÑœÑŒ±ŒªŒ¨Œº      ‡§™‡•Å‡§§‡•ç‡§§‡§≤‡§Æ ‡§ú‡§ø‡§≤‡§æ     Puttalama      Puttalam
         name_it                name_ja       name_ko     name_nl       name_pl
1860 Trincomalee       „Éà„É™„É≥„Ç≥„Éû„É™„ÉºÁúå Ìä∏ÎßÅÏΩîÎßêÎ¶¨ Íµ¨ Trincomalee Trikunamalaja
1861  Mullaitivu „É†„ÉÉ„É©„Ç§„ÉÉ„ÉÜ„Ç£„Éº„É¥„ÉºÁúå Î¨ºÎùºÏù¥Ìã∞Î∂Ä Íµ¨  Mullaitivu   Mullajttiwu
1862      Jaffna             „Ç∏„É£„Éï„ÉäÁúå     ÏûêÌîÑÎÇò Íµ¨      Jaffna        D≈ºafna
1863 Kilinochchi           „Ç≠„É™„Éé„ÉÉ„ÉÅÁúå ÌÇ¨Î¶¨ÎÖ∏ÏπòÏπò Íµ¨ Kilinochchi     Kilinoƒáƒái
1864      Mannar           „Éû„É≥„Éä„Éº„É´Áúå     ÎßåÎÇòÎ•¥ Íµ¨      Mannar        Mannar
1865    Puttalam           „Éó„ÉÉ„Çø„É©„É†Áúå     Ìë∏ÌÉàÎûå Íµ¨    Puttalam      Puttalam
         name_pt          name_ru     name_sv       name_tr          name_vi
1860 Trincomalee –¢—Ä–∏–Ω–∫–æ–º–∞–ª–∏ –æ–∫—Ä—É–≥ Trincomalee Triku·πáƒÅmalaya      Trincomalee
1861 Mullaittivu       –ú—É–ª–ª–∞–π—Ç–∏–≤—É  Mullaitivu    Mullaitivu  Qu·∫≠n Mullaitivu
1862      Jaffna     –æ–∫—Ä—É–≥ –î–∂–∞—Ñ–Ω–∞      Jaffna      YƒÅpanaya         YƒÅpanaya
1863 Kilinochchi        –ö–∏–ª–∏–Ω–æ—á—á–∏ Kilinochchi   Kilinochchi Qu·∫≠n Kilinochchi
1864      Mannar           –ú–∞–Ω–Ω–∞—Ä      Mannar        Mannar      Qu·∫≠n Mannar
1865    Puttalam         –ü—É—Ç—Ç–∞–ª–∞–º    Puttalam      Puttalam    Qu·∫≠n Puttalam
        name_zh      ne_id      name_he    name_uk        name_ur
1860 ‰∫≠ÂèØÈ¶¨ÈáåÂçÄ 1159311407 ◊ò◊®◊ô◊ß◊ï◊†◊î◊û◊ú◊ê◊ô◊î –¢—Ä—ñ–Ω–∫–æ–º–∞–ª—ñ ÿ™ÿ±€åŸÜ⁄©ŸàŸÖÿßŸÑ€å ÿ∂ŸÑÿπ
1861 Á©ÜËé±ËíÇÊ≠¶Âå∫ 1159311415        ◊û◊ï◊ú◊ò◊î –ú—É–ª–ª–∞–π—Ç—ñ–≤—É  ŸÖŸàŸÑÿß€åÿ™€åŸàŸà ÿ∂ŸÑÿπ
1862   Ë¥æÂ§´Á∫≥Âå∫ 1159311395     ◊ô◊ê◊§◊ê◊†◊ê◊ô◊î     –î–∂–∞—Ñ–Ω–∞       ÿ¨ŸÅŸÅŸÜÿßÿ∂ŸÑÿπ
1863 Âü∫Âà©ËØ∫Â•áÂå∫ 1159311417     ◊ß◊ô◊ú◊ô◊†◊¶'◊ô  –ö—ñ–ª—ñ–Ω–æ—á—á—ñ  ⁄©€åŸÑ€åŸÜŸà⁄Ü⁄Ü€å ÿ∂ŸÑÿπ
1864   È©¨Á∫≥Â∞îÂå∫ 1159311387     ◊î◊ê◊ô ◊û◊†◊°◊ú     –ú–∞–Ω–Ω–∞—Ä      ŸÖÿßŸÜÿßÿ± ÿ∂ŸÑÿπ
1865 ÊôÆÂ°îÂãíÂßÜÂå∫ 1159311421     ◊§◊ï◊ò◊ê◊ú◊ê◊û◊î   –ü—É—Ç—Ç–∞–ª–∞–º    ŸæŸàŸπÿßŸÑÿßŸÖ ÿ∂ŸÑÿπ
              name_fa   name_zht FCLASS_ISO FCLASS_US FCLASS_FR FCLASS_RU
1860 ŸÜÿßÿ≠€åŸá ÿ™ÿ±€åŸÜ⁄©ŸàŸÖÿßŸÑ€å ‰∫≠ÂèØÈ¶¨ÈáåÂçÄ       <NA>      <NA>      <NA>      <NA>
1861  ŸÜÿßÿ≠€åŸá ŸÖŸàŸÑÿß€åÿ™€åŸàŸà Á©ÜËêäËíÇÊ≠¶ÂçÄ       <NA>      <NA>      <NA>      <NA>
1862       ŸÜÿßÿ≠€åŸá ÿ¨ŸÅŸÜÿß   Ë≥àÂ§´Á¥çÂçÄ       <NA>      <NA>      <NA>      <NA>
1863   ŸÜÿßÿ≠€åŸá ⁄©€åŸÑ€åŸÜŸà⁄Ü€å Âü∫Âà©Ë´æÂ•áÂçÄ       <NA>      <NA>      <NA>      <NA>
1864       ŸÜÿßÿ≠€åŸá ŸÖŸÜÿßÿ±   È¶¨Á¥çÁàæÂçÄ       <NA>      <NA>      <NA>      <NA>
1865    ŸÜÿßÿ≠€åŸá ŸæŸàÿ™ÿßŸÑÿßŸÖ ÊôÆÂ°îÂãíÂßÜÂçÄ       <NA>      <NA>      <NA>      <NA>
     FCLASS_ES FCLASS_CN FCLASS_TW FCLASS_IN FCLASS_NP FCLASS_PK FCLASS_DE
1860      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>
1861      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>
1862      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>
1863      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>
1864      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>
1865      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>
     FCLASS_GB FCLASS_BR FCLASS_IL FCLASS_PS FCLASS_SA FCLASS_EG FCLASS_MA
1860      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>
1861      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>
1862      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>
1863      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>
1864      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>
1865      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>
     FCLASS_PT FCLASS_AR FCLASS_JP FCLASS_KO FCLASS_VN FCLASS_TR FCLASS_ID
1860      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>
1861      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>
1862      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>
1863      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>
1864      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>
1865      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>
     FCLASS_PL FCLASS_GR FCLASS_IT FCLASS_NL FCLASS_SE FCLASS_BD FCLASS_UA
1860      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>
1861      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>
1862      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>
1863      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>
1864      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>
1865      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>      <NA>
     FCLASS_TLC                       geometry
1860       <NA> MULTIPOLYGON (((80.92292 8....
1861       <NA> MULTIPOLYGON (((80.62598 9....
1862       <NA> MULTIPOLYGON (((80.44174 9....
1863       <NA> MULTIPOLYGON (((80.29067 9....
1864       <NA> MULTIPOLYGON (((79.91278 8....
1865       <NA> MULTIPOLYGON (((79.82789 7....
\end{verbatim}

Example 2

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(rnaturalearth)}
\FunctionTok{library}\NormalTok{(sf)}
\FunctionTok{library}\NormalTok{(ggplot2)}

\CommentTok{\# Get world countries as sf object}
\NormalTok{world }\OtherTok{\textless{}{-}} \FunctionTok{ne\_countries}\NormalTok{(}\AttributeTok{scale =} \StringTok{"medium"}\NormalTok{, }\AttributeTok{returnclass =} \StringTok{"sf"}\NormalTok{)}

\CommentTok{\# Plot the map}
\FunctionTok{ggplot}\NormalTok{(world) }\SpecialCharTok{+}
  \FunctionTok{geom\_sf}\NormalTok{(}\AttributeTok{fill =} \StringTok{"lightblue"}\NormalTok{, }\AttributeTok{color =} \StringTok{"black"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"World Map"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{06-chap6_files/figure-pdf/unnamed-chunk-32-1.pdf}}

\section{Practical}\label{practical}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Mark following locations on the map
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{oz\_capitals }\OtherTok{\textless{}{-}}\NormalTok{ tibble}\SpecialCharTok{::}\FunctionTok{tribble}\NormalTok{( }
  \SpecialCharTok{\textasciitilde{}}\NormalTok{city,           }\SpecialCharTok{\textasciitilde{}}\NormalTok{lat,     }\SpecialCharTok{\textasciitilde{}}\NormalTok{lon,}
  \StringTok{"Sydney"}\NormalTok{,    }\SpecialCharTok{{-}}\FloatTok{33.8688}\NormalTok{, }\FloatTok{151.2093}\NormalTok{,  }
  \StringTok{"Melbourne"}\NormalTok{, }\SpecialCharTok{{-}}\FloatTok{37.8136}\NormalTok{, }\FloatTok{144.9631}\NormalTok{, }
  \StringTok{"Brisbane"}\NormalTok{,  }\SpecialCharTok{{-}}\FloatTok{27.4698}\NormalTok{, }\FloatTok{153.0251}\NormalTok{, }
  \StringTok{"Adelaide"}\NormalTok{,  }\SpecialCharTok{{-}}\FloatTok{34.9285}\NormalTok{, }\FloatTok{138.6007}\NormalTok{, }
  \StringTok{"Perth"}\NormalTok{,     }\SpecialCharTok{{-}}\FloatTok{31.9505}\NormalTok{, }\FloatTok{115.8605}\NormalTok{, }
  \StringTok{"Hobart"}\NormalTok{,    }\SpecialCharTok{{-}}\FloatTok{42.8821}\NormalTok{, }\FloatTok{147.3272}\NormalTok{, }
  \StringTok{"Canberra"}\NormalTok{,  }\SpecialCharTok{{-}}\FloatTok{35.2809}\NormalTok{, }\FloatTok{149.1300}\NormalTok{, }
  \StringTok{"Darwin"}\NormalTok{,    }\SpecialCharTok{{-}}\FloatTok{12.4634}\NormalTok{, }\FloatTok{130.8456}\NormalTok{, }
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Help:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(ozmaps)}
\FunctionTok{library}\NormalTok{(sf)}
\NormalTok{oz\_states }\OtherTok{\textless{}{-}}\NormalTok{ ozmaps}\SpecialCharTok{::}\NormalTok{ozmap\_states}
\NormalTok{oz\_states}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Simple feature collection with 9 features and 1 field
Geometry type: MULTIPOLYGON
Dimension:     XY
Bounding box:  xmin: 105.5507 ymin: -43.63203 xmax: 167.9969 ymax: -9.229287
Geodetic CRS:  GDA94
# A tibble: 9 x 2
  NAME                                                                  geometry
* <chr>                                                       <MULTIPOLYGON [¬∞]>
1 New South Wales              (((150.7016 -35.12286, 150.6611 -35.11782, 150.6~
2 Victoria                     (((146.6196 -38.70196, 146.6721 -38.70259, 146.6~
3 Queensland                   (((148.8473 -20.3457, 148.8722 -20.37575, 148.85~
4 South Australia              (((137.3481 -34.48242, 137.3749 -34.46885, 137.3~
5 Western Australia            (((126.3868 -14.01168, 126.3625 -13.98264, 126.3~
6 Tasmania                     (((147.8397 -40.29844, 147.8902 -40.30258, 147.8~
7 Northern Territory           (((136.3669 -13.84237, 136.3339 -13.83922, 136.3~
8 Australian Capital Territory (((149.2317 -35.222, 149.2346 -35.24047, 149.271~
9 Other Territories            (((167.9333 -29.05421, 167.9188 -29.0344, 167.93~
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Projecting your data
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# devtools::install\_github("hrbrmstr/albersusa")}
\FunctionTok{library}\NormalTok{(albersusa)}
\NormalTok{crs\_use }\OtherTok{=} \StringTok{"+proj=laea +lat\_0=30 +lon\_0={-}95"}

\NormalTok{d\_points }\OtherTok{=} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{long =} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{110}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{103}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{84}\NormalTok{), }
                      \AttributeTok{lat  =} \FunctionTok{c}\NormalTok{(}\DecValTok{45}\NormalTok{, }\DecValTok{40}\NormalTok{, }\DecValTok{41}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\bookmarksetup{startatroot}

\chapter{Exercise}\label{exercise-3}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Write the code to obtain the following plot.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{shape }\OtherTok{\textless{}{-}} \FunctionTok{st\_read}\NormalTok{(}\FunctionTok{system.file}\NormalTok{(}\StringTok{"shape/nc.shp"}\NormalTok{, }\AttributeTok{package=}\StringTok{"sf"}\NormalTok{)) }\CommentTok{\# included with sf package}

\NormalTok{cities }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{name =} \FunctionTok{c}\NormalTok{(}\StringTok{"Raleigh"}\NormalTok{, }\StringTok{"Greensboro"}\NormalTok{, }\StringTok{"Wilmington"}\NormalTok{),}
                     \AttributeTok{x =} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{78.633333}\NormalTok{, }\SpecialCharTok{{-}}\FloatTok{79.819444}\NormalTok{, }\SpecialCharTok{{-}}\FloatTok{77.912222}\NormalTok{),}
                     \AttributeTok{y =} \FunctionTok{c}\NormalTok{(}\FloatTok{35.766667}\NormalTok{, }\FloatTok{36.08}\NormalTok{, }\FloatTok{34.223333}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Reading layer `nc' from data source 
  `C:\Users\DELL\AppData\Local\R\win-library\4.5\sf\shape\nc.shp' 
  using driver `ESRI Shapefile'
Simple feature collection with 100 features and 14 fields
Geometry type: MULTIPOLYGON
Dimension:     XY
Bounding box:  xmin: -84.32385 ymin: 33.88199 xmax: -75.45698 ymax: 36.58965
Geodetic CRS:  NAD27
\end{verbatim}

\pandocbounded{\includegraphics[keepaspectratio]{07-chap07_files/figure-pdf/unnamed-chunk-1-1.pdf}}

\bookmarksetup{startatroot}

\chapter{\texorpdfstring{Reading, Exploring, and Visualising Spatial
Data with \texttt{sf} (Cont. Chapter
6)}{Reading, Exploring, and Visualising Spatial Data with sf (Cont. Chapter 6)}}\label{reading-exploring-and-visualising-spatial-data-with-sf-cont.-chapter-6}

\section{Package}\label{package}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(spdep)}
\FunctionTok{library}\NormalTok{(sf)}
\end{Highlighting}
\end{Shaded}

\section{Data}\label{data}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{columbus }\OtherTok{\textless{}{-}} \FunctionTok{st\_read}\NormalTok{(}\FunctionTok{system.file}\NormalTok{(}\StringTok{"shapes/columbus.gpkg"}\NormalTok{, }\AttributeTok{package=}\StringTok{"spData"}\NormalTok{)[}\DecValTok{1}\NormalTok{], }\AttributeTok{quiet=}\ConstantTok{TRUE}\NormalTok{)}
\NormalTok{columbus}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Simple feature collection with 49 features and 20 fields
Geometry type: POLYGON
Dimension:     XY
Bounding box:  xmin: 5.874907 ymin: 10.78863 xmax: 11.28742 ymax: 14.74245
Projected CRS: Undefined Cartesian SRS with unknown unit
First 10 features:
       AREA PERIMETER COLUMBUS_ COLUMBUS_I POLYID NEIG  HOVAL    INC     CRIME
1  0.309441  2.440629         2          5      1    5 80.467 19.531 15.725980
2  0.259329  2.236939         3          1      2    1 44.567 21.232 18.801754
3  0.192468  2.187547         4          6      3    6 26.350 15.956 30.626781
4  0.083841  1.427635         5          2      4    2 33.200  4.477 32.387760
5  0.488888  2.997133         6          7      5    7 23.225 11.252 50.731510
6  0.283079  2.335634         7          8      6    8 28.750 16.029 26.066658
7  0.257084  2.554577         8          4      7    4 75.000  8.438  0.178269
8  0.204954  2.139524         9          3      8    3 37.125 11.337 38.425858
9  0.500755  3.169707        10         18      9   18 52.600 17.586 30.515917
10 0.246689  2.087235        11         10     10   10 96.400 13.598 34.000835
       OPEN    PLUMB DISCBD     X     Y NSA NSB EW CP THOUS NEIGNO
1  2.850747 0.217155   5.03 38.80 44.07   1   1  1  0  1000   1005
2  5.296720 0.320581   4.27 35.62 42.38   1   1  0  0  1000   1001
3  4.534649 0.374404   3.89 39.82 41.18   1   1  1  0  1000   1006
4  0.394427 1.186944   3.70 36.50 40.52   1   1  0  0  1000   1002
5  0.405664 0.624596   2.83 40.01 38.00   1   1  1  0  1000   1007
6  0.563075 0.254130   3.78 43.75 39.28   1   1  1  0  1000   1008
7  0.000000 2.402402   2.74 33.36 38.41   1   1  0  0  1000   1004
8  3.483478 2.739726   2.89 36.71 38.71   1   1  0  0  1000   1003
9  0.527488 0.890736   3.17 43.44 35.92   1   1  1  0  1000   1018
10 1.548348 0.557724   4.33 47.61 36.42   1   1  1  0  1000   1010
                             geom
1  POLYGON ((8.624129 14.23698...
2  POLYGON ((8.25279 14.23694,...
3  POLYGON ((8.653305 14.00809...
4  POLYGON ((8.459499 13.82035...
5  POLYGON ((8.685274 13.63952...
6  POLYGON ((9.401384 13.5504,...
7  POLYGON ((8.037741 13.60752...
8  POLYGON ((8.247527 13.58651...
9  POLYGON ((9.333297 13.27242...
10 POLYGON ((10.08251 13.03377...
\end{verbatim}

\section{Explore data structure}\label{explore-data-structure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{st\_crs}\NormalTok{(columbus)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Coordinate Reference System:
  User input: Undefined Cartesian SRS with unknown unit 
  wkt:
ENGCRS["Undefined Cartesian SRS with unknown unit",
    EDATUM["Unknown engineering datum"],
    CS[Cartesian,2],
        AXIS["x",unspecified,
            ORDER[1],
            LENGTHUNIT["unknown",0]],
        AXIS["y",unspecified,
            ORDER[2],
            LENGTHUNIT["unknown",0]]]
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sf}\SpecialCharTok{::}\FunctionTok{st\_geometry}\NormalTok{(columbus)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Geometry set for 49 features 
Geometry type: POLYGON
Dimension:     XY
Bounding box:  xmin: 5.874907 ymin: 10.78863 xmax: 11.28742 ymax: 14.74245
Projected CRS: Undefined Cartesian SRS with unknown unit
First 5 geometries:
\end{verbatim}

\section{Visualise data}\label{visualise-data}

\texttt{st\_geometry()} is an \texttt{sf} function that extracts only
the geometry from an sf object.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{st\_geometry}\NormalTok{(columbus)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Geometry set for 49 features 
Geometry type: POLYGON
Dimension:     XY
Bounding box:  xmin: 5.874907 ymin: 10.78863 xmax: 11.28742 ymax: 14.74245
Projected CRS: Undefined Cartesian SRS with unknown unit
First 5 geometries:
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(}\FunctionTok{st\_geometry}\NormalTok{(columbus))}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{08-chap8_files/figure-pdf/unnamed-chunk-6-1.pdf}}

Your turn: Use ggplot2 to draw the plot

\bookmarksetup{startatroot}

\chapter*{Bibliography}\label{bibliography}
\addcontentsline{toc}{chapter}{Bibliography}

\markboth{Bibliography}{Bibliography}

\printbibliography[heading=none]





\end{document}
